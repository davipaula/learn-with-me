WEBVTT
Kind: captions
Language: en

00:00:12.784 --> 00:00:15.659
Hi, I'm Refik. I'm a media artist.

00:00:15.683 --> 00:00:17.658
I use data as a pigment

00:00:17.682 --> 00:00:19.572
and paint with a thinking brush

00:00:19.596 --> 00:00:22.455
that is assisted
by artificial intelligence.

00:00:23.128 --> 00:00:25.876
Using architectural spaces as canvases,

00:00:25.900 --> 00:00:27.694
I collaborate with machines

00:00:27.718 --> 00:00:30.661
to make buildings dream and hallucinate.

00:00:30.685 --> 00:00:33.400
You may be wondering,
what does all this mean?

00:00:33.424 --> 00:00:37.089
So let me please take you
into my work and my world.

00:00:37.851 --> 00:00:41.590
I witnessed the power of imagination
when I was eight years old,

00:00:41.614 --> 00:00:43.956
as a child growing up in Istanbul.

00:00:43.980 --> 00:00:47.371
One day, my mom brought home
a videocassette

00:00:47.395 --> 00:00:50.078
of the science-fiction movie
"Blade Runner."

00:00:50.102 --> 00:00:53.077
I clearly remember being mesmerized

00:00:53.101 --> 00:00:58.010
by the stunning architectural vision
of the future of Los Angeles,

00:00:58.034 --> 00:01:00.586
a place that I had never seen before.

00:01:00.610 --> 00:01:06.007
That vision became
a kind of a staple of my daydreams.

00:01:06.031 --> 00:01:08.793
When I arrived in LA in 2012

00:01:08.817 --> 00:01:11.237
for a graduate program
in Design Media Arts,

00:01:11.261 --> 00:01:13.651
I rented a car and drove downtown

00:01:13.675 --> 00:01:16.721
to see that wonderful world
of the near future.

00:01:17.482 --> 00:01:19.128
I remember a specific line

00:01:19.152 --> 00:01:22.221
that kept playing
over and over in my head:

00:01:22.245 --> 00:01:24.340
the scene when the android Rachael

00:01:24.364 --> 00:01:28.079
realizes that her memories
are actually not hers,

00:01:28.103 --> 00:01:32.754
and when Deckard tells her
they are someone else's memories.

00:01:32.778 --> 00:01:34.011
Since that moment,

00:01:34.035 --> 00:01:36.915
one of my inspirations
has been this question.

00:01:37.561 --> 00:01:41.900
What can a machine do
with someone else's memories?

00:01:41.924 --> 00:01:44.627
Or, to say that in another way,

00:01:44.651 --> 00:01:48.402
what does it mean to be an AI
in the 21st century?

00:01:49.441 --> 00:01:51.538
Any android or AI machine

00:01:51.562 --> 00:01:54.679
is only intelligent
as long as we collaborate with it.

00:01:55.327 --> 00:01:56.792
It can construct things

00:01:56.816 --> 00:02:00.072
that human intelligence intends to produce

00:02:00.096 --> 00:02:02.238
but does not have the capacity to do so.

00:02:03.373 --> 00:02:07.178
Think about your activities
and social networks, for example.

00:02:07.208 --> 00:02:10.756
They get smarter
the more you interact with them.

00:02:10.780 --> 00:02:15.249
If machines can learn or process memories,

00:02:15.273 --> 00:02:17.134
can they also dream?

00:02:17.158 --> 00:02:18.644
Hallucinate?

00:02:18.668 --> 00:02:21.082
Involuntarily remember,

00:02:21.106 --> 00:02:25.059
or make connections
between multiple people's dreams?

00:02:25.083 --> 00:02:31.106
Does being an AI in the 21st century
simply mean not forgetting anything?

00:02:32.365 --> 00:02:33.548
And, if so,

00:02:33.572 --> 00:02:37.826
isn't it the most revolutionary thing
that we have experienced

00:02:37.850 --> 00:02:42.762
in our centuries-long effort
to capture history across media?

00:02:43.406 --> 00:02:44.740
In other words,

00:02:44.764 --> 00:02:48.217
how far have we come
since Ridley Scott's "Blade Runner"?

00:02:48.678 --> 00:02:52.165
So I established my studio in 2014

00:02:52.189 --> 00:02:54.200
and invited architects,

00:02:54.224 --> 00:02:56.596
computer and data scientists,
neuroscientists,

00:02:56.620 --> 00:02:59.467
musicians and even storytellers

00:02:59.491 --> 00:03:02.232
to join me in realizing my dreams.

00:03:03.001 --> 00:03:05.835
Can data become a pigment?

00:03:05.859 --> 00:03:08.446
This was the very first question we asked

00:03:08.470 --> 00:03:13.017
when starting our journey
to embed media arts into architecture,

00:03:13.041 --> 00:03:15.699
to collide virtual and physical worlds.

00:03:16.555 --> 00:03:21.294
So we began to imagine
what I would call the poetics of data.

00:03:22.124 --> 00:03:24.841
One of our first projects,
"Virtual Depictions,"

00:03:24.865 --> 00:03:26.964
was a public data sculpture piece

00:03:26.988 --> 00:03:29.688
commissioned by the city of San Francisco.

00:03:29.712 --> 00:03:31.918
The work invites the audience

00:03:31.942 --> 00:03:35.157
to be part of a spectacular
aesthetic experience

00:03:35.181 --> 00:03:36.820
in a living urban space

00:03:36.844 --> 00:03:42.415
by depicting a fluid network
of connections of the city itself.

00:03:42.439 --> 00:03:45.162
It also stands as a reminder

00:03:45.186 --> 00:03:48.546
of how invisible data
from our everyday lives,

00:03:48.570 --> 00:03:51.736
like the Twitter feeds
that are represented here,

00:03:51.760 --> 00:03:53.888
can be made visible

00:03:53.912 --> 00:03:59.609
and transformed into sensory knowledge
that can be experienced collectively.

00:04:00.619 --> 00:04:05.519
In fact, data can only become knowledge
when it's experienced,

00:04:05.543 --> 00:04:09.519
and what is knowledge and experience
can take many forms.

00:04:09.543 --> 00:04:11.303
When exploring such connections

00:04:11.327 --> 00:04:15.833
through the vast potential
of machine intelligence,

00:04:15.857 --> 00:04:21.072
we also pondered the connection
between human senses

00:04:21.096 --> 00:04:24.747
and the machines' capacity
for simulating nature.

00:04:24.771 --> 00:04:29.771
These inquiries began
while working on wind-data paintings.

00:04:29.795 --> 00:04:32.755
They took the shape of visualized poems

00:04:32.779 --> 00:04:37.593
based on hidden data sets
that we collected from wind sensors.

00:04:37.617 --> 00:04:40.430
We then used generative algorithms

00:04:40.454 --> 00:04:44.645
to transform wind speed,
gust and direction

00:04:44.669 --> 00:04:47.303
into an ethereal data pigment.

00:04:48.387 --> 00:04:52.418
The result was a meditative
yet speculative experience.

00:04:53.349 --> 00:04:56.212
This kinetic data sculpture,
titled "Bosphorus,"

00:04:56.236 --> 00:05:00.553
was a similar attempt to question
our capacity to reimagine

00:05:00.577 --> 00:05:01.982
natural occurrences.

00:05:03.299 --> 00:05:07.736
Using high-frequency radar collections
of the Marmara Sea,

00:05:07.760 --> 00:05:09.990
we collected sea-surface data

00:05:10.014 --> 00:05:13.195
and projected its dynamic movement
with machine intelligence.

00:05:13.874 --> 00:05:15.972
We create a sense of immersion

00:05:15.996 --> 00:05:20.175
in a calm yet constantly changing
synthetic sea view.

00:05:21.524 --> 00:05:25.612
Seeing with the brain
is often called imagination,

00:05:25.636 --> 00:05:27.940
and, for me, imagining architecture

00:05:27.964 --> 00:05:31.845
goes beyond just glass, metal or concrete,

00:05:31.869 --> 00:05:36.370
instead experimenting with
the furthermost possibilities of immersion

00:05:36.394 --> 00:05:40.507
and ways of augmenting
our perception in built environments.

00:05:40.531 --> 00:05:44.184
Research in artificial intelligence
is growing every day,

00:05:44.208 --> 00:05:48.086
leaving us with the feeling
of being plugged into a system

00:05:48.110 --> 00:05:50.404
that is bigger and more knowledgeable

00:05:50.428 --> 00:05:51.880
than ourselves.

00:05:51.904 --> 00:05:55.508
In 2017, we discovered
an open-source library

00:05:55.532 --> 00:05:58.174
of cultural documents in Istanbul

00:05:58.198 --> 00:06:01.658
and began working on "Archive Dreaming,"

00:06:01.682 --> 00:06:05.976
one of the first AI-driven
public installations in the world,

00:06:06.000 --> 00:06:12.975
an AI exploring approximately
1.7 million documents that span 270 years.

00:06:13.788 --> 00:06:16.630
One of our inspirations
during this process

00:06:16.654 --> 00:06:20.081
was a short story
called "The Library of Babel"

00:06:20.105 --> 00:06:23.312
by the Argentine writer Jorge Luis Borges.

00:06:23.336 --> 00:06:29.065
In the story, the author conceives
a universe in the form of a vast library

00:06:29.089 --> 00:06:35.000
containing all possible 410-page books
of a certain format and character set.

00:06:35.024 --> 00:06:36.493
Through this inspiring image,

00:06:36.517 --> 00:06:41.247
we imagine a way to physically explore
the vast archives of knowledge

00:06:41.271 --> 00:06:43.762
in the age of machine intelligence.

00:06:43.786 --> 00:06:45.844
The resulting work, as you can see,

00:06:45.868 --> 00:06:48.491
was a user-driven immersive space.

00:06:48.515 --> 00:06:53.390
"Archive Dreaming" profoundly transformed
the experience of a library

00:06:53.414 --> 00:06:56.163
in the age of machine intelligence.

00:06:56.187 --> 00:07:00.255
"Machine Hallucination"
is an exploration of time and space

00:07:00.279 --> 00:07:04.732
experienced through New York City's
public photographic archives.

00:07:04.756 --> 00:07:07.382
For this one-of-a-kind immersive project,

00:07:07.406 --> 00:07:10.070
we deployed machine-learning algorithms

00:07:10.094 --> 00:07:14.256
to find and process over
100 million photographs of the city.

00:07:15.008 --> 00:07:18.090
We designed an innovative narrative system

00:07:18.114 --> 00:07:24.317
to use artificial intelligence
to predict or to hallucinate new images,

00:07:24.341 --> 00:07:28.264
allowing the viewer
to step into a dreamlike fusion

00:07:28.288 --> 00:07:30.412
of past and future New York.

00:07:31.832 --> 00:07:33.651
As our projects delve deeper

00:07:33.675 --> 00:07:37.351
into remembering
and transmitting knowledge,

00:07:37.375 --> 00:07:42.333
we thought more about how memories
were not static recollections

00:07:42.357 --> 00:07:45.718
but ever-changing
interpretations of past events.

00:07:46.269 --> 00:07:48.350
We pondered how machines

00:07:48.374 --> 00:07:52.404
could simulate unconscious
and subconscious events,

00:07:52.428 --> 00:07:56.340
such as dreaming,
remembering and hallucinating.

00:07:57.356 --> 00:08:00.260
Thus, we created "Melting Memories"

00:08:00.284 --> 00:08:02.705
to visualize the moment of remembering.

00:08:03.824 --> 00:08:06.491
The inspiration came from a tragic event,

00:08:06.515 --> 00:08:10.026
when I found out that my uncle
was diagnosed with Alzheimer's.

00:08:11.602 --> 00:08:14.023
At that time, all I could think about

00:08:14.047 --> 00:08:19.110
was to find a way to celebrate
how and what we remember

00:08:19.134 --> 00:08:21.128
when we are still able to do so.

00:08:21.152 --> 00:08:25.232
I began to think of memories
not as disappearing

00:08:25.256 --> 00:08:28.168
but as melting or changing shape.

00:08:28.192 --> 00:08:30.253
With the help of machine intelligence,

00:08:30.277 --> 00:08:33.740
we worked with the scientists
at the Neuroscape Laboratory

00:08:33.764 --> 00:08:35.603
at the University of California,

00:08:35.627 --> 00:08:41.184
who showed us how to understand
brain signals as memories are made.

00:08:41.208 --> 00:08:46.311
Although my own uncle was losing
the ability to process memories,

00:08:46.335 --> 00:08:49.858
the artwork generated by EEG data

00:08:49.882 --> 00:08:53.184
explored the materiality of remembering

00:08:53.208 --> 00:08:57.588
and stood as a tribute
to what my uncle had lost.

00:09:00.533 --> 00:09:03.487
Almost nothing about contemporary LA

00:09:03.511 --> 00:09:07.272
matched my childhood
expectation of the city,

00:09:07.296 --> 00:09:10.386
with the exception
of one amazing building:

00:09:10.410 --> 00:09:13.799
the Walt Disney Concert Hall,
designed by Frank Gehry,

00:09:13.823 --> 00:09:15.554
one of my all-time heroes.

00:09:16.208 --> 00:09:19.565
In 2018, I had a call
from the LA Philharmonic

00:09:19.589 --> 00:09:21.500
who was looking for an installation

00:09:21.524 --> 00:09:25.614
to help mark the celebrated symphony's
hundred-year anniversary.

00:09:25.638 --> 00:09:29.010
For this, we decided to ask the question,

00:09:29.034 --> 00:09:31.974
"Can a building learn? Can it dream?"

00:09:32.614 --> 00:09:33.791
To answer this question,

00:09:33.815 --> 00:09:39.646
we decided to collect everything recorded
in the archives of the LA Phil and WDCH.

00:09:39.670 --> 00:09:44.535
To be precise, 77 terabytes
of digitally archived memories.

00:09:44.559 --> 00:09:46.726
By using machine intelligence,

00:09:46.750 --> 00:09:50.166
the entire archive, going back 100 years,

00:09:50.190 --> 00:09:53.195
became projections on the building's skin,

00:09:53.219 --> 00:09:57.163
42 projectors to achieve
this futuristic public experience

00:09:57.187 --> 00:09:59.362
in the heart of Los Angeles,

00:09:59.386 --> 00:10:03.369
getting one step closer
to the LA of "Blade Runner."

00:10:04.146 --> 00:10:06.660
If ever a building could dream,

00:10:06.684 --> 00:10:08.361
it was in this moment.

00:10:11.703 --> 00:10:16.449
Now, I am inviting you to one last journey
into the mind of a machine.

00:10:17.877 --> 00:10:21.241
Right now, we are fully immersed
in the data universe

00:10:21.265 --> 00:10:25.813
of every single curated TED Talk
from the past 30 years.

00:10:25.837 --> 00:10:32.439
That means this data set includes
7,705 talks from the TED stage.

00:10:33.094 --> 00:10:37.635
Those talks have been translated
into 7.4 million seconds,

00:10:37.659 --> 00:10:41.754
and each second is represented
here in this data universe.

00:10:41.778 --> 00:10:43.849
Every image that you are seeing in here

00:10:43.873 --> 00:10:46.945
represents unique moments
from those talks.

00:10:46.969 --> 00:10:48.842
By using machine intelligence,

00:10:48.866 --> 00:10:53.167
we processed a total of 487,000 sentences

00:10:53.191 --> 00:10:57.580
into 330 unique clusters of topics
like nature, global emissions,

00:10:57.604 --> 00:11:00.890
extinction, race issues, computation,

00:11:00.914 --> 00:11:04.454
trust, emotions, water and refugees.

00:11:04.478 --> 00:11:07.327
These clusters are then
connected to each other

00:11:07.351 --> 00:11:08.613
by an algorithm,

00:11:08.637 --> 00:11:12.479
[that] generated 113 million
line segments,

00:11:12.503 --> 00:11:15.606
which reveal new conceptual relationships.

00:11:15.630 --> 00:11:18.971
Wouldn't it be amazing
to be able to remember

00:11:18.995 --> 00:11:22.064
all the questions that have ever
been asked on the stage?

00:11:23.507 --> 00:11:24.946
Here I am,

00:11:24.970 --> 00:11:27.832
inside the mind
of countless great thinkers,

00:11:27.856 --> 00:11:31.579
as well as a machine,
interacting with various feelings

00:11:31.603 --> 00:11:33.968
attributed to learning,

00:11:33.992 --> 00:11:36.228
remembering, questioning

00:11:36.252 --> 00:11:39.619
and imagining all at the same time,

00:11:39.643 --> 00:11:41.918
expanding the power of the mind.

00:11:43.034 --> 00:11:45.431
For me, being right here

00:11:45.455 --> 00:11:49.407
is indeed what it means
to be an AI in the 21st century.

00:11:50.184 --> 00:11:52.477
It is in our hands, humans,

00:11:52.501 --> 00:11:56.017
to train this mind to learn and remember

00:11:56.041 --> 00:11:58.134
what we can only dream of.

00:11:59.258 --> 00:12:00.408
Thank you.

