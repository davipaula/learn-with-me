WEBVTT
Kind: captions
Language: en

00:00:13.292 --> 00:00:15.167
It’s 6:30 in the morning,

00:00:15.583 --> 00:00:20.458
and Kristen is wheeling
her prostate patient into the OR.

00:00:21.500 --> 00:00:23.750
She's a resident, a surgeon in training.

00:00:24.333 --> 00:00:26.500
It’s her job to learn.

00:00:27.292 --> 00:00:30.643
Today, she’s really hoping to do
some of the nerve-sparing,

00:00:30.667 --> 00:00:34.542
extremely delicate dissection
that can preserve erectile function.

00:00:35.500 --> 00:00:38.838
That'll be up to the attending surgeon,
though, but he's not there yet.

00:00:39.625 --> 00:00:42.018
She and the team put the patient under,

00:00:42.042 --> 00:00:45.750
and she leads the initial eight-inch
incision in the lower abdomen.

00:00:47.042 --> 00:00:50.628
Once she’s got that clamped back,
she tells the nurse to call the attending.

00:00:51.583 --> 00:00:53.875
He arrives, gowns up,

00:00:54.458 --> 00:01:00.250
And from there on in, their four hands
are mostly in that patient --

00:01:00.708 --> 00:01:03.625
with him guiding
but Kristin leading the way.

00:01:04.875 --> 00:01:09.518
When the prostates out (and, yes,
he let Kristen do a little nerve sparing),

00:01:09.542 --> 00:01:10.768
he rips off his scrubs.

00:01:10.792 --> 00:01:12.167
He starts to do paperwork.

00:01:12.833 --> 00:01:18.208
Kristen closes the patient by 8:15,

00:01:18.583 --> 00:01:21.018
with a junior resident
looking over her shoulder.

00:01:21.042 --> 00:01:24.125
And she lets him do
the final line of sutures.

00:01:24.833 --> 00:01:27.875
Kristen feels great.

00:01:28.250 --> 00:01:29.809
Patient’s going to be fine,

00:01:29.833 --> 00:01:33.000
and no doubt she’s a better surgeon
than she was at 6:30.

00:01:34.208 --> 00:01:37.042
Now this is extreme work.

00:01:37.417 --> 00:01:41.250
But Kristin’s learning to do her job
the way that most of us do:

00:01:41.625 --> 00:01:43.518
watching an expert for a bit,

00:01:43.542 --> 00:01:46.684
getting involved in easy,
safe parts of the work

00:01:46.708 --> 00:01:48.893
and progressing to riskier
and harder tasks

00:01:48.917 --> 00:01:51.250
as they guide and decide she’s ready.

00:01:52.042 --> 00:01:54.934
My whole life I’ve been fascinated
by this kind of learning.

00:01:54.958 --> 00:01:58.625
It feels elemental,
part of what makes us human.

00:01:59.750 --> 00:02:05.167
It has different names: apprenticeship,
coaching, mentorship, on the job training.

00:02:05.542 --> 00:02:08.833
In surgery, it’s called
“see one, do one, teach one.”

00:02:09.625 --> 00:02:10.969
But the process is the same,

00:02:10.993 --> 00:02:15.167
and it’s been the main path to skill
around the globe for thousands of years.

00:02:16.333 --> 00:02:20.833
Right now, we’re handling AI
in a way that blocks that path.

00:02:21.625 --> 00:02:24.315
We’re sacrificing learning
in our quest for productivity.

00:02:25.292 --> 00:02:28.101
I found this first in surgery
while I was at MIT,

00:02:28.125 --> 00:02:30.601
but now I’ve got evidence
it’s happening all over,

00:02:30.625 --> 00:02:34.500
in very different industries
and with very different kinds of AI.

00:02:35.083 --> 00:02:40.934
If we do nothing, millions of us
are going to hit a brick wall

00:02:40.958 --> 00:02:43.375
as we try to learn to deal with AI.

00:02:45.125 --> 00:02:46.897
Let’s go back to surgery to see how.

00:02:47.708 --> 00:02:49.643
Fast forward six months.

00:02:49.667 --> 00:02:55.143
It’s 6:30am again, and Kristen
is wheeling another prostate patient in,

00:02:55.167 --> 00:02:58.333
but this time to the robotic OR.

00:02:59.667 --> 00:03:01.351
The attending leads attaching

00:03:01.375 --> 00:03:04.208
a four-armed, thousand-pound
robot to the patient.

00:03:04.750 --> 00:03:07.184
They both rip off their scrubs,

00:03:07.208 --> 00:03:10.333
head to control consoles
10 or 15 feet away,

00:03:11.167 --> 00:03:14.917
and Kristen just watches.

00:03:16.375 --> 00:03:19.428
The robot allows the attending
to do the whole procedure himself,

00:03:19.452 --> 00:03:21.035
so he basically does.

00:03:21.917 --> 00:03:24.018
He knows she needs practice.

00:03:24.042 --> 00:03:25.625
He wants to give her control.

00:03:26.250 --> 00:03:29.643
But he also knows she’d be slower
and make more mistakes,

00:03:29.667 --> 00:03:31.167
and his patient comes first.

00:03:32.250 --> 00:03:36.875
So Kristin has no hope of getting anywhere
near those nerves during this rotation.

00:03:37.417 --> 00:03:41.792
She’ll be lucky if she operates more than
15 minutes during a four-hour procedure.

00:03:42.250 --> 00:03:44.875
And she knows that when she slips up,

00:03:45.458 --> 00:03:48.500
he’ll tap a touch screen,
and she’ll be watching again,

00:03:48.917 --> 00:03:51.542
feeling like a kid in the corner
with a dunce cap.

00:03:53.583 --> 00:03:57.084
Like all the studies of robots and work
I’ve done in the last eight years,

00:03:57.108 --> 00:03:59.226
I started this one
with a big, open question:

00:03:59.250 --> 00:04:02.042
How do we learn to work
with intelligent machines?

00:04:02.792 --> 00:04:08.601
To find out, I spent two and a half years
observing dozens of residents and surgeons

00:04:08.625 --> 00:04:12.101
doing traditional and robotic surgery,
interviewing them

00:04:12.125 --> 00:04:15.463
and in general hanging out
with the residents as they tried to learn.

00:04:16.250 --> 00:04:19.601
I covered 18 of the top
US teaching hospitals,

00:04:19.625 --> 00:04:21.083
and the story was the same.

00:04:21.875 --> 00:04:24.417
Most residents were in Kristen's shoes.

00:04:24.958 --> 00:04:26.750
They got to “see one” plenty,

00:04:27.583 --> 00:04:29.875
but the “do one” was barely available.

00:04:30.333 --> 00:04:32.861
So they couldn’t struggle,
and they weren’t learning.

00:04:33.291 --> 00:04:37.101
This was important news for surgeons, but
I needed to know how widespread it was:

00:04:37.125 --> 00:04:40.958
Where else was using AI
blocking learning on the job?

00:04:42.208 --> 00:04:46.518
To find out, I’ve connected with a small
but growing group of young researchers

00:04:46.542 --> 00:04:49.976
who’ve done boots-on-the-ground studies
of work involving AI

00:04:50.000 --> 00:04:52.976
in very diverse settings
like start-ups, policing,

00:04:53.000 --> 00:04:55.601
investment banking and online education.

00:04:55.625 --> 00:05:01.476
Like me, they spent at least a year
and many hundreds of hours observing,

00:05:01.500 --> 00:05:05.417
interviewing and often working
side-by-side with the people they studied.

00:05:06.458 --> 00:05:08.875
We shared data, and I looked for patterns.

00:05:09.917 --> 00:05:15.125
No matter the industry, the work,
the AI, the story was the same.

00:05:16.042 --> 00:05:19.684
Organizations were trying harder
and harder to get results from AI,

00:05:19.708 --> 00:05:23.250
and they were peeling learners away from
expert work as they did it.

00:05:24.333 --> 00:05:27.208
Start-up managers were outsourcing
their customer contact.

00:05:27.833 --> 00:05:31.875
Cops had to learn to deal with crime
forecasts without experts support.

00:05:32.875 --> 00:05:36.125
Junior bankers were getting
cut out of complex analysis,

00:05:36.500 --> 00:05:39.583
and professors had to build
online courses without help.

00:05:41.125 --> 00:05:44.351
And the effect of all of this
was the same as in surgery.

00:05:44.375 --> 00:05:47.292
Learning on the job
was getting much harder.

00:05:48.958 --> 00:05:50.375
This can’t last.

00:05:51.542 --> 00:05:55.809
McKinsey estimates that between half
a billion and a billion of us

00:05:55.833 --> 00:05:59.958
are going to have to adapt to AI
in our daily work by 2030.

00:06:01.000 --> 00:06:03.011
And we’re assuming
that on-the-job learning

00:06:03.035 --> 00:06:04.952
will be there for us as we try.

00:06:05.500 --> 00:06:09.768
Accenture’s latest workers survey showed
that most workers learned key skills

00:06:09.792 --> 00:06:12.083
on the job, not in formal training.

00:06:13.292 --> 00:06:16.809
So while we talk a lot about its
potential future impact,

00:06:16.833 --> 00:06:20.518
the aspect of AI
that may matter most right now

00:06:20.542 --> 00:06:23.917
is that we’re handling it in a way
that blocks learning on the job

00:06:24.375 --> 00:06:26.000
just when we need it most.

00:06:27.458 --> 00:06:33.500
Now across all our sites,
a small minority found a way to learn.

00:06:35.625 --> 00:06:38.667
They did it by breaking and bending rules.

00:06:39.083 --> 00:06:43.726
Approved methods weren’t working,
so they bent and broke rules

00:06:43.750 --> 00:06:45.726
to get hands-on practice with experts.

00:06:45.750 --> 00:06:51.351
In my setting, residents got involved
in robotic surgery in medical school

00:06:51.375 --> 00:06:54.958
at the expense
of their generalist education.

00:06:56.417 --> 00:07:02.268
And they spent hundreds of extra hours
with simulators and recordings of surgery,

00:07:02.292 --> 00:07:04.833
when you were supposed to learn in the OR.

00:07:05.375 --> 00:07:08.851
And maybe most importantly,
they found ways to struggle

00:07:08.875 --> 00:07:12.625
in live procedures
with limited expert supervision.

00:07:13.792 --> 00:07:18.101
I call all this “shadow learning,”
because it bends the rules

00:07:18.125 --> 00:07:20.125
and learner’s do it out of the limelight.

00:07:21.542 --> 00:07:25.643
And everyone turns a blind eye
because it gets results.

00:07:25.667 --> 00:07:28.833
Remember, these are
the star pupils of the bunch.

00:07:29.792 --> 00:07:33.000
Now, obviously, this is not OK,
and it’s not sustainable.

00:07:33.708 --> 00:07:35.893
No one should have to risk getting fired

00:07:35.917 --> 00:07:38.067
to learn the skills
they need to do their job.

00:07:38.792 --> 00:07:40.848
But we do need to learn from these people.

00:07:41.917 --> 00:07:44.167
They took serious risks to learn.

00:07:44.792 --> 00:07:49.143
They understood they needed to protect
struggle and challenge in their work

00:07:49.167 --> 00:07:52.059
so that they could push themselves
to tackle hard problems

00:07:52.083 --> 00:07:54.042
right near the edge of their capacity.

00:07:54.458 --> 00:07:56.674
They also made sure
there was an expert nearby

00:07:56.698 --> 00:07:59.792
to offer pointers and to backstop
against catastrophe.

00:08:00.875 --> 00:08:04.333
Let’s build this combination
of struggle and expert support

00:08:04.708 --> 00:08:07.458
into each AI implementation.

00:08:08.375 --> 00:08:11.203
Here’s one clear example
I could get of this on the ground.

00:08:12.125 --> 00:08:13.351
Before robots,

00:08:13.375 --> 00:08:18.167
if you were a bomb disposal technician,
you dealt with an IED by walking up to it.

00:08:19.333 --> 00:08:21.476
A junior officer was
hundreds of feet away,

00:08:21.500 --> 00:08:24.809
so could only watch and help
if you decided it was safe

00:08:24.833 --> 00:08:26.250
and invited them downrange.

00:08:27.208 --> 00:08:31.101
Now you sit side-by-side
in a bomb-proof truck.

00:08:31.125 --> 00:08:32.934
You both watched the video feed.

00:08:32.958 --> 00:08:37.268
They control a distant robot,
and you guide the work out loud.

00:08:37.292 --> 00:08:40.500
Trainees learn better than they
did before robots.

00:08:41.125 --> 00:08:45.058
We can scale this to surgery,
start-ups, policing,

00:08:45.082 --> 00:08:47.707
investment banking,
online education and beyond.

00:08:48.375 --> 00:08:50.875
The good news is
we’ve got new tools to do it.

00:08:51.750 --> 00:08:55.832
The internet and the cloud mean we don’t
always need one expert for every trainee,

00:08:56.167 --> 00:09:00.625
for them to be physically near each other
or even to be in the same organization.

00:09:01.292 --> 00:09:04.333
And we can build AI to help:

00:09:05.167 --> 00:09:10.226
to coach learners as they struggle,
to coach experts as they coach

00:09:10.250 --> 00:09:12.792
and to connect those two groups
in smart ways.

00:09:15.375 --> 00:09:17.917
There are people at work
on systems like this,

00:09:18.333 --> 00:09:21.125
but they’ve been mostly focused
on formal training.

00:09:21.458 --> 00:09:24.042
And the deeper crisis
is in on-the-job learning.

00:09:24.417 --> 00:09:26.268
We must do better.

00:09:26.292 --> 00:09:28.875
Today’s problems demand we do better

00:09:29.375 --> 00:09:34.250
to create work that takes full advantage
of AI’s amazing capabilities

00:09:35.042 --> 00:09:37.792
while enhancing our skills as we do it.

00:09:38.333 --> 00:09:41.083
That’s the kind of future
I dreamed of as a kid.

00:09:41.458 --> 00:09:43.625
And the time to create it is now.

00:09:44.333 --> 00:09:45.559
Thank you.

00:09:45.583 --> 00:09:49.208
(Applause)

