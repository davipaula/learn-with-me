WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Ivana Korom
Reviewer: Krystian Aparta

00:00:12.865 --> 00:00:14.992
Let me share a paradox.

00:00:16.429 --> 00:00:17.896
For the last 10 years,

00:00:17.920 --> 00:00:21.768
many companies have been trying
to become less bureaucratic,

00:00:21.792 --> 00:00:24.625
to have fewer central rules
and procedures,

00:00:24.649 --> 00:00:27.894
more autonomy for their local
teams to be more agile.

00:00:28.204 --> 00:00:32.790
And now they are pushing
artificial intelligence, AI,

00:00:32.814 --> 00:00:35.259
unaware that cool technology

00:00:35.283 --> 00:00:38.885
might make them
more bureaucratic than ever.

00:00:39.378 --> 00:00:40.529
Why?

00:00:40.553 --> 00:00:44.045
Because AI operates
just like bureaucracies.

00:00:44.403 --> 00:00:46.815
The essence of bureaucracy

00:00:46.839 --> 00:00:51.283
is to favor rules and procedures
over human judgment.

00:00:51.887 --> 00:00:55.728
And AI decides solely based on rules.

00:00:56.062 --> 00:00:58.895
Many rules inferred from past data

00:00:58.919 --> 00:01:00.823
but only rules.

00:01:01.204 --> 00:01:04.934
And if human judgment
is not kept in the loop,

00:01:04.958 --> 00:01:09.514
AI will bring a terrifying form
of new bureaucracy --

00:01:09.538 --> 00:01:12.537
I call it "algocracy" --

00:01:12.561 --> 00:01:17.061
where AI will take more and more
critical decisions by the rules

00:01:17.085 --> 00:01:19.402
outside of any human control.

00:01:20.427 --> 00:01:22.101
Is there a real risk?

00:01:22.514 --> 00:01:23.664
Yes.

00:01:23.688 --> 00:01:26.694
I'm leading a team of 800 AI specialists.

00:01:26.718 --> 00:01:30.575
We have deployed
over 100 customized AI solutions

00:01:30.599 --> 00:01:33.066
for large companies around the world.

00:01:33.417 --> 00:01:39.236
And I see too many corporate executives
behaving like bureaucrats from the past.

00:01:39.784 --> 00:01:44.696
They want to take costly,
old-fashioned humans out of the loop

00:01:44.720 --> 00:01:48.585
and rely only upon AI to take decisions.

00:01:49.244 --> 00:01:53.497
I call this the "human-zero mindset."

00:01:54.260 --> 00:01:56.378
And why is it so tempting?

00:01:56.879 --> 00:02:02.283
Because the other route,
"Human plus AI," is long,

00:02:02.307 --> 00:02:04.916
costly and difficult.

00:02:04.940 --> 00:02:08.233
Business teams, tech teams,
data-science teams

00:02:08.257 --> 00:02:10.336
have to iterate for months

00:02:10.360 --> 00:02:15.628
to craft exactly how humans and AI
can best work together.

00:02:16.160 --> 00:02:19.588
Long, costly and difficult.

00:02:19.891 --> 00:02:21.961
But the reward is huge.

00:02:22.343 --> 00:02:25.649
A recent survey from BCG and MIT

00:02:25.673 --> 00:02:30.180
shows that 18 percent
of companies in the world

00:02:30.204 --> 00:02:32.418
are pioneering AI,

00:02:32.442 --> 00:02:34.743
making money with it.

00:02:35.157 --> 00:02:40.747
Those companies focus 80 percent
of their AI initiatives

00:02:40.771 --> 00:02:42.724
on effectiveness and growth,

00:02:42.748 --> 00:02:44.918
taking better decisions --

00:02:44.942 --> 00:02:48.480
not replacing humans with AI
to save costs.

00:02:50.159 --> 00:02:53.359
Why is it important
to keep humans in the loop?

00:02:54.032 --> 00:02:58.879
Simply because, left alone,
AI can do very dumb things.

00:02:59.363 --> 00:03:02.736
Sometimes with no consequences,
like in this tweet.

00:03:03.212 --> 00:03:04.776
"Dear Amazon,

00:03:04.800 --> 00:03:06.186
I bought a toilet seat.

00:03:06.210 --> 00:03:07.871
Necessity, not desire.

00:03:07.895 --> 00:03:09.347
I do not collect them,

00:03:09.371 --> 00:03:11.609
I'm not a toilet-seat addict.

00:03:11.633 --> 00:03:13.839
No matter how temptingly you email me,

00:03:13.863 --> 00:03:16.212
I am not going to think, 'Oh, go on, then,

00:03:16.236 --> 00:03:18.376
one more toilet seat,
I'll treat myself.' "

00:03:18.400 --> 00:03:19.744
(Laughter)

00:03:19.768 --> 00:03:24.386
Sometimes, with more consequence,
like in this other tweet.

00:03:24.903 --> 00:03:26.690
"Had the same situation

00:03:26.714 --> 00:03:29.173
with my mother's burial urn."

00:03:29.197 --> 00:03:30.205
(Laughter)

00:03:30.229 --> 00:03:31.594
"For months after her death,

00:03:31.618 --> 00:03:35.166
I got messages from Amazon,
saying, 'If you liked that ...' "

00:03:35.190 --> 00:03:37.205
(Laughter)

00:03:37.229 --> 00:03:39.757
Sometimes with worse consequences.

00:03:39.781 --> 00:03:44.511
Take an AI engine rejecting
a student application for university.

00:03:44.535 --> 00:03:45.685
Why?

00:03:45.709 --> 00:03:48.379
Because it has "learned," on past data,

00:03:48.403 --> 00:03:51.585
characteristics of students
that will pass and fail.

00:03:51.609 --> 00:03:53.712
Some are obvious, like GPAs.

00:03:54.069 --> 00:03:59.178
But if, in the past, all students
from a given postal code have failed,

00:03:59.202 --> 00:04:02.734
it is very likely
that AI will make this a rule

00:04:02.758 --> 00:04:06.528
and will reject every student
with this postal code,

00:04:06.552 --> 00:04:11.365
not giving anyone the opportunity
to prove the rule wrong.

00:04:11.857 --> 00:04:14.373
And no one can check all the rules,

00:04:14.397 --> 00:04:17.849
because advanced AI
is constantly learning.

00:04:18.307 --> 00:04:20.633
And if humans are kept out of the room,

00:04:20.657 --> 00:04:23.934
there comes the algocratic nightmare.

00:04:24.466 --> 00:04:27.323
Who is accountable
for rejecting the student?

00:04:27.347 --> 00:04:28.990
No one, AI did.

00:04:29.014 --> 00:04:30.688
Is it fair? Yes.

00:04:30.712 --> 00:04:33.954
The same set of objective rules
has been applied to everyone.

00:04:34.367 --> 00:04:38.269
Could we reconsider for this bright kid
with the wrong postal code?

00:04:38.899 --> 00:04:42.010
No, algos don't change their mind.

00:04:42.974 --> 00:04:44.990
We have a choice here.

00:04:45.756 --> 00:04:48.280
Carry on with algocracy

00:04:48.304 --> 00:04:51.169
or decide to go to "Human plus AI."

00:04:51.193 --> 00:04:52.526
And to do this,

00:04:52.550 --> 00:04:55.990
we need to stop thinking tech first,

00:04:56.014 --> 00:04:59.664
and we need to start applying
the secret formula.

00:05:00.601 --> 00:05:02.704
To deploy "Human plus AI,"

00:05:02.728 --> 00:05:05.649
10 percent of the effort is to code algos;

00:05:05.673 --> 00:05:09.204
20 percent to build tech
around the algos,

00:05:09.228 --> 00:05:13.334
collecting data, building UI,
integrating into legacy systems;

00:05:13.358 --> 00:05:16.262
But 70 percent, the bulk of the effort,

00:05:16.286 --> 00:05:20.762
is about weaving together AI
with people and processes

00:05:20.786 --> 00:05:23.160
to maximize real outcome.

00:05:24.136 --> 00:05:28.770
AI fails when cutting short
on the 70 percent.

00:05:28.794 --> 00:05:31.953
The price tag for that can be small,

00:05:31.977 --> 00:05:35.962
wasting many, many millions
of dollars on useless technology.

00:05:35.986 --> 00:05:37.136
Anyone cares?

00:05:38.153 --> 00:05:40.478
Or real tragedies:

00:05:41.137 --> 00:05:48.652
346 casualties in the recent crashes
of two B-737 aircrafts

00:05:48.776 --> 00:05:52.037
when pilots could not interact properly

00:05:52.061 --> 00:05:54.528
with a computerized command system.

00:05:55.974 --> 00:05:57.768
For a successful 70 percent,

00:05:57.792 --> 00:06:02.887
the first step is to make sure
that algos are coded by data scientists

00:06:02.911 --> 00:06:05.029
and domain experts together.

00:06:05.427 --> 00:06:07.625
Take health care for example.

00:06:07.649 --> 00:06:12.466
One of our teams worked on a new drug
with a slight problem.

00:06:12.784 --> 00:06:14.283
When taking their first dose,

00:06:14.307 --> 00:06:17.791
some patients, very few,
have heart attacks.

00:06:18.117 --> 00:06:21.252
So, all patients,
when taking their first dose,

00:06:21.276 --> 00:06:23.958
have to spend one day in hospital,

00:06:23.982 --> 00:06:26.053
for monitoring, just in case.

00:06:26.613 --> 00:06:32.169
Our objective was to identify patients
who were at zero risk of heart attacks,

00:06:32.193 --> 00:06:34.526
who could skip the day in hospital.

00:06:34.962 --> 00:06:39.041
We used AI to analyze data
from clinical trials,

00:06:40.145 --> 00:06:44.513
to correlate ECG signal,
blood composition, biomarkers,

00:06:44.537 --> 00:06:46.537
with the risk of heart attack.

00:06:47.232 --> 00:06:48.506
In one month,

00:06:48.530 --> 00:06:54.561
our model could flag 62 percent
of patients at zero risk.

00:06:54.887 --> 00:06:57.109
They could skip the day in hospital.

00:06:57.863 --> 00:07:01.355
Would you be comfortable
staying at home for your first dose

00:07:01.379 --> 00:07:02.903
if the algo said so?

00:07:02.927 --> 00:07:03.942
(Laughter)

00:07:03.966 --> 00:07:05.616
Doctors were not.

00:07:05.966 --> 00:07:08.268
What if we had false negatives,

00:07:08.292 --> 00:07:13.521
meaning people who are told by AI
they can stay at home, and die?

00:07:13.545 --> 00:07:14.910
(Laughter)

00:07:14.934 --> 00:07:17.386
There started our 70 percent.

00:07:17.410 --> 00:07:19.402
We worked with a team of doctors

00:07:19.426 --> 00:07:23.225
to check the medical logic
of each variable in our model.

00:07:23.537 --> 00:07:28.106
For instance, we were using
the concentration of a liver enzyme

00:07:28.130 --> 00:07:29.403
as a predictor,

00:07:29.427 --> 00:07:33.125
for which the medical logic
was not obvious.

00:07:33.149 --> 00:07:35.815
The statistical signal was quite strong.

00:07:36.300 --> 00:07:39.133
But what if it was a bias in our sample?

00:07:39.157 --> 00:07:41.957
That predictor was taken out of the model.

00:07:42.307 --> 00:07:45.752
We also took out predictors
for which experts told us

00:07:45.776 --> 00:07:49.712
they cannot be rigorously measured
by doctors in real life.

00:07:50.371 --> 00:07:52.061
After four months,

00:07:52.085 --> 00:07:55.156
we had a model and a medical protocol.

00:07:55.514 --> 00:07:57.180
They both got approved

00:07:57.204 --> 00:08:00.426
my medical authorities
in the US last spring,

00:08:00.450 --> 00:08:04.156
resulting in far less stress
for half of the patients

00:08:04.180 --> 00:08:05.980
and better quality of life.

00:08:06.355 --> 00:08:10.624
And an expected upside on sales
over 100 million for that drug.

00:08:11.668 --> 00:08:15.866
Seventy percent weaving AI
with team and processes

00:08:15.890 --> 00:08:19.461
also means building powerful interfaces

00:08:19.485 --> 00:08:24.794
for humans and AI to solve
the most difficult problems together.

00:08:25.286 --> 00:08:29.921
Once, we got challenged
by a fashion retailer.

00:08:31.143 --> 00:08:33.641
"We have the best buyers in the world.

00:08:33.665 --> 00:08:38.776
Could you build an AI engine
that would beat them at forecasting sales?

00:08:38.800 --> 00:08:42.966
At telling how many high-end,
light-green, men XL shirts

00:08:42.990 --> 00:08:45.037
we need to buy for next year?

00:08:45.061 --> 00:08:47.871
At predicting better what will sell or not

00:08:47.895 --> 00:08:49.855
than our designers."

00:08:50.434 --> 00:08:54.410
Our team trained a model in a few weeks,
on past sales data,

00:08:54.434 --> 00:08:57.967
and the competition was organized
with human buyers.

00:08:58.347 --> 00:08:59.497
Result?

00:09:00.061 --> 00:09:04.743
AI wins, reducing forecasting
errors by 25 percent.

00:09:05.903 --> 00:09:10.736
Human-zero champions could have tried
to implement this initial model

00:09:10.760 --> 00:09:13.514
and create a fight with all human buyers.

00:09:13.538 --> 00:09:14.688
Have fun.

00:09:15.205 --> 00:09:20.331
But we knew that human buyers
had insights on fashion trends

00:09:20.355 --> 00:09:23.200
that could not be found in past data.

00:09:23.701 --> 00:09:26.558
There started our 70 percent.

00:09:26.582 --> 00:09:28.526
We went for a second test,

00:09:28.550 --> 00:09:31.653
where human buyers
were reviewing quantities

00:09:31.677 --> 00:09:33.339
suggested by AI

00:09:33.363 --> 00:09:35.688
and could correct them if needed.

00:09:36.180 --> 00:09:37.330
Result?

00:09:37.704 --> 00:09:39.821
Humans using AI ...

00:09:39.845 --> 00:09:41.252
lose.

00:09:41.795 --> 00:09:45.946
Seventy-five percent
of the corrections made by a human

00:09:45.970 --> 00:09:48.025
were reducing accuracy.

00:09:49.002 --> 00:09:52.176
Was it time to get rid of human buyers?

00:09:52.200 --> 00:09:53.358
No.

00:09:53.382 --> 00:09:55.999
It was time to recreate a model

00:09:56.023 --> 00:10:01.094
where humans would not try
to guess when AI is wrong,

00:10:01.118 --> 00:10:05.660
but where AI would take real input
from human buyers.

00:10:06.962 --> 00:10:08.573
We fully rebuilt the model

00:10:08.597 --> 00:10:14.561
and went away from our initial interface,
which was, more or less,

00:10:14.585 --> 00:10:17.022
"Hey, human! This is what I forecast,

00:10:17.046 --> 00:10:18.807
correct whatever you want,"

00:10:18.831 --> 00:10:22.467
and moved to a much richer one, more like,

00:10:22.491 --> 00:10:24.467
"Hey, humans!

00:10:24.491 --> 00:10:26.316
I don't know the trends for next year.

00:10:26.340 --> 00:10:29.296
Could you share with me
your top creative bets?"

00:10:30.063 --> 00:10:31.539
"Hey, humans!

00:10:31.563 --> 00:10:34.282
Could you help me quantify
those few big items?

00:10:34.306 --> 00:10:37.623
I cannot find any good comparables
in the past for them."

00:10:38.401 --> 00:10:39.551
Result?

00:10:40.195 --> 00:10:42.195
"Human plus AI" wins,

00:10:42.219 --> 00:10:46.138
reducing forecast errors by 50 percent.

00:10:47.770 --> 00:10:50.598
It took one year to finalize the tool.

00:10:51.073 --> 00:10:54.390
Long, costly and difficult.

00:10:55.046 --> 00:10:57.252
But profits and benefits

00:10:57.276 --> 00:11:02.672
were in excess of 100 million of savings
per year for that retailer.

00:11:03.459 --> 00:11:06.395
Seventy percent on very sensitive topics

00:11:06.419 --> 00:11:10.197
also means human have to decide
what is right or wrong

00:11:10.221 --> 00:11:14.307
and define rules
for what AI can do or not,

00:11:14.331 --> 00:11:17.815
like setting caps on prices
to prevent pricing engines

00:11:17.839 --> 00:11:22.363
[from charging] outrageously high prices
to uneducated customers

00:11:22.387 --> 00:11:23.853
who would accept them.

00:11:24.538 --> 00:11:27.101
Only humans can define those boundaries --

00:11:27.125 --> 00:11:30.746
there is no way AI
can find them in past data.

00:11:31.230 --> 00:11:33.697
Some situations are in the gray zone.

00:11:34.135 --> 00:11:36.880
We worked with a health insurer.

00:11:36.904 --> 00:11:41.617
He developed an AI engine
to identify, among his clients,

00:11:41.641 --> 00:11:44.189
people who are just about
to go to hospital

00:11:44.213 --> 00:11:46.482
to sell them premium services.

00:11:46.506 --> 00:11:48.021
And the problem is,

00:11:48.045 --> 00:11:51.014
some prospects were called
by the commercial team

00:11:51.038 --> 00:11:53.735
while they did not know yet

00:11:53.759 --> 00:11:56.577
they would have to go
to hospital very soon.

00:11:57.720 --> 00:12:00.037
You are the CEO of this company.

00:12:00.061 --> 00:12:01.728
Do you stop that program?

00:12:02.577 --> 00:12:04.490
Not an easy question.

00:12:04.514 --> 00:12:08.077
And to tackle this question,
some companies are building teams,

00:12:08.101 --> 00:12:13.894
defining ethical rules and standards
to help business and tech teams set limits

00:12:13.918 --> 00:12:17.514
between personalization and manipulation,

00:12:17.538 --> 00:12:20.507
customization of offers
and discrimination,

00:12:20.531 --> 00:12:22.554
targeting and intrusion.

00:12:24.562 --> 00:12:28.236
I am convinced that in every company,

00:12:28.260 --> 00:12:32.910
applying AI where it really matters
has massive payback.

00:12:33.474 --> 00:12:35.625
Business leaders need to be bold

00:12:35.649 --> 00:12:37.625
and select a few topics,

00:12:37.649 --> 00:12:42.585
and for each of them, mobilize
10, 20, 30 people from their best teams --

00:12:42.609 --> 00:12:45.942
tech, AI, data science, ethics --

00:12:45.966 --> 00:12:50.387
and go through the full
10-, 20-, 70-percent cycle

00:12:50.411 --> 00:12:52.133
of "Human plus AI,"

00:12:52.157 --> 00:12:56.497
if they want to land AI effectively
in their teams and processes.

00:12:57.006 --> 00:12:58.895
There is no other way.

00:12:58.919 --> 00:13:03.643
Citizens in developed economies
already fear algocracy.

00:13:04.196 --> 00:13:07.767
Seven thousand were interviewed
in a recent survey.

00:13:08.157 --> 00:13:11.712
More than 75 percent
expressed real concerns

00:13:11.736 --> 00:13:15.673
on the impact of AI
on the workforce, on privacy,

00:13:15.697 --> 00:13:19.133
on the risk of a dehumanized society.

00:13:19.157 --> 00:13:24.537
Pushing algocracy creates a real risk
of severe backlash against AI

00:13:24.561 --> 00:13:28.664
within companies or in society at large.

00:13:29.014 --> 00:13:32.299
"Human plus AI" is our only option

00:13:32.323 --> 00:13:35.457
to bring the benefits of AI
to the real world.

00:13:36.038 --> 00:13:37.196
And in the end,

00:13:37.220 --> 00:13:41.354
winning organizations
will invest in human knowledge,

00:13:41.378 --> 00:13:43.703
not just AI and data.

00:13:44.792 --> 00:13:48.120
Recruiting, training,
rewarding human experts.

00:13:48.800 --> 00:13:51.942
Data is said to be the new oil,

00:13:51.966 --> 00:13:56.037
but believe me, human knowledge
will make the difference,

00:13:56.061 --> 00:13:59.649
because it is the only derrick available

00:13:59.673 --> 00:14:03.347
to pump the oil hidden in the data.

00:14:04.633 --> 00:14:05.786
Thank you.

00:14:05.810 --> 00:14:09.714
(Applause)

