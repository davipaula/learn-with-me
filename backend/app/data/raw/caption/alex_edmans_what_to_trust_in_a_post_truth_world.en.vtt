WEBVTT
Kind: captions
Language: en

00:00:13.675 --> 00:00:16.595
Belle Gibson was a happy young Australian.

00:00:16.619 --> 00:00:19.642
She lived in Perth,
and she loved skateboarding.

00:00:20.173 --> 00:00:24.622
But in 2009, Belle learned that she had
brain cancer and four months to live.

00:00:25.034 --> 00:00:28.567
Two months of chemo
and radiotherapy had no effect.

00:00:29.145 --> 00:00:30.645
But Belle was determined.

00:00:30.669 --> 00:00:32.799
She'd been a fighter her whole life.

00:00:32.823 --> 00:00:36.117
From age six, she had to cook
for her brother, who had autism,

00:00:36.141 --> 00:00:38.529
and her mother,
who had multiple sclerosis.

00:00:38.553 --> 00:00:40.307
Her father was out of the picture.

00:00:40.736 --> 00:00:44.022
So Belle fought, with exercise,
with meditation

00:00:44.046 --> 00:00:46.886
and by ditching meat
for fruit and vegetables.

00:00:47.387 --> 00:00:49.587
And she made a complete recovery.

00:00:50.784 --> 00:00:52.363
Belle's story went viral.

00:00:52.387 --> 00:00:55.780
It was tweeted, blogged about,
shared and reached millions of people.

00:00:56.246 --> 00:00:59.357
It showed the benefits of shunning
traditional medicine

00:00:59.381 --> 00:01:00.848
for diet and exercise.

00:01:01.381 --> 00:01:05.879
In August 2013, Belle launched
a healthy eating app,

00:01:05.903 --> 00:01:07.252
The Whole Pantry,

00:01:07.276 --> 00:01:11.299
downloaded 200,000 times
in the first month.

00:01:13.228 --> 00:01:16.027
But Belle's story was a lie.

00:01:17.227 --> 00:01:18.761
Belle never had cancer.

00:01:19.601 --> 00:01:23.734
People shared her story
without ever checking if it was true.

00:01:24.815 --> 00:01:28.035
This is a classic example
of confirmation bias.

00:01:28.403 --> 00:01:33.079
We accept a story uncritically
if it confirms what we'd like to be true.

00:01:33.484 --> 00:01:35.990
And we reject any story
that contradicts it.

00:01:36.937 --> 00:01:38.762
How often do we see this

00:01:38.786 --> 00:01:41.831
in the stories
that we share and we ignore?

00:01:41.855 --> 00:01:46.037
In politics, in business,
in health advice.

00:01:47.180 --> 00:01:51.286
The Oxford Dictionary's
word of 2016 was "post-truth."

00:01:51.768 --> 00:01:55.260
And the recognition that we now live
in a post-truth world

00:01:55.284 --> 00:01:58.648
has led to a much needed emphasis
on checking the facts.

00:01:59.339 --> 00:02:00.736
But the punch line of my talk

00:02:00.760 --> 00:02:03.751
is that just checking
the facts is not enough.

00:02:04.347 --> 00:02:07.274
Even if Belle's story were true,

00:02:07.298 --> 00:02:09.365
it would be just as irrelevant.

00:02:10.457 --> 00:02:11.607
Why?

00:02:11.957 --> 00:02:15.465
Well, let's look at one of the most
fundamental techniques in statistics.

00:02:15.489 --> 00:02:17.899
It's called Bayesian inference.

00:02:18.251 --> 00:02:21.187
And the very simple version is this:

00:02:21.211 --> 00:02:24.479
We care about "does the data
support the theory?"

00:02:25.053 --> 00:02:28.509
Does the data increase our belief
that the theory is true?

00:02:29.520 --> 00:02:33.903
But instead, we end up asking,
"Is the data consistent with the theory?"

00:02:34.838 --> 00:02:37.353
But being consistent with the theory

00:02:37.377 --> 00:02:40.306
does not mean that the data
supports the theory.

00:02:40.799 --> 00:02:41.958
Why?

00:02:41.982 --> 00:02:45.807
Because of a crucial
but forgotten third term --

00:02:45.831 --> 00:02:49.389
the data could also be consistent
with rival theories.

00:02:49.918 --> 00:02:54.585
But due to confirmation bias,
we never consider the rival theories,

00:02:54.609 --> 00:02:57.760
because we're so protective
of our own pet theory.

00:02:58.688 --> 00:03:01.101
Now, let's look at this for Belle's story.

00:03:01.125 --> 00:03:05.339
Well, we care about:
Does Belle's story support the theory

00:03:05.363 --> 00:03:06.966
that diet cures cancer?

00:03:06.990 --> 00:03:08.777
But instead, we end up asking,

00:03:08.801 --> 00:03:12.846
"Is Belle's story consistent
with diet curing cancer?"

00:03:13.790 --> 00:03:15.394
And the answer is yes.

00:03:15.839 --> 00:03:19.942
If diet did cure cancer,
we'd see stories like Belle's.

00:03:20.839 --> 00:03:23.688
But even if diet did not cure cancer,

00:03:23.712 --> 00:03:26.355
we'd still see stories like Belle's.

00:03:26.744 --> 00:03:31.934
A single story in which
a patient apparently self-cured

00:03:31.958 --> 00:03:35.132
just due to being misdiagnosed
in the first place.

00:03:35.680 --> 00:03:39.006
Just like, even if smoking
was bad for your health,

00:03:39.030 --> 00:03:42.334
you'd still see one smoker
who lived until 100.

00:03:42.664 --> 00:03:43.814
(Laughter)

00:03:44.157 --> 00:03:46.719
Just like, even if education
was good for your income,

00:03:46.743 --> 00:03:51.024
you'd still see one multimillionaire
who didn't go to university.

00:03:51.048 --> 00:03:56.032
(Laughter)

00:03:56.056 --> 00:03:59.967
So the biggest problem with Belle's story
is not that it was false.

00:03:59.991 --> 00:04:02.522
It's that it's only one story.

00:04:03.094 --> 00:04:07.475
There might be thousands of other stories
where diet alone failed,

00:04:07.499 --> 00:04:09.433
but we never hear about them.

00:04:10.141 --> 00:04:14.037
We share the outlier cases
because they are new,

00:04:14.061 --> 00:04:15.928
and therefore they are news.

00:04:16.657 --> 00:04:19.133
We never share the ordinary cases.

00:04:19.157 --> 00:04:22.370
They're too ordinary,
they're what normally happens.

00:04:23.125 --> 00:04:26.220
And that's the true
99 percent that we ignore.

00:04:26.244 --> 00:04:29.212
Just like in society, you can't just
listen to the one percent,

00:04:29.236 --> 00:04:30.394
the outliers,

00:04:30.418 --> 00:04:33.084
and ignore the 99 percent, the ordinary.

00:04:34.022 --> 00:04:37.276
Because that's the second example
of confirmation bias.

00:04:37.300 --> 00:04:40.069
We accept a fact as data.

00:04:41.038 --> 00:04:45.006
The biggest problem is not
that we live in a post-truth world;

00:04:45.030 --> 00:04:48.799
it's that we live in a post-data world.

00:04:49.792 --> 00:04:53.536
We prefer a single story to tons of data.

00:04:54.752 --> 00:04:57.768
Now, stories are powerful,
they're vivid, they bring it to life.

00:04:57.792 --> 00:05:00.014
They tell you to start
every talk with a story.

00:05:00.038 --> 00:05:01.188
I did.

00:05:01.696 --> 00:05:06.450
But a single story
is meaningless and misleading

00:05:06.474 --> 00:05:09.323
unless it's backed up by large-scale data.

00:05:11.236 --> 00:05:13.593
But even if we had large-scale data,

00:05:13.617 --> 00:05:15.775
that might still not be enough.

00:05:16.260 --> 00:05:19.398
Because it could still be consistent
with rival theories.

00:05:20.136 --> 00:05:21.286
Let me explain.

00:05:22.072 --> 00:05:25.334
A classic study
by psychologist Peter Wason

00:05:25.358 --> 00:05:27.310
gives you a set of three numbers

00:05:27.334 --> 00:05:30.239
and asks you to think of the rule
that generated them.

00:05:30.585 --> 00:05:35.061
So if you're given two, four, six,

00:05:35.085 --> 00:05:36.235
what's the rule?

00:05:36.895 --> 00:05:40.114
Well, most people would think,
it's successive even numbers.

00:05:40.767 --> 00:05:42.282
How would you test it?

00:05:42.306 --> 00:05:45.568
Well, you'd propose other sets
of successive even numbers:

00:05:45.592 --> 00:05:48.910
4, 6, 8 or 12, 14, 16.

00:05:49.546 --> 00:05:52.346
And Peter would say these sets also work.

00:05:53.124 --> 00:05:55.688
But knowing that these sets also work,

00:05:55.712 --> 00:06:00.477
knowing that perhaps hundreds of sets
of successive even numbers also work,

00:06:00.501 --> 00:06:01.849
tells you nothing.

00:06:02.572 --> 00:06:05.930
Because this is still consistent
with rival theories.

00:06:06.889 --> 00:06:10.094
Perhaps the rule
is any three even numbers.

00:06:11.000 --> 00:06:13.133
Or any three increasing numbers.

00:06:14.365 --> 00:06:17.253
And that's the third example
of confirmation bias:

00:06:17.277 --> 00:06:20.966
accepting data as evidence,

00:06:20.990 --> 00:06:23.990
even if it's consistent
with rival theories.

00:06:24.704 --> 00:06:27.656
Data is just a collection of facts.

00:06:28.402 --> 00:06:33.325
Evidence is data that supports
one theory and rules out others.

00:06:34.665 --> 00:06:37.148
So the best way to support your theory

00:06:37.172 --> 00:06:41.102
is actually to try to disprove it,
to play devil's advocate.

00:06:41.466 --> 00:06:46.184
So test something, like 4, 12, 26.

00:06:46.938 --> 00:06:50.621
If you got a yes to that,
that would disprove your theory

00:06:50.645 --> 00:06:52.581
of successive even numbers.

00:06:53.232 --> 00:06:55.248
Yet this test is powerful,

00:06:55.272 --> 00:07:00.117
because if you got a no, it would rule out
"any three even numbers"

00:07:00.141 --> 00:07:01.853
and "any three increasing numbers."

00:07:01.877 --> 00:07:05.218
It would rule out the rival theories,
but not rule out yours.

00:07:05.968 --> 00:07:10.762
But most people are too afraid
of testing the 4, 12, 26,

00:07:10.786 --> 00:07:14.949
because they don't want to get a yes
and prove their pet theory to be wrong.

00:07:16.727 --> 00:07:22.403
Confirmation bias is not only
about failing to search for new data,

00:07:22.427 --> 00:07:25.500
but it's also about misinterpreting
data once you receive it.

00:07:26.339 --> 00:07:29.887
And this applies outside the lab
to important, real-world problems.

00:07:29.911 --> 00:07:33.220
Indeed, Thomas Edison famously said,

00:07:33.244 --> 00:07:35.132
"I have not failed,

00:07:35.156 --> 00:07:39.344
I have found 10,000 ways that won't work."

00:07:40.281 --> 00:07:42.908
Finding out that you're wrong

00:07:42.932 --> 00:07:45.665
is the only way to find out what's right.

00:07:46.654 --> 00:07:49.600
Say you're a university
admissions director

00:07:49.624 --> 00:07:52.187
and your theory is that only
students with good grades

00:07:52.211 --> 00:07:53.974
from rich families do well.

00:07:54.339 --> 00:07:56.529
So you only let in such students.

00:07:56.553 --> 00:07:57.703
And they do well.

00:07:58.482 --> 00:08:01.254
But that's also consistent
with the rival theory.

00:08:01.593 --> 00:08:04.340
Perhaps all students
with good grades do well,

00:08:04.364 --> 00:08:05.545
rich or poor.

00:08:06.307 --> 00:08:10.037
But you never test that theory
because you never let in poor students

00:08:10.061 --> 00:08:12.861
because you don't want to be proven wrong.

00:08:14.577 --> 00:08:16.434
So, what have we learned?

00:08:17.315 --> 00:08:20.875
A story is not fact,
because it may not be true.

00:08:21.498 --> 00:08:23.585
A fact is not data,

00:08:23.609 --> 00:08:27.648
it may not be representative
if it's only one data point.

00:08:28.680 --> 00:08:31.029
And data is not evidence --

00:08:31.053 --> 00:08:34.731
it may not be supportive
if it's consistent with rival theories.

00:08:36.146 --> 00:08:38.423
So, what do you do?

00:08:39.464 --> 00:08:42.146
When you're at
the inflection points of life,

00:08:42.170 --> 00:08:44.736
deciding on a strategy for your business,

00:08:44.760 --> 00:08:47.371
a parenting technique for your child

00:08:47.395 --> 00:08:49.823
or a regimen for your health,

00:08:49.847 --> 00:08:53.386
how do you ensure
that you don't have a story

00:08:53.410 --> 00:08:54.878
but you have evidence?

00:08:56.268 --> 00:08:57.887
Let me give you three tips.

00:08:58.641 --> 00:09:02.625
The first is to actively seek
other viewpoints.

00:09:02.649 --> 00:09:06.243
Read and listen to people
you flagrantly disagree with.

00:09:06.267 --> 00:09:09.755
Ninety percent of what they say
may be wrong, in your view.

00:09:10.728 --> 00:09:12.861
But what if 10 percent is right?

00:09:13.851 --> 00:09:15.470
As Aristotle said,

00:09:15.494 --> 00:09:17.708
"The mark of an educated man

00:09:17.732 --> 00:09:21.129
is the ability to entertain a thought

00:09:21.153 --> 00:09:23.486
without necessarily accepting it."

00:09:24.649 --> 00:09:26.903
Surround yourself with people
who challenge you,

00:09:26.917 --> 00:09:30.616
and create a culture
that actively encourages dissent.

00:09:31.347 --> 00:09:33.665
Some banks suffered from groupthink,

00:09:33.689 --> 00:09:37.998
where staff were too afraid to challenge
management's lending decisions,

00:09:38.022 --> 00:09:40.488
contributing to the financial crisis.

00:09:41.029 --> 00:09:45.228
In a meeting, appoint someone
to be devil's advocate

00:09:45.252 --> 00:09:46.894
against your pet idea.

00:09:47.720 --> 00:09:50.291
And don't just hear another viewpoint --

00:09:50.315 --> 00:09:52.491
listen to it, as well.

00:09:53.389 --> 00:09:55.793
As psychologist Stephen Covey said,

00:09:55.817 --> 00:09:59.214
"Listen with the intent to understand,

00:09:59.238 --> 00:10:00.904
not the intent to reply."

00:10:01.642 --> 00:10:05.134
A dissenting viewpoint
is something to learn from

00:10:05.158 --> 00:10:06.706
not to argue against.

00:10:07.690 --> 00:10:11.556
Which takes us to the other
forgotten terms in Bayesian inference.

00:10:12.198 --> 00:10:14.522
Because data allows you to learn,

00:10:14.546 --> 00:10:18.061
but learning is only relative
to a starting point.

00:10:18.085 --> 00:10:23.801
If you started with complete certainty
that your pet theory must be true,

00:10:23.825 --> 00:10:25.722
then your view won't change --

00:10:25.746 --> 00:10:28.212
regardless of what data you see.

00:10:28.641 --> 00:10:33.032
Only if you are truly open
to the possibility of being wrong

00:10:33.056 --> 00:10:34.323
can you ever learn.

00:10:35.580 --> 00:10:37.675
As Leo Tolstoy wrote,

00:10:37.699 --> 00:10:39.881
"The most difficult subjects

00:10:39.905 --> 00:10:43.040
can be explained to the most
slow-witted man

00:10:43.064 --> 00:10:45.817
if he has not formed
any idea of them already.

00:10:46.365 --> 00:10:48.238
But the simplest thing

00:10:48.262 --> 00:10:51.333
cannot be made clear
to the most intelligent man

00:10:51.357 --> 00:10:54.691
if he is firmly persuaded
that he knows already."

00:10:56.500 --> 00:11:00.243
Tip number two is "listen to experts."

00:11:01.040 --> 00:11:04.532
Now, that's perhaps the most
unpopular advice that I could give you.

00:11:04.556 --> 00:11:05.776
(Laughter)

00:11:05.800 --> 00:11:10.538
British politician Michael Gove
famously said that people in this country

00:11:10.562 --> 00:11:12.838
have had enough of experts.

00:11:13.696 --> 00:11:17.204
A recent poll showed that more people
would trust their hairdresser --

00:11:17.228 --> 00:11:19.513
(Laughter)

00:11:19.537 --> 00:11:21.370
or the man on the street

00:11:21.394 --> 00:11:25.699
than they would leaders of businesses,
the health service and even charities.

00:11:26.227 --> 00:11:30.204
So we respect a teeth-whitening formula
discovered by a mom,

00:11:30.228 --> 00:11:33.426
or we listen to an actress's view
on vaccination.

00:11:33.450 --> 00:11:36.315
We like people who tell it like it is,
who go with their gut,

00:11:36.339 --> 00:11:38.139
and we call them authentic.

00:11:38.847 --> 00:11:42.061
But gut feel can only get you so far.

00:11:42.736 --> 00:11:47.172
Gut feel would tell you never to give
water to a baby with diarrhea,

00:11:47.196 --> 00:11:49.514
because it would just
flow out the other end.

00:11:49.538 --> 00:11:52.116
Expertise tells you otherwise.

00:11:53.149 --> 00:11:56.577
You'd never trust your surgery
to the man on the street.

00:11:56.887 --> 00:12:00.474
You'd want an expert
who spent years doing surgery

00:12:00.498 --> 00:12:02.498
and knows the best techniques.

00:12:03.514 --> 00:12:06.647
But that should apply
to every major decision.

00:12:07.255 --> 00:12:11.811
Politics, business, health advice

00:12:11.835 --> 00:12:14.731
require expertise, just like surgery.

00:12:16.474 --> 00:12:20.013
So then, why are experts so mistrusted?

00:12:20.981 --> 00:12:24.220
Well, one reason
is they're seen as out of touch.

00:12:24.244 --> 00:12:28.334
A millionaire CEO couldn't possibly
speak for the man on the street.

00:12:29.455 --> 00:12:33.014
But true expertise is found on evidence.

00:12:33.447 --> 00:12:36.352
And evidence stands up
for the man on the street

00:12:36.376 --> 00:12:37.909
and against the elites.

00:12:38.456 --> 00:12:41.123
Because evidence forces you to prove it.

00:12:41.774 --> 00:12:46.195
Evidence prevents the elites
from imposing their own view

00:12:46.219 --> 00:12:47.369
without proof.

00:12:49.006 --> 00:12:51.077
A second reason
why experts are not trusted

00:12:51.101 --> 00:12:54.188
is that different experts
say different things.

00:12:54.212 --> 00:12:58.688
For every expert who claimed that leaving
the EU would be bad for Britain,

00:12:58.712 --> 00:13:01.141
another expert claimed it would be good.

00:13:01.165 --> 00:13:04.932
Half of these so-called experts
will be wrong.

00:13:05.774 --> 00:13:10.017
And I have to admit that most papers
written by experts are wrong.

00:13:10.520 --> 00:13:14.025
Or at best, make claims that
the evidence doesn't actually support.

00:13:14.990 --> 00:13:18.123
So we can't just take
an expert's word for it.

00:13:18.776 --> 00:13:24.810
In November 2016, a study
on executive pay hit national headlines.

00:13:25.240 --> 00:13:28.130
Even though none of the newspapers
who covered the study

00:13:28.154 --> 00:13:29.754
had even seen the study.

00:13:30.685 --> 00:13:32.218
It wasn't even out yet.

00:13:32.708 --> 00:13:34.912
They just took the author's word for it,

00:13:35.768 --> 00:13:37.168
just like with Belle.

00:13:38.093 --> 00:13:40.529
Nor does it mean that we can
just handpick any study

00:13:40.553 --> 00:13:42.664
that happens to support our viewpoint --

00:13:42.688 --> 00:13:44.791
that would, again, be confirmation bias.

00:13:44.815 --> 00:13:47.370
Nor does it mean
that if seven studies show A

00:13:47.394 --> 00:13:49.062
and three show B,

00:13:49.086 --> 00:13:50.569
that A must be true.

00:13:51.109 --> 00:13:53.768
What matters is the quality,

00:13:53.792 --> 00:13:56.609
and not the quantity of expertise.

00:13:57.879 --> 00:13:59.679
So we should do two things.

00:14:00.434 --> 00:14:05.012
First, we should critically examine
the credentials of the authors.

00:14:05.807 --> 00:14:09.950
Just like you'd critically examine
the credentials of a potential surgeon.

00:14:10.347 --> 00:14:13.553
Are they truly experts in the matter,

00:14:13.577 --> 00:14:15.844
or do they have a vested interest?

00:14:16.768 --> 00:14:19.291
Second, we should pay particular attention

00:14:19.315 --> 00:14:23.204
to papers published
in the top academic journals.

00:14:24.038 --> 00:14:27.899
Now, academics are often accused
of being detached from the real world.

00:14:28.585 --> 00:14:32.315
But this detachment gives you
years to spend on a study.

00:14:32.339 --> 00:14:34.244
To really nail down a result,

00:14:34.268 --> 00:14:36.283
to rule out those rival theories,

00:14:36.307 --> 00:14:39.441
and to distinguish correlation
from causation.

00:14:40.172 --> 00:14:43.649
And academic journals involve peer review,

00:14:43.673 --> 00:14:45.967
where a paper is rigorously scrutinized

00:14:45.991 --> 00:14:47.410
(Laughter)

00:14:47.434 --> 00:14:49.368
by the world's leading minds.

00:14:50.434 --> 00:14:52.990
The better the journal,
the higher the standard.

00:14:53.014 --> 00:14:58.162
The most elite journals
reject 95 percent of papers.

00:14:59.434 --> 00:15:02.767
Now, academic evidence is not everything.

00:15:03.109 --> 00:15:05.776
Real-world experience is critical, also.

00:15:06.465 --> 00:15:09.865
And peer review is not perfect,
mistakes are made.

00:15:10.530 --> 00:15:12.593
But it's better to go
with something checked

00:15:12.617 --> 00:15:14.284
than something unchecked.

00:15:14.696 --> 00:15:17.895
If we latch onto a study
because we like the findings,

00:15:17.919 --> 00:15:21.807
without considering who it's by
or whether it's even been vetted,

00:15:21.831 --> 00:15:25.458
there is a massive chance
that that study is misleading.

00:15:26.894 --> 00:15:29.474
And those of us who claim to be experts

00:15:29.498 --> 00:15:32.751
should recognize the limitations
of our analysis.

00:15:33.244 --> 00:15:37.807
Very rarely is it possible to prove
or predict something with certainty,

00:15:38.292 --> 00:15:42.661
yet it's so tempting to make
a sweeping, unqualified statement.

00:15:43.069 --> 00:15:47.413
It's easier to turn into a headline
or to be tweeted in 140 characters.

00:15:48.417 --> 00:15:51.559
But even evidence may not be proof.

00:15:52.481 --> 00:15:56.691
It may not be universal,
it may not apply in every setting.

00:15:57.252 --> 00:16:02.172
So don't say, "Red wine
causes longer life,"

00:16:02.196 --> 00:16:06.878
when the evidence is only that red wine
is correlated with longer life.

00:16:07.379 --> 00:16:10.149
And only then in people
who exercise as well.

00:16:11.868 --> 00:16:15.834
Tip number three
is "pause before sharing anything."

00:16:16.907 --> 00:16:20.371
The Hippocratic oath says,
"First, do no harm."

00:16:21.046 --> 00:16:24.180
What we share is potentially contagious,

00:16:24.204 --> 00:16:27.887
so be very careful about what we spread.

00:16:28.632 --> 00:16:31.585
Our goal should not be
to get likes or retweets.

00:16:31.609 --> 00:16:35.594
Otherwise, we only share the consensus;
we don't challenge anyone's thinking.

00:16:36.085 --> 00:16:38.990
Otherwise, we only share what sounds good,

00:16:39.014 --> 00:16:41.414
regardless of whether it's evidence.

00:16:42.188 --> 00:16:44.654
Instead, we should ask the following:

00:16:45.572 --> 00:16:47.707
If it's a story, is it true?

00:16:47.731 --> 00:16:50.596
If it's true, is it backed up
by large-scale evidence?

00:16:50.620 --> 00:16:53.215
If it is, who is it by,
what are their credentials?

00:16:53.239 --> 00:16:55.995
Is it published,
how rigorous is the journal?

00:16:56.733 --> 00:16:59.050
And ask yourself
the million-dollar question:

00:16:59.980 --> 00:17:04.003
If the same study was written by the same
authors with the same credentials

00:17:05.130 --> 00:17:06.717
but found the opposite results,

00:17:07.608 --> 00:17:11.302
would you still be willing
to believe it and to share it?

00:17:13.442 --> 00:17:15.688
Treating any problem --

00:17:15.712 --> 00:17:19.504
a nation's economic problem
or an individual's health problem,

00:17:19.528 --> 00:17:20.678
is difficult.

00:17:21.242 --> 00:17:25.625
So we must ensure that we have
the very best evidence to guide us.

00:17:26.188 --> 00:17:28.869
Only if it's true can it be fact.

00:17:29.601 --> 00:17:32.382
Only if it's representative
can it be data.

00:17:33.128 --> 00:17:36.293
Only if it's supportive
can it be evidence.

00:17:36.317 --> 00:17:41.484
And only with evidence
can we move from a post-truth world

00:17:41.508 --> 00:17:43.091
to a pro-truth world.

00:17:44.183 --> 00:17:45.517
Thank you very much.

00:17:45.541 --> 00:17:46.691
(Applause)

