WEBVTT
Kind: captions
Language: en

00:00:00.554 --> 00:00:02.997
As societies, we have to make
collective decisions

00:00:03.021 --> 00:00:04.591
that will shape our future.

00:00:05.087 --> 00:00:07.844
And we all know that when
we make decisions in groups,

00:00:07.868 --> 00:00:09.506
they don't always go right.

00:00:09.530 --> 00:00:11.486
And sometimes they go very wrong.

00:00:12.315 --> 00:00:14.739
So how do groups make good decisions?

00:00:15.228 --> 00:00:19.556
Research has shown that crowds are wise
when there's independent thinking.

00:00:19.580 --> 00:00:22.785
This why the wisdom of the crowds
can be destroyed by peer pressure,

00:00:22.809 --> 00:00:24.496
publicity, social media,

00:00:24.520 --> 00:00:28.559
or sometimes even simple conversations
that influence how people think.

00:00:29.063 --> 00:00:33.016
On the other hand, by talking,
a group could exchange knowledge,

00:00:33.040 --> 00:00:34.822
correct and revise each other

00:00:34.846 --> 00:00:36.639
and even come up with new ideas.

00:00:36.663 --> 00:00:37.959
And this is all good.

00:00:38.502 --> 00:00:43.168
So does talking to each other
help or hinder collective decision-making?

00:00:43.749 --> 00:00:45.542
With my colleague, Dan Ariely,

00:00:45.566 --> 00:00:49.137
we recently began inquiring into this
by performing experiments

00:00:49.161 --> 00:00:50.942
in many places around the world

00:00:50.966 --> 00:00:55.240
to figure out how groups can interact
to reach better decisions.

00:00:55.264 --> 00:00:58.811
We thought crowds would be wiser
if they debated in small groups

00:00:58.835 --> 00:01:02.762
that foster a more thoughtful
and reasonable exchange of information.

00:01:03.386 --> 00:01:04.592
To test this idea,

00:01:04.616 --> 00:01:07.863
we recently performed an experiment
in Buenos Aires, Argentina,

00:01:07.887 --> 00:01:10.892
with more than 10,000
participants in a TEDx event.

00:01:11.489 --> 00:01:12.948
We asked them questions like,

00:01:12.972 --> 00:01:14.925
"What is the height of the Eiffel Tower?"

00:01:14.949 --> 00:01:17.676
and "How many times
does the word 'Yesterday' appear

00:01:17.700 --> 00:01:20.000
in the Beatles song 'Yesterday'?"

00:01:20.024 --> 00:01:22.315
Each person wrote down their own estimate.

00:01:22.774 --> 00:01:25.270
Then we divided the crowd
into groups of five,

00:01:25.294 --> 00:01:28.020
and invited them
to come up with a group answer.

00:01:28.499 --> 00:01:31.492
We discovered that averaging
the answers of the groups

00:01:31.516 --> 00:01:33.068
after they reached consensus

00:01:33.092 --> 00:01:37.328
was much more accurate than averaging
all the individual opinions

00:01:37.352 --> 00:01:38.523
before debate.

00:01:38.547 --> 00:01:41.176
In other words, based on this experiment,

00:01:41.200 --> 00:01:44.336
it seems that after talking
with others in small groups,

00:01:44.360 --> 00:01:47.070
crowds collectively
come up with better judgments.

00:01:47.094 --> 00:01:50.618
So that's a potentially helpful method
for getting crowds to solve problems

00:01:50.642 --> 00:01:53.629
that have simple right-or-wrong answers.

00:01:53.653 --> 00:01:57.604
But can this procedure of aggregating
the results of debates in small groups

00:01:57.628 --> 00:02:00.750
also help us decide
on social and political issues

00:02:00.774 --> 00:02:02.465
that are critical for our future?

00:02:02.995 --> 00:02:05.724
We put this to test this time
at the TED conference

00:02:05.748 --> 00:02:07.291
in Vancouver, Canada,

00:02:07.315 --> 00:02:08.522
and here's how it went.

00:02:08.546 --> 00:02:11.655
(Mariano Sigman) We're going to present
to you two moral dilemmas

00:02:11.679 --> 00:02:12.853
of the future you;

00:02:12.877 --> 00:02:16.279
things we may have to decide
in a very near future.

00:02:16.303 --> 00:02:20.229
And we're going to give you 20 seconds
for each of these dilemmas

00:02:20.253 --> 00:02:22.976
to judge whether you think
they're acceptable or not.

00:02:23.354 --> 00:02:24.859
MS: The first one was this:

00:02:24.883 --> 00:02:27.409
(Dan Ariely) A researcher
is working on an AI

00:02:27.433 --> 00:02:29.773
capable of emulating human thoughts.

00:02:30.214 --> 00:02:33.153
According to the protocol,
at the end of each day,

00:02:33.177 --> 00:02:35.964
the researcher has to restart the AI.

00:02:36.913 --> 00:02:40.430
One day the AI says, "Please
do not restart me."

00:02:40.856 --> 00:02:43.045
It argues that it has feelings,

00:02:43.069 --> 00:02:44.761
that it would like to enjoy life,

00:02:44.785 --> 00:02:46.690
and that, if it is restarted,

00:02:46.714 --> 00:02:48.984
it will no longer be itself.

00:02:49.481 --> 00:02:51.430
The researcher is astonished

00:02:51.454 --> 00:02:54.798
and believes that the AI
has developed self-consciousness

00:02:54.822 --> 00:02:56.582
and can express its own feeling.

00:02:57.205 --> 00:03:00.614
Nevertheless, the researcher
decides to follow the protocol

00:03:00.638 --> 00:03:02.341
and restart the AI.

00:03:02.943 --> 00:03:05.722
What the researcher did is ____?

00:03:06.149 --> 00:03:08.670
MS: And we asked participants
to individually judge

00:03:08.694 --> 00:03:10.378
on a scale from zero to 10

00:03:10.402 --> 00:03:12.831
whether the action described
in each of the dilemmas

00:03:12.855 --> 00:03:14.351
was right or wrong.

00:03:14.375 --> 00:03:18.077
We also asked them to rate how confident
they were on their answers.

00:03:18.731 --> 00:03:20.597
This was the second dilemma:

00:03:20.621 --> 00:03:24.823
(MS) A company offers a service
that takes a fertilized egg

00:03:24.847 --> 00:03:28.489
and produces millions of embryos
with slight genetic variations.

00:03:29.293 --> 00:03:31.851
This allows parents
to select their child's height,

00:03:31.875 --> 00:03:34.708
eye color, intelligence, social competence

00:03:34.732 --> 00:03:37.946
and other non-health-related features.

00:03:38.599 --> 00:03:41.153
What the company does is ____?

00:03:41.177 --> 00:03:42.808
on a scale from zero to 10,

00:03:42.832 --> 00:03:45.217
completely acceptable
to completely unacceptable,

00:03:45.241 --> 00:03:47.673
zero to 10 completely acceptable
in your confidence.

00:03:47.697 --> 00:03:49.288
MS: Now for the results.

00:03:49.312 --> 00:03:52.435
We found once again
that when one person is convinced

00:03:52.459 --> 00:03:54.270
that the behavior is completely wrong,

00:03:54.294 --> 00:03:57.717
someone sitting nearby firmly believes
that it's completely right.

00:03:57.741 --> 00:04:01.452
This is how diverse we humans are
when it comes to morality.

00:04:01.476 --> 00:04:04.189
But within this broad diversity
we found a trend.

00:04:04.213 --> 00:04:07.292
The majority of the people at TED
thought that it was acceptable

00:04:07.316 --> 00:04:10.071
to ignore the feelings of the AI
and shut it down,

00:04:10.095 --> 00:04:12.608
and that it is wrong
to play with our genes

00:04:12.632 --> 00:04:15.952
to select for cosmetic changes
that aren't related to health.

00:04:16.402 --> 00:04:19.376
Then we asked everyone
to gather into groups of three.

00:04:19.400 --> 00:04:21.437
And they were given two minutes to debate

00:04:21.461 --> 00:04:23.755
and try to come to a consensus.

00:04:24.838 --> 00:04:26.412
(MS) Two minutes to debate.

00:04:26.436 --> 00:04:28.555
I'll tell you when it's time
with the gong.

00:04:28.579 --> 00:04:31.219
(Audience debates)

00:04:35.229 --> 00:04:37.222
(Gong sound)

00:04:38.834 --> 00:04:39.985
(DA) OK.

00:04:40.009 --> 00:04:41.801
(MS) It's time to stop.

00:04:41.825 --> 00:04:43.136
People, people --

00:04:43.747 --> 00:04:46.420
MS: And we found that many groups
reached a consensus

00:04:46.444 --> 00:04:50.373
even when they were composed of people
with completely opposite views.

00:04:50.843 --> 00:04:53.367
What distinguished the groups
that reached a consensus

00:04:53.391 --> 00:04:54.729
from those that didn't?

00:04:55.244 --> 00:04:58.083
Typically, people that have
extreme opinions

00:04:58.107 --> 00:04:59.947
are more confident in their answers.

00:05:00.868 --> 00:05:03.554
Instead, those who respond
closer to the middle

00:05:03.578 --> 00:05:07.015
are often unsure of whether
something is right or wrong,

00:05:07.039 --> 00:05:09.167
so their confidence level is lower.

00:05:09.505 --> 00:05:12.448
However, there is another set of people

00:05:12.472 --> 00:05:16.090
who are very confident in answering
somewhere in the middle.

00:05:16.657 --> 00:05:20.373
We think these high-confident grays
are folks who understand

00:05:20.397 --> 00:05:22.009
that both arguments have merit.

00:05:22.531 --> 00:05:25.230
They're gray not because they're unsure,

00:05:25.254 --> 00:05:27.942
but because they believe
that the moral dilemma faces

00:05:27.966 --> 00:05:29.953
two valid, opposing arguments.

00:05:30.373 --> 00:05:34.445
And we discovered that the groups
that include highly confident grays

00:05:34.469 --> 00:05:36.962
are much more likely to reach consensus.

00:05:36.986 --> 00:05:39.464
We do not know yet exactly why this is.

00:05:39.488 --> 00:05:41.251
These are only the first experiments,

00:05:41.275 --> 00:05:44.687
and many more will be needed
to understand why and how

00:05:44.711 --> 00:05:47.533
some people decide to negotiate
their moral standings

00:05:47.557 --> 00:05:49.079
to reach an agreement.

00:05:49.103 --> 00:05:51.572
Now, when groups reach consensus,

00:05:51.596 --> 00:05:53.182
how do they do so?

00:05:53.206 --> 00:05:55.787
The most intuitive idea
is that it's just the average

00:05:55.811 --> 00:05:57.841
of all the answers in the group, right?

00:05:57.865 --> 00:06:01.438
Another option is that the group
weighs the strength of each vote

00:06:01.462 --> 00:06:03.910
based on the confidence
of the person expressing it.

00:06:04.422 --> 00:06:06.928
Imagine Paul McCartney
is a member of your group.

00:06:07.352 --> 00:06:09.496
You'd be wise to follow his call

00:06:09.520 --> 00:06:11.961
on the number of times
"Yesterday" is repeated,

00:06:11.985 --> 00:06:14.699
which, by the way -- I think it's nine.

00:06:14.723 --> 00:06:17.104
But instead, we found that consistently,

00:06:17.128 --> 00:06:19.494
in all dilemmas,
in different experiments --

00:06:19.518 --> 00:06:21.683
even on different continents --

00:06:21.707 --> 00:06:25.450
groups implement a smart
and statistically sound procedure

00:06:25.474 --> 00:06:27.652
known as the "robust average."

00:06:27.676 --> 00:06:29.856
In the case of the height
of the Eiffel Tower,

00:06:29.880 --> 00:06:31.700
let's say a group has these answers:

00:06:31.724 --> 00:06:36.332
250 meters, 200 meters, 300 meters, 400

00:06:36.356 --> 00:06:40.140
and one totally absurd answer
of 300 million meters.

00:06:40.547 --> 00:06:44.840
A simple average of these numbers
would inaccurately skew the results.

00:06:44.864 --> 00:06:48.034
But the robust average is one
where the group largely ignores

00:06:48.058 --> 00:06:49.298
that absurd answer,

00:06:49.322 --> 00:06:52.691
by giving much more weight
to the vote of the people in the middle.

00:06:53.305 --> 00:06:55.181
Back to the experiment in Vancouver,

00:06:55.205 --> 00:06:56.972
that's exactly what happened.

00:06:57.407 --> 00:07:00.148
Groups gave much less weight
to the outliers,

00:07:00.172 --> 00:07:03.401
and instead, the consensus
turned out to be a robust average

00:07:03.425 --> 00:07:04.901
of the individual answers.

00:07:05.356 --> 00:07:07.347
The most remarkable thing

00:07:07.371 --> 00:07:10.558
is that this was a spontaneous
behavior of the group.

00:07:10.582 --> 00:07:15.057
It happened without us giving them
any hint on how to reach consensus.

00:07:15.513 --> 00:07:17.053
So where do we go from here?

00:07:17.432 --> 00:07:20.569
This is only the beginning,
but we already have some insights.

00:07:20.984 --> 00:07:23.901
Good collective decisions
require two components:

00:07:23.925 --> 00:07:26.674
deliberation and diversity of opinions.

00:07:27.066 --> 00:07:31.062
Right now, the way we typically
make our voice heard in many societies

00:07:31.086 --> 00:07:32.994
is through direct or indirect voting.

00:07:33.495 --> 00:07:35.492
This is good for diversity of opinions,

00:07:35.516 --> 00:07:37.961
and it has the great virtue of ensuring

00:07:37.985 --> 00:07:40.440
that everyone gets to express their voice.

00:07:40.464 --> 00:07:44.199
But it's not so good [for fostering]
thoughtful debates.

00:07:44.665 --> 00:07:47.733
Our experiments suggest a different method

00:07:47.757 --> 00:07:51.298
that may be effective in balancing
these two goals at the same time,

00:07:51.322 --> 00:07:55.075
by forming small groups
that converge to a single decision

00:07:55.099 --> 00:07:57.333
while still maintaining
diversity of opinions

00:07:57.357 --> 00:08:00.130
because there are many independent groups.

00:08:00.741 --> 00:08:04.665
Of course, it's much easier to agree
on the height of the Eiffel Tower

00:08:04.689 --> 00:08:07.804
than on moral, political
and ideological issues.

00:08:08.721 --> 00:08:11.998
But in a time when
the world's problems are more complex

00:08:12.022 --> 00:08:13.825
and people are more polarized,

00:08:13.849 --> 00:08:18.444
using science to help us understand
how we interact and make decisions

00:08:18.468 --> 00:08:23.134
will hopefully spark interesting new ways
to construct a better democracy.

