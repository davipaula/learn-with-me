WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Ivana Korom
Reviewer: Joanna Pietrulewicz

00:00:13.760 --> 00:00:18.440
I consider myself one part artist
and one part designer.

00:00:18.480 --> 00:00:21.640
And I work at an artificial
intelligence research lab.

00:00:22.720 --> 00:00:24.416
We're trying to create technology

00:00:24.440 --> 00:00:27.736
that you'll want to interact with
in the far future.

00:00:27.760 --> 00:00:32.400
Not just six months from now,
but try years and decades from now.

00:00:33.120 --> 00:00:34.736
And we're taking a moonshot

00:00:34.760 --> 00:00:37.216
that we'll want to be
interacting with computers

00:00:37.240 --> 00:00:39.360
in deeply emotional ways.

00:00:40.280 --> 00:00:41.736
So in order to do that,

00:00:41.760 --> 00:00:46.240
the technology has to be
just as much human as it is artificial.

00:00:46.920 --> 00:00:49.176
It has to get you.

00:00:49.200 --> 00:00:52.536
You know, like that inside joke
that'll have you and your best friend

00:00:52.560 --> 00:00:54.496
on the floor, cracking up.

00:00:54.520 --> 00:00:59.080
Or that look of disappointment
that you can just smell from miles away.

00:01:00.560 --> 00:01:06.600
I view art as the gateway to help us
bridge this gap between human and machine:

00:01:07.280 --> 00:01:10.416
to figure out what it means
to get each other

00:01:10.440 --> 00:01:13.200
so that we can train AI to get us.

00:01:13.920 --> 00:01:17.736
See, to me, art is a way
to put tangible experiences

00:01:17.760 --> 00:01:21.000
to intangible ideas,
feelings and emotions.

00:01:21.800 --> 00:01:24.400
And I think it's one
of the most human things about us.

00:01:25.480 --> 00:01:28.416
See, we're a complicated
and complex bunch.

00:01:28.440 --> 00:01:31.576
We have what feels like
an infinite range of emotions,

00:01:31.600 --> 00:01:34.096
and to top it off, we're all different.

00:01:34.120 --> 00:01:36.416
We have different family backgrounds,

00:01:36.440 --> 00:01:39.520
different experiences
and different psychologies.

00:01:40.240 --> 00:01:42.960
And this is what makes life
really interesting.

00:01:43.440 --> 00:01:46.936
But this is also what makes
working on intelligent technology

00:01:46.960 --> 00:01:48.560
extremely difficult.

00:01:49.640 --> 00:01:53.096
And right now, AI research, well,

00:01:53.120 --> 00:01:55.136
it's a bit lopsided on the tech side.

00:01:55.160 --> 00:01:57.296
And that makes a lot of sense.

00:01:57.320 --> 00:01:59.776
See, for every
qualitative thing about us --

00:01:59.800 --> 00:02:04.256
you know, those parts of us that are
emotional, dynamic and subjective --

00:02:04.280 --> 00:02:07.416
we have to convert it
to a quantitative metric:

00:02:07.440 --> 00:02:11.800
something that can be represented
with facts, figures and computer code.

00:02:13.000 --> 00:02:16.376
The issue is, there are
many qualitative things

00:02:16.400 --> 00:02:18.360
that we just can't put our finger on.

00:02:20.400 --> 00:02:23.600
So, think about hearing
your favorite song for the first time.

00:02:25.200 --> 00:02:26.400
What were you doing?

00:02:28.000 --> 00:02:29.200
How did you feel?

00:02:30.720 --> 00:02:32.080
Did you get goosebumps?

00:02:33.240 --> 00:02:34.880
Or did you get fired up?

00:02:36.400 --> 00:02:37.600
Hard to describe, right?

00:02:38.800 --> 00:02:40.896
See, parts of us feel so simple,

00:02:40.920 --> 00:02:44.576
but under the surface,
there's really a ton of complexity.

00:02:44.600 --> 00:02:47.536
And translating
that complexity to machines

00:02:47.560 --> 00:02:50.416
is what makes them modern-day moonshots.

00:02:50.440 --> 00:02:54.616
And I'm not convinced that we can
answer these deeper questions

00:02:54.640 --> 00:02:56.120
with just ones and zeros alone.

00:02:57.120 --> 00:02:59.056
So, in the lab, I've been creating art

00:02:59.080 --> 00:03:01.536
as a way to help me
design better experiences

00:03:01.560 --> 00:03:03.656
for bleeding-edge technology.

00:03:03.680 --> 00:03:05.416
And it's been serving as a catalyst

00:03:05.440 --> 00:03:09.280
to beef up the more human ways
that computers can relate to us.

00:03:10.000 --> 00:03:12.696
Through art, we're tacking
some of the hardest questions,

00:03:12.720 --> 00:03:15.080
like what does it really mean to feel?

00:03:16.120 --> 00:03:20.200
Or how do we engage and know
how to be present with each other?

00:03:20.800 --> 00:03:24.800
And how does intuition
affect the way that we interact?

00:03:26.440 --> 00:03:28.496
So, take for example human emotion.

00:03:28.520 --> 00:03:31.776
Right now, computers can make sense
of our most basic ones,

00:03:31.800 --> 00:03:35.496
like joy, sadness,
anger, fear and disgust,

00:03:35.520 --> 00:03:38.520
by converting those
characteristics to math.

00:03:39.400 --> 00:03:41.936
But what about the more complex emotions?

00:03:41.960 --> 00:03:43.176
You know, those emotions

00:03:43.200 --> 00:03:45.576
that we have a hard time
describing to each other?

00:03:45.600 --> 00:03:47.040
Like nostalgia.

00:03:47.640 --> 00:03:51.576
So, to explore this, I created
a piece of art, an experience,

00:03:51.600 --> 00:03:53.696
that asked people to share a memory,

00:03:53.720 --> 00:03:55.856
and I teamed up with some data scientists

00:03:55.880 --> 00:03:59.456
to figure out how to take
an emotion that's so highly subjective

00:03:59.480 --> 00:04:02.680
and convert it into something
mathematically precise.

00:04:03.840 --> 00:04:05.976
So, we created what we call
a nostalgia score

00:04:06.000 --> 00:04:08.216
and it's the heart of this installation.

00:04:08.240 --> 00:04:11.296
To do that, the installation
asks you to share a story,

00:04:11.320 --> 00:04:14.576
the computer then analyzes it
for its simpler emotions,

00:04:14.600 --> 00:04:17.256
it checks for your tendency
to use past-tense wording

00:04:17.280 --> 00:04:20.616
and also looks for words
that we tend to associate with nostalgia,

00:04:20.640 --> 00:04:23.680
like "home," "childhood" and "the past."

00:04:24.760 --> 00:04:26.816
It then creates a nostalgia score

00:04:26.840 --> 00:04:29.576
to indicate how nostalgic your story is.

00:04:29.600 --> 00:04:33.736
And that score is the driving force
behind these light-based sculptures

00:04:33.760 --> 00:04:37.656
that serve as physical embodiments
of your contribution.

00:04:37.680 --> 00:04:40.896
And the higher the score,
the rosier the hue.

00:04:40.920 --> 00:04:44.856
You know, like looking at the world
through rose-colored glasses.

00:04:44.880 --> 00:04:47.496
So, when you see your score

00:04:47.520 --> 00:04:50.176
and the physical representation of it,

00:04:50.200 --> 00:04:53.136
sometimes you'd agree
and sometimes you wouldn't.

00:04:53.160 --> 00:04:56.640
It's as if it really understood
how that experience made you feel.

00:04:57.400 --> 00:04:59.616
But other times it gets tripped up

00:04:59.640 --> 00:05:02.200
and has you thinking
it doesn't understand you at all.

00:05:02.680 --> 00:05:04.576
But the piece really serves to show

00:05:04.600 --> 00:05:08.656
that if we have a hard time explaining
the emotions that we have to each other,

00:05:08.680 --> 00:05:11.040
how can we teach a computer
to make sense of them?

00:05:12.360 --> 00:05:15.936
So, even the more objective parts
about being human are hard to describe.

00:05:15.960 --> 00:05:17.200
Like, conversation.

00:05:17.880 --> 00:05:20.616
Have you ever really tried
to break down the steps?

00:05:20.640 --> 00:05:23.296
So think about sitting
with your friend at a coffee shop

00:05:23.320 --> 00:05:24.640
and just having small talk.

00:05:25.160 --> 00:05:26.880
How do you know when to take a turn?

00:05:27.440 --> 00:05:29.280
How do you know when to shift topics?

00:05:29.960 --> 00:05:32.680
And how do you even know
what topics to discuss?

00:05:33.560 --> 00:05:35.656
See, most of us
don't really think about it,

00:05:35.680 --> 00:05:37.336
because it's almost second nature.

00:05:37.360 --> 00:05:40.856
And when we get to know someone,
we learn more about what makes them tick,

00:05:40.880 --> 00:05:43.256
and then we learn
what topics we can discuss.

00:05:43.280 --> 00:05:46.936
But when it comes to teaching
AI systems how to interact with people,

00:05:46.960 --> 00:05:49.816
we have to teach them
step by step what to do.

00:05:49.840 --> 00:05:53.336
And right now, it feels clunky.

00:05:53.360 --> 00:05:57.496
If you've ever tried to talk
with Alexa, Siri or Google Assistant,

00:05:57.520 --> 00:06:01.720
you can tell that it or they
can still sound cold.

00:06:02.440 --> 00:06:04.096
And have you ever gotten annoyed

00:06:04.120 --> 00:06:06.376
when they didn't understand
what you were saying

00:06:06.400 --> 00:06:10.240
and you had to rephrase what you wanted
20 times just to play a song?

00:06:11.440 --> 00:06:16.336
Alright, to the credit of the designers,
realistic communication is really hard.

00:06:16.360 --> 00:06:18.496
And there's a whole branch of sociology,

00:06:18.520 --> 00:06:20.456
called conversation analysis,

00:06:20.480 --> 00:06:23.616
that tries to make blueprints
for different types of conversation.

00:06:23.640 --> 00:06:27.720
Types like customer service
or counseling, teaching and others.

00:06:28.880 --> 00:06:31.816
I've been collaborating
with a conversation analyst at the lab

00:06:31.840 --> 00:06:36.536
to try to help our AI systems
hold more human-sounding conversations.

00:06:36.560 --> 00:06:39.736
This way, when you have an interaction
with a chatbot on your phone

00:06:39.760 --> 00:06:41.616
or a voice-based system in the car,

00:06:41.640 --> 00:06:44.960
it sounds a little more human
and less cold and disjointed.

00:06:46.360 --> 00:06:47.696
So I created a piece of art

00:06:47.720 --> 00:06:50.536
that tries to highlight
the robotic, clunky interaction

00:06:50.560 --> 00:06:52.536
to help us understand, as designers,

00:06:52.560 --> 00:06:57.136
why it doesn't sound human yet
and, well, what we can do about it.

00:06:57.160 --> 00:06:58.616
The piece is called Bot to Bot

00:06:58.640 --> 00:07:01.576
and it puts one conversational
system against another

00:07:01.600 --> 00:07:04.136
and then exposes it to the general public.

00:07:04.160 --> 00:07:06.656
And what ends up happening
is that you get something

00:07:06.680 --> 00:07:08.576
that tries to mimic human conversation,

00:07:08.600 --> 00:07:10.496
but falls short.

00:07:10.520 --> 00:07:13.256
Sometimes it works and sometimes
it gets into these, well,

00:07:13.280 --> 00:07:14.816
loops of misunderstanding.

00:07:14.840 --> 00:07:17.936
So even though the machine-to-machine
conversation can make sense,

00:07:17.960 --> 00:07:19.976
grammatically and colloquially,

00:07:20.000 --> 00:07:23.216
it can still end up
feeling cold and robotic.

00:07:23.240 --> 00:07:27.256
And despite checking all the boxes,
the dialogue lacks soul

00:07:27.280 --> 00:07:30.416
and those one-off quirks
that make each of us who we are.

00:07:30.440 --> 00:07:32.496
So while it might be grammatically correct

00:07:32.520 --> 00:07:35.176
and uses all the right
hashtags and emojis,

00:07:35.200 --> 00:07:39.336
it can end up sounding mechanical
and, well, a little creepy.

00:07:39.360 --> 00:07:41.696
And we call this the uncanny valley.

00:07:41.720 --> 00:07:43.656
You know, that creepiness factor of tech

00:07:43.680 --> 00:07:46.536
where it's close to human
but just slightly off.

00:07:46.560 --> 00:07:48.016
And the piece will start being

00:07:48.040 --> 00:07:51.256
one way that we test
for the humanness of a conversation

00:07:51.280 --> 00:07:53.440
and the parts that get
lost in translation.

00:07:54.560 --> 00:07:57.416
So there are other things
that get lost in translation, too,

00:07:57.440 --> 00:07:59.056
like human intuition.

00:07:59.080 --> 00:08:01.856
Right now, computers
are gaining more autonomy.

00:08:01.880 --> 00:08:03.616
They can take care of things for us,

00:08:03.640 --> 00:08:06.816
like change the temperature
of our houses based on our preferences

00:08:06.840 --> 00:08:09.000
and even help us drive on the freeway.

00:08:09.560 --> 00:08:12.056
But there are things
that you and I do in person

00:08:12.080 --> 00:08:14.840
that are really difficult
to translate to AI.

00:08:15.440 --> 00:08:19.800
So think about the last time
that you saw an old classmate or coworker.

00:08:21.080 --> 00:08:23.560
Did you give them a hug
or go in for a handshake?

00:08:24.800 --> 00:08:26.296
You probably didn't think twice

00:08:26.320 --> 00:08:28.656
because you've had so many
built up experiences

00:08:28.680 --> 00:08:30.680
that had you do one or the other.

00:08:31.440 --> 00:08:34.896
And as an artist, I feel
that access to one's intuition,

00:08:34.920 --> 00:08:36.336
your unconscious knowing,

00:08:36.360 --> 00:08:39.416
is what helps us create amazing things.

00:08:39.440 --> 00:08:43.496
Big ideas, from that abstract,
nonlinear place in our consciousness

00:08:43.520 --> 00:08:46.480
that is the culmination
of all of our experiences.

00:08:47.840 --> 00:08:52.496
And if we want computers to relate to us
and help amplify our creative abilities,

00:08:52.520 --> 00:08:56.416
I feel that we'll need to start thinking
about how to make computers be intuitive.

00:08:56.440 --> 00:08:59.536
So I wanted to explore
how something like human intuition

00:08:59.560 --> 00:09:03.016
could be directly translated
to artificial intelligence.

00:09:03.040 --> 00:09:06.256
And I created a piece
that explores computer-based intuition

00:09:06.280 --> 00:09:07.600
in a physical space.

00:09:08.480 --> 00:09:10.176
The piece is called Wayfinding,

00:09:10.200 --> 00:09:14.136
and it's set up as a symbolic compass
that has four kinetic sculptures.

00:09:14.160 --> 00:09:16.216
Each one represents a direction,

00:09:16.240 --> 00:09:18.360
north, east, south and west.

00:09:19.080 --> 00:09:21.776
And there are sensors set up
on the top of each sculpture

00:09:21.800 --> 00:09:24.056
that capture how far away
you are from them.

00:09:24.080 --> 00:09:25.896
And the data that gets collected

00:09:25.920 --> 00:09:28.056
ends up changing the way
that sculptures move

00:09:28.080 --> 00:09:30.120
and the direction of the compass.

00:09:31.360 --> 00:09:35.016
The thing is, the piece doesn't work
like the automatic door sensor

00:09:35.040 --> 00:09:37.696
that just opens
when you walk in front of it.

00:09:37.720 --> 00:09:42.776
See, your contribution is only a part
of its collection of lived experiences.

00:09:42.800 --> 00:09:46.856
And all of those experiences
affect the way that it moves.

00:09:46.880 --> 00:09:48.616
So when you walk in front of it,

00:09:48.640 --> 00:09:50.616
it starts to use all of the data

00:09:50.640 --> 00:09:53.256
that it's captured
throughout its exhibition history --

00:09:53.280 --> 00:09:55.096
or its intuition --

00:09:55.120 --> 00:09:58.680
to mechanically respond to you
based on what it's learned from others.

00:09:59.480 --> 00:10:02.016
And what ends up happening
is that as participants

00:10:02.040 --> 00:10:04.856
we start to learn the level
of detail that we need

00:10:04.880 --> 00:10:06.896
in order to manage expectations

00:10:06.920 --> 00:10:09.696
from both humans and machines.

00:10:09.720 --> 00:10:13.336
We can almost see our intuition
being played out on the computer,

00:10:13.360 --> 00:10:16.960
picturing all of that data
being processed in our mind's eye.

00:10:17.560 --> 00:10:19.216
My hope is that this type of art

00:10:19.240 --> 00:10:21.656
will help us think differently
about intuition

00:10:21.680 --> 00:10:23.960
and how to apply that to AI in the future.

00:10:24.480 --> 00:10:28.416
So these are just a few examples
of how I'm using art to feed into my work

00:10:28.440 --> 00:10:31.536
as a designer and researcher
of artificial intelligence.

00:10:31.560 --> 00:10:35.056
And I see it as a crucial way
to move innovation forward.

00:10:35.080 --> 00:10:39.456
Because right now, there are
a lot of extremes when it comes to AI.

00:10:39.480 --> 00:10:42.296
Popular movies show it
as this destructive force

00:10:42.320 --> 00:10:45.376
while commercials
are showing it as a savior

00:10:45.400 --> 00:10:48.336
to solve some of the world's
most complex problems.

00:10:48.360 --> 00:10:50.896
But regardless of where you stand,

00:10:50.920 --> 00:10:53.096
it's hard to deny
that we're living in a world

00:10:53.120 --> 00:10:55.696
that's becoming more
and more digital by the second.

00:10:55.720 --> 00:11:00.320
Our lives revolve around our devices,
smart appliances and more.

00:11:01.400 --> 00:11:03.720
And I don't think
this will let up any time soon.

00:11:04.400 --> 00:11:08.136
So, I'm trying to embed
more humanness from the start.

00:11:08.160 --> 00:11:13.296
And I have a hunch that bringing art
into an AI research process

00:11:13.320 --> 00:11:15.216
is a way to do just that.

00:11:15.240 --> 00:11:16.456
Thank you.

00:11:16.480 --> 00:11:18.760
(Applause)

