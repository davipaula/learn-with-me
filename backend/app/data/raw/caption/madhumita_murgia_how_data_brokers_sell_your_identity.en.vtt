WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Riaki PoniÅ¡t
Reviewer: Ellen Maloney

00:00:22.290 --> 00:00:25.569
I'm a 26-year-old British Asian woman

00:00:25.579 --> 00:00:29.530
working in media and living 
in a South West postcode in London.

00:00:30.520 --> 00:00:34.030
I have previously lived
at two addresses in Sussex,

00:00:34.030 --> 00:00:36.880
and two others in North East London.

00:00:37.850 --> 00:00:41.869
While growing up, my family lived
in a detached house in Kent

00:00:41.869 --> 00:00:44.730
and took holidays to India every year.

00:00:46.350 --> 00:00:49.550
They mostly did their shopping
online at Ocado,

00:00:49.570 --> 00:00:52.920
gave money to charities
and read the Financial Times.

00:00:54.090 --> 00:00:58.080
Now, I live in a recently converted flat
with a private landlord,

00:00:58.100 --> 00:00:59.730
and I have a housemate.

00:01:00.320 --> 00:01:03.360
I'm interested in movies and startups,

00:01:03.360 --> 00:01:06.729
and I have taken five holidays
in the past 12 months,

00:01:06.729 --> 00:01:09.090
mostly to visit friends abroad.

00:01:09.760 --> 00:01:12.960
I'm about to buy flights within 14 days.

00:01:14.380 --> 00:01:18.849
My annual salary is between
30,000 and 40,000 pounds a year.

00:01:19.269 --> 00:01:22.750
I don't own a TV or watch
any scheduled programming,

00:01:22.780 --> 00:01:27.020
but I do enjoy on-demand services
such as Netflix or Now TV.

00:01:28.220 --> 00:01:31.360
Last week, I passed
through Upper Street in North London

00:01:31.360 --> 00:01:34.469
on Monday and Wednesday
evenings at 7 p.m.

00:01:35.889 --> 00:01:40.180
I cook a little, but I tend to eat out
or get takeaways often.

00:01:40.620 --> 00:01:43.890
My favourite cuisines
are Thai and Mexican food.

00:01:44.570 --> 00:01:48.390
I don't own any furniture,
and I don't have any children.

00:01:49.400 --> 00:01:51.469
On weeknights, I tend
to spend the evenings

00:01:51.489 --> 00:01:53.959
with my university friends having dinner.

00:01:54.559 --> 00:01:59.050
I usually buy my groceries at Sainsbury's
but only because it's on my way home.

00:02:00.210 --> 00:02:02.690
I don't care for cars or own one.

00:02:03.200 --> 00:02:05.390
I don't like any form of housework,

00:02:05.390 --> 00:02:08.810
and I have a cleaner who lets
herself in while I'm at work.

00:02:09.920 --> 00:02:13.040
On Fridays, you'll find me
at the pub after work.

00:02:13.580 --> 00:02:17.420
At home, I'm far more likely
to be browsing restaurant reviews

00:02:17.440 --> 00:02:21.760
rather than managing my finances
or looking at property prices online.

00:02:23.190 --> 00:02:25.810
I like the idea of living abroad someday.

00:02:26.360 --> 00:02:29.020
I prefer to work as a team than on my own.

00:02:29.790 --> 00:02:34.120
I'm ambitious, and it's important to me
that my many thinks I'm doing well.

00:02:34.930 --> 00:02:37.740
I'm rarely swayed by others' views.

00:02:39.170 --> 00:02:43.700
This motley set of characteristics, 
attitudes, thoughts, and desires

00:02:43.730 --> 00:02:46.720
come very close
to defining me as a person.

00:02:47.530 --> 00:02:50.620
It is also a precise
and accurate description

00:02:50.660 --> 00:02:53.830
of what a group of companies
I had never heard of,

00:02:54.120 --> 00:02:57.710
personal data trackers,
had learned about me.

00:03:00.940 --> 00:03:04.020
My journey to uncover
what data companies knew

00:03:04.030 --> 00:03:09.550
began in 2014, when I became curious
about the murky world of data brokers,

00:03:09.760 --> 00:03:11.780
a multi-billion-pound industry

00:03:11.790 --> 00:03:17.930
of companies that collect, package,
and sell detailed profiles of individuals

00:03:17.940 --> 00:03:20.949
based on their online
and offline behaviours.

00:03:21.799 --> 00:03:24.640
I decided to write about it 
for Wired Magazine.

00:03:26.270 --> 00:03:28.620
What I found out shocked me,

00:03:28.620 --> 00:03:32.810
and reinforced my anxieties
about a profit-led system

00:03:32.810 --> 00:03:34.840
designed to log behaviours

00:03:34.840 --> 00:03:37.929
every time we interact
with the connected world.

00:03:39.549 --> 00:03:44.830
I already knew about my daily records
being collected by services

00:03:44.840 --> 00:03:50.209
such as Google Maps, Search, Facebook,
or contactless credit card transactions.

00:03:50.729 --> 00:03:53.380
But you combine that
with public information

00:03:53.380 --> 00:03:57.740
such as land registry,
council tax, or voter records,

00:03:57.780 --> 00:03:59.720
along with my shopping habits

00:03:59.730 --> 00:04:02.820
and real-time health
and location information,

00:04:02.830 --> 00:04:06.029
and these benign data sets
begin to reveal a lot,

00:04:06.349 --> 00:04:12.200
such as whether you're optimistic,
political, ambitious, or a risk-taker.

00:04:12.909 --> 00:04:16.600
Even as you're listening to me,
you may be sedentary,

00:04:16.620 --> 00:04:19.410
but your smartphone
can reveal your exact location,

00:04:19.429 --> 00:04:21.410
and even your posture.

00:04:21.420 --> 00:04:26.450
Your life is being converted
into such a data package to be sold on.

00:04:27.470 --> 00:04:30.920
Ultimately, you are the product.

00:04:32.250 --> 00:04:36.030
Ostensibly, we're all protected
by data protection laws.

00:04:36.030 --> 00:04:37.769
In the UK, the law states

00:04:37.769 --> 00:04:41.450
that any personal data set 
has to be stripped of identifiers

00:04:41.460 --> 00:04:44.960
such as your name
or your National Insurance number.

00:04:45.570 --> 00:04:50.160
Personal data is considered anything
that can be traced directly back to you.

00:04:50.160 --> 00:04:52.310
without the need
for additional information.

00:04:53.380 --> 00:04:55.410
This doesn't mean it can't be sold on.

00:04:55.430 --> 00:04:57.880
It only means that they
need your permission.

00:04:58.470 --> 00:05:00.690
Simple examples of personal data include

00:05:00.690 --> 00:05:04.970
your full credit card number,
your bank statement, or a criminal record.

00:05:05.970 --> 00:05:10.690
However, I discovered that online
anonymity is a complete myth.

00:05:11.550 --> 00:05:15.950
Particulars such as your postcode,
your date of birth, and your gender

00:05:15.950 --> 00:05:18.870
can be traded freely 
and without your permission

00:05:18.900 --> 00:05:22.510
because they're not considered
personal but pseudonymous.

00:05:22.540 --> 00:05:25.230
In other words, 
they can't be traced back to you

00:05:25.250 --> 00:05:27.960
without the need
for additional information.

00:05:28.890 --> 00:05:32.100
So why does it matter if a bunch
of companies you've never heard of

00:05:32.100 --> 00:05:34.520
know your age or your 
postcode, you may think.

00:05:34.540 --> 00:05:36.730
Well, it matters quite a lot.

00:05:37.310 --> 00:05:38.800
About a decade ago,

00:05:38.820 --> 00:05:42.840
Latanya Sweeney, a professor
of privacy at Harvard University

00:05:43.010 --> 00:05:48.470
proved that about 87% of US citizens
could be uniquely identified

00:05:48.490 --> 00:05:50.670
by just three facts about them:

00:05:51.320 --> 00:05:55.450
their zip code, their date
of birth, and their gender.

00:05:56.518 --> 00:05:59.300
In the UK, where we have
far fewer citizens

00:05:59.300 --> 00:06:03.080
serviced by much longer postcodes,
that probability is far higher.

00:06:04.460 --> 00:06:07.500
Professor Sweeney proved this
in a rather cheeky way

00:06:07.780 --> 00:06:12.390
when William Weld, a former governor
of Cambridge, Massachusetts, in the US

00:06:12.620 --> 00:06:19.140
decided to support the commercial release
of 135,000 state employee health records

00:06:19.170 --> 00:06:22.010
along with their families,
including his own.

00:06:23.020 --> 00:06:27.110
These records did not contain a name
or a social security number,

00:06:27.290 --> 00:06:30.790
but did contain hundreds of fields
of sensitive medical information

00:06:30.810 --> 00:06:33.810
including drugs prescribed,
hospitalisations,

00:06:33.820 --> 00:06:36.150
and procedures performed
on these employees.

00:06:37.400 --> 00:06:39.460
For $20, Professor Sweeney

00:06:39.490 --> 00:06:42.610
purchased the voter records 
for Cambridge, Massachusetts,

00:06:42.620 --> 00:06:47.100
containing the names, zip codes, 
dates of birth, and gender

00:06:47.130 --> 00:06:48.850
for every voter in the area,

00:06:49.110 --> 00:06:52.060
and then cross-referenced this
with their health records.

00:06:52.770 --> 00:06:56.540
Within minutes, she had pinpointed
Governor Welds' own health records.

00:06:57.390 --> 00:07:00.940
Only six people in Cambridge
shared his date of birth.

00:07:01.360 --> 00:07:03.340
Three of them were men.

00:07:03.730 --> 00:07:06.189
And he was the only one
living in his zip code.

00:07:07.429 --> 00:07:11.120
Professor Sweeney sent the governor
his health records in the post.

00:07:11.780 --> 00:07:13.570
(Laughter)

00:07:14.460 --> 00:07:16.970
Every day, we hear about new examples

00:07:16.980 --> 00:07:20.310
of companies digging ever deeper
into our personal lives.

00:07:20.940 --> 00:07:23.550
In the November US presidential election,

00:07:23.570 --> 00:07:27.460
a little-known British company
known as Cambridge Analytica

00:07:27.630 --> 00:07:31.599
was tasked with winning the election
for a certain candidate: Donald Trump,

00:07:31.790 --> 00:07:33.640
using data analytics.

00:07:34.450 --> 00:07:39.000
The company employed cookies online
to track people around the web,

00:07:39.290 --> 00:07:42.790
logging every website visited,
every search term typed,

00:07:42.790 --> 00:07:44.370
and every video watched.

00:07:44.800 --> 00:07:49.260
They also created a viral Facebook quiz
to dig into people's personalities,

00:07:49.260 --> 00:07:51.670
which was taken
by over six million people.

00:07:52.740 --> 00:07:58.400
In total, they managed to amass data
on 220 million voting Americans

00:07:58.420 --> 00:08:03.000
with an average of about 5,000 pieces
of data on each person.

00:08:03.910 --> 00:08:07.720
They then used this data
to understand people's inner feelings

00:08:07.739 --> 00:08:10.450
and then targeted adverts
to them on Facebook.

00:08:11.380 --> 00:08:14.230
Researchers have called them
a propaganda machine.

00:08:15.450 --> 00:08:18.169
It's not just large companies
digging into your life;

00:08:18.169 --> 00:08:20.569
it's free apps and small startups as well.

00:08:21.389 --> 00:08:22.719
I realised on my phone

00:08:22.729 --> 00:08:26.279
that every time I logged fitness data
into the app Endomondo,

00:08:26.299 --> 00:08:29.790
it was sharing my details
including my location and gender

00:08:29.810 --> 00:08:31.879
with third-party advertisers.

00:08:32.709 --> 00:08:34.790
WebMD, a symptom checkers app,

00:08:34.820 --> 00:08:36.920
was sharing even more
sensitive information

00:08:36.930 --> 00:08:41.669
including the symptoms, procedures,
and drugs viewed by users within its app

00:08:41.670 --> 00:08:43.170
with its third parties.

00:08:44.330 --> 00:08:46.550
Fitbit was sharing data with Yahoo.

00:08:46.980 --> 00:08:50.369
A pregnancy tracking app
was selling on information

00:08:50.369 --> 00:08:54.090
about its users' ovulation cycles
and fertility cycles

00:08:54.110 --> 00:08:56.870
with people or advertisers like InMobi.

00:08:58.390 --> 00:09:02.110
As long as my phone is turned on,
my location can be tracked,

00:09:02.130 --> 00:09:05.229
not just by the obvious apps
like Google Maps,

00:09:05.249 --> 00:09:08.100
but a whole host of unrelated services

00:09:08.120 --> 00:09:13.900
from Uber to Twitter, Photos, 
Snapchat, TripAdvisor, and others.

00:09:14.960 --> 00:09:17.170
You're not even safe in your own home.

00:09:17.970 --> 00:09:22.520
In 2015, Samsung was found
to be recording people in the homes

00:09:22.540 --> 00:09:27.030
in which their TVs had been sold
using their voice recognition systems.

00:09:27.570 --> 00:09:30.360
They have now adapted this
so they only record

00:09:30.360 --> 00:09:33.120
when the voice recognition is activated.

00:09:33.130 --> 00:09:35.280
But the creepy factor remains.

00:09:35.960 --> 00:09:38.170
Even services like Google and Facebook,

00:09:38.200 --> 00:09:40.440
trusted and used
by billions around the world,

00:09:40.440 --> 00:09:42.480
have been accused of crossing the line.

00:09:43.710 --> 00:09:46.910
A few weeks ago, my husband and I
were driving home from work

00:09:46.920 --> 00:09:49.100
and discussing
where we should have dinner.

00:09:49.860 --> 00:09:53.170
I suggested a restaurant that I knew
was somewhere on our way back

00:09:53.190 --> 00:09:55.830
and then opened up Google Maps to plot it.

00:09:56.210 --> 00:09:59.600
Turns out it was already marked
on the map with a little bubble.

00:10:00.560 --> 00:10:03.770
That sinking feeling of being watched
is not unique to me.

00:10:04.230 --> 00:10:08.290
There have been several anecdotal reports
of people being shown adverts

00:10:08.350 --> 00:10:11.880
based on things and conversations
they were having in real life,

00:10:11.890 --> 00:10:15.930
prompting concerns that Facebook
and Google are eavesdropping on people

00:10:15.940 --> 00:10:17.970
via their personal devices.

00:10:20.100 --> 00:10:23.080
To piece together what all
these companies knew about me,

00:10:23.090 --> 00:10:25.650
I spoke to a data profiler called Eyeota.

00:10:26.800 --> 00:10:30.930
Eyeota uses cookies to assign me
to thousands of different categories,

00:10:30.950 --> 00:10:33.730
including my job,
how many children I have,

00:10:33.750 --> 00:10:36.840
and whether I'm likely to buy
Star Wars memorabilia.

00:10:37.180 --> 00:10:38.230
(Laughter)

00:10:38.380 --> 00:10:39.970
They don't know my name,

00:10:40.000 --> 00:10:42.550
but they know more about me 
than my neighbours do.

00:10:43.330 --> 00:10:46.740
Eyeota also buys information
from third parties

00:10:46.760 --> 00:10:49.570
such as the credit rating agency Experian,

00:10:49.580 --> 00:10:53.360
which amasses a massive database
of 15 different demographic types

00:10:53.360 --> 00:10:57.560
and 66 lifestyles,
all based on people's post codes.

00:10:58.700 --> 00:11:01.260
Because Eyeota buys
this information, it knows

00:11:01.270 --> 00:11:05.470
that I'm more likely to take taxis home
rather than night buses late at night

00:11:05.750 --> 00:11:10.010
and that I'm very, very unlikely
to ever be found in a DIY store.

00:11:10.050 --> 00:11:11.390
(Laughter)

00:11:11.680 --> 00:11:14.820
It can then sell this information on
to the highest bidder.

00:11:15.960 --> 00:11:19.720
Sometimes, large data sets
can be useful for the public good,

00:11:19.750 --> 00:11:21.890
for example for the use
of health researchers

00:11:21.890 --> 00:11:23.669
or city and urban planners.

00:11:23.929 --> 00:11:26.460
But most of this information
being collected

00:11:26.460 --> 00:11:29.820
is sustained by advertisers
and traded commercially.

00:11:30.400 --> 00:11:34.950
In fact, eMarketer has predicted
that the online advertising industry,

00:11:34.979 --> 00:11:38.550
which is based almost completely
on data targeting and tracking,

00:11:38.550 --> 00:11:42.380
will hit an all-time high
of 77 billion dollars this year.

00:11:43.829 --> 00:11:46.850
If you think you don't care
about being unmasked,

00:11:46.850 --> 00:11:48.720
you may want to reconsider.

00:11:49.450 --> 00:11:52.500
Personalised browser ads may be harmless,

00:11:52.510 --> 00:11:55.080
but connecting disparate
aspects of your life

00:11:55.100 --> 00:11:59.389
to predict your future behaviour
could lead to unexpected consequences.

00:12:00.190 --> 00:12:00.980
For instance,

00:12:00.980 --> 00:12:04.830
decisions on whether your child
gets to go to a certain university

00:12:04.830 --> 00:12:08.530
or what price you pay for your home
or car insurance premiums

00:12:08.530 --> 00:12:10.730
could be made based on data

00:12:10.750 --> 00:12:13.900
given to third parties
that you never intended to,

00:12:13.930 --> 00:12:18.240
such as your own lifestyle habits
or family members' ailments.

00:12:18.960 --> 00:12:21.080
In 2014, Ross Anderson,

00:12:21.100 --> 00:12:24.480
a professor of Privacy and Security
at Cambridge University

00:12:24.490 --> 00:12:28.520
found that the NHS had been sharing
its hospitals' database,

00:12:28.550 --> 00:12:33.169
which included details of hospitalisations
for every citizen in Britain

00:12:33.820 --> 00:12:37.290
with the Institute
and Faculty of Actuaries,

00:12:37.300 --> 00:12:40.629
a body that was researching
how likely people are

00:12:40.629 --> 00:12:43.439
to develop chronic illnesses 
at certain ages.

00:12:44.040 --> 00:12:48.699
Of course, this resulted in an increase
in health insurance premiums.

00:12:51.509 --> 00:12:55.699
As the amount of data that is collected
increases exponentially,

00:12:55.899 --> 00:12:58.789
it becomes much easier to identify you.

00:12:59.109 --> 00:13:03.319
For example, your Fitbit measures 
our heart rate or your gait patterns

00:13:03.339 --> 00:13:05.269
and these can be used to estimate things

00:13:05.269 --> 00:13:08.460
like your height, your weight,
or even your gender.

00:13:09.060 --> 00:13:12.739
These are details that are very hard
to mimic or change.

00:13:13.379 --> 00:13:15.900
The data is no longer about you.

00:13:16.090 --> 00:13:17.289
It is you.

00:13:18.309 --> 00:13:22.020
Companies are also starting to predict
future behaviours - for example,

00:13:22.020 --> 00:13:26.860
whether you're a trustworthy driver,
a good employee, or a good credit risk,

00:13:26.880 --> 00:13:29.660
based on things
like your social media activity,

00:13:29.670 --> 00:13:32.510
your health and fitness,
or your home energy use.

00:13:33.680 --> 00:13:36.389
The more the companies know about you -

00:13:36.399 --> 00:13:38.780
where you live,
how many children you have,

00:13:38.800 --> 00:13:41.340
what your medical ailments are,
what you buy -

00:13:41.360 --> 00:13:43.850
your anonymity becomes irrelevant.

00:13:44.420 --> 00:13:47.910
What's more, you lose
your right to free choice,

00:13:47.930 --> 00:13:51.680
as companies make decisions
on your behalf without your knowledge.

00:13:54.460 --> 00:13:59.040
Along my journey of discovery,
my first reaction was shock.

00:13:59.740 --> 00:14:01.920
I immediately wrote to my local council

00:14:01.920 --> 00:14:04.540
and asked them to make
my voter records private.

00:14:04.960 --> 00:14:06.680
I made up a fake email address,

00:14:06.680 --> 00:14:09.860
and I started registering
with a fake age and gender.

00:14:10.360 --> 00:14:12.730
I turned off targeted advertising,

00:14:12.740 --> 00:14:16.630
and I asked Facebook to send me
all the information that they held on me,

00:14:16.630 --> 00:14:18.430
including things I had deleted,

00:14:18.430 --> 00:14:21.230
and spent hours
poring over it obsessively.

00:14:22.060 --> 00:14:25.710
But after a few weeks I realised
this was a pointless exercise.

00:14:26.190 --> 00:14:28.070
I couldn't be a digital hermit.

00:14:28.730 --> 00:14:31.440
It wasn't realistic for me to stop using

00:14:31.650 --> 00:14:36.680
social media, search
and navigation apps, and my iPhone,

00:14:36.680 --> 00:14:40.450
all a part of modern life
that I cherished and needed.

00:14:41.663 --> 00:14:45.931
Instead, I realised that the knowledge
itself was empowering.

00:14:46.590 --> 00:14:48.160
Knowing all the different ways

00:14:48.170 --> 00:14:51.670
in which my data
was being shared and collected

00:14:51.670 --> 00:14:54.220
made me more responsible
about where I put it.

00:14:54.910 --> 00:14:58.482
For example, I stopped signing up
to supposedly free services,

00:14:59.070 --> 00:15:01.840
for example, a VIP card
at my local hairdresser

00:15:01.850 --> 00:15:04.267
or a discount coupon at your supermarket.

00:15:04.997 --> 00:15:06.640
Whenever I download an app,

00:15:06.640 --> 00:15:09.820
I make sure to check my settings
to see what permissions it has.

00:15:10.150 --> 00:15:14.610
Anything that seems unnecessary
like access to my location, I turn off.

00:15:15.840 --> 00:15:17.970
Ultimately, there is hope.

00:15:19.080 --> 00:15:23.760
As more of us begin to realise
the extent of our data footprint,

00:15:23.980 --> 00:15:28.030
we will start to demand custody
and control of this data.

00:15:29.050 --> 00:15:30.980
Some critics have even suggested

00:15:30.980 --> 00:15:34.800
that people be paid for their data
in order to give them more control.

00:15:35.560 --> 00:15:38.290
This means it will become
too expensive for companies,

00:15:38.290 --> 00:15:40.230
governments, and non-profits

00:15:40.230 --> 00:15:44.706
to recklessly mine and hold our data,
and sell it on indiscriminately

00:15:46.129 --> 00:15:48.640
But until the data economy matures,

00:15:49.120 --> 00:15:52.770
and power moves back
from the corporation to the individual,

00:15:53.565 --> 00:15:55.973
I have lost more than my anonymity.

00:15:56.918 --> 00:16:01.645
I have given up my right
to self-determination and free choice.

00:16:02.887 --> 00:16:05.373
All I have left is my name.

00:16:06.495 --> 00:16:07.640
Thank you.

00:16:07.640 --> 00:16:09.950
(Applause)

