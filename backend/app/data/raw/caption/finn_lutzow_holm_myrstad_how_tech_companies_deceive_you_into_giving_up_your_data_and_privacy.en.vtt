WEBVTT
Kind: captions
Language: en

00:00:13.040 --> 00:00:15.456
Do you remember when you were a child,

00:00:15.480 --> 00:00:19.056
you probably had a favorite toy
that was a constant companion,

00:00:19.080 --> 00:00:21.696
like Christopher Robin
had Winnie the Pooh,

00:00:21.720 --> 00:00:24.520
and your imagination
fueled endless adventures?

00:00:25.640 --> 00:00:28.040
What could be more innocent than that?

00:00:28.800 --> 00:00:33.600
Well, let me introduce you
to my friend Cayla.

00:00:34.600 --> 00:00:38.056
Cayla was voted toy of the year
in countries around the world.

00:00:38.080 --> 00:00:41.656
She connects to the internet
and uses speech recognition technology

00:00:41.680 --> 00:00:43.816
to answer your child's questions,

00:00:43.840 --> 00:00:45.800
respond just like a friend.

00:00:46.920 --> 00:00:50.576
But the power doesn't lie
with your child's imagination.

00:00:50.600 --> 00:00:55.136
It actually lies with the company
harvesting masses of personal information

00:00:55.160 --> 00:01:00.696
while your family is innocently
chatting away in the safety of their home,

00:01:00.720 --> 00:01:03.200
a dangerously false sense of security.

00:01:04.840 --> 00:01:07.496
This case sounded alarm bells for me,

00:01:07.520 --> 00:01:10.720
as it is my job to protect
consumers' rights in my country.

00:01:11.800 --> 00:01:15.296
And with billions of devices such as cars,

00:01:15.320 --> 00:01:20.416
energy meters and even vacuum cleaners
expected to come online by 2020,

00:01:20.440 --> 00:01:24.376
we thought this was a case
worth investigating further.

00:01:24.400 --> 00:01:26.296
Because what was Cayla doing

00:01:26.320 --> 00:01:28.856
with all the interesting things
she was learning?

00:01:28.880 --> 00:01:32.520
Did she have another friend she was
loyal to and shared her information with?

00:01:33.640 --> 00:01:36.416
Yes, you guessed right. She did.

00:01:36.440 --> 00:01:38.536
In order to play with Cayla,

00:01:38.560 --> 00:01:41.560
you need to download an app
to access all her features.

00:01:42.280 --> 00:01:46.120
Parents must consent to the terms
being changed without notice.

00:01:47.280 --> 00:01:51.056
The recordings of the child,
her friends and family,

00:01:51.080 --> 00:01:53.040
can be used for targeted advertising.

00:01:54.080 --> 00:01:59.040
And all this information can be shared
with unnamed third parties.

00:01:59.760 --> 00:02:01.880
Enough? Not quite.

00:02:02.880 --> 00:02:07.176
Anyone with a smartphone
can connect to Cayla

00:02:07.200 --> 00:02:08.800
within a certain distance.

00:02:09.560 --> 00:02:14.136
When we confronted the company
that made and programmed Cayla,

00:02:14.160 --> 00:02:16.416
they issued a series of statements

00:02:16.440 --> 00:02:20.560
that one had to be an IT expert
in order to breach the security.

00:02:22.039 --> 00:02:25.960
Shall we fact-check that statement
and live hack Cayla together?

00:02:29.920 --> 00:02:31.120
Here she is.

00:02:32.200 --> 00:02:35.576
Cayla is equipped with a Bluetooth device

00:02:35.600 --> 00:02:37.816
which can transmit up to 60 feet,

00:02:37.840 --> 00:02:40.456
a bit less if there's a wall between.

00:02:40.480 --> 00:02:45.776
That means I, or any stranger,
can connect to the doll

00:02:45.800 --> 00:02:49.536
while being outside the room
where Cayla and her friends are.

00:02:49.560 --> 00:02:51.736
And to illustrate this,

00:02:51.760 --> 00:02:53.896
I'm going to turn Cayla on now.

00:02:53.920 --> 00:02:55.720
Let's see, one, two, three.

00:02:57.040 --> 00:02:59.016
There. She's on. And I asked a colleague

00:02:59.040 --> 00:03:01.136
to stand outside with his smartphone,

00:03:01.160 --> 00:03:02.400
and he's connected,

00:03:03.320 --> 00:03:05.416
and to make this a bit creepier ...

00:03:05.440 --> 00:03:09.496
(Laughter)

00:03:09.520 --> 00:03:14.440
let's see what kids could hear Cayla say
in the safety of their room.

00:03:15.920 --> 00:03:18.816
Man: Hi. My name is Cayla. What is yours?

00:03:18.840 --> 00:03:20.160
Finn Myrstad: Uh, Finn.

00:03:20.960 --> 00:03:22.256
Man: Is your mom close by?

00:03:22.280 --> 00:03:23.760
FM: Uh, no, she's in the store.

00:03:24.680 --> 00:03:27.056
Man: Ah. Do you want
to come out and play with me?

00:03:27.080 --> 00:03:28.560
FM: That's a great idea.

00:03:29.720 --> 00:03:30.920
Man: Ah, great.

00:03:32.480 --> 00:03:34.616
FM: I'm going to turn Cayla off now.

00:03:34.640 --> 00:03:35.840
(Laughter)

00:03:39.080 --> 00:03:41.816
We needed no password

00:03:41.840 --> 00:03:45.400
or to circumvent any other
type of security to do this.

00:03:46.440 --> 00:03:50.256
We published a report
in 20 countries around the world,

00:03:50.280 --> 00:03:53.256
exposing this significant security flaw

00:03:53.280 --> 00:03:55.040
and many other problematic issues.

00:03:56.000 --> 00:03:57.240
So what happened?

00:03:57.840 --> 00:03:59.480
Cayla was banned in Germany,

00:04:00.480 --> 00:04:03.696
taken off the shelves
by Amazon and Wal-Mart,

00:04:03.720 --> 00:04:06.776
and she's now peacefully resting

00:04:06.800 --> 00:04:10.256
at the German Spy Museum in Berlin.

00:04:10.280 --> 00:04:13.056
(Laughter)

00:04:13.080 --> 00:04:17.376
However, Cayla was also for sale
in stores around the world

00:04:17.400 --> 00:04:20.976
for more than a year
after we published our report.

00:04:21.000 --> 00:04:25.256
What we uncovered is that
there are few rules to protect us

00:04:25.280 --> 00:04:28.640
and the ones we have
are not being properly enforced.

00:04:30.000 --> 00:04:33.856
We need to get the security
and privacy of these devices right

00:04:33.880 --> 00:04:36.736
before they enter the market,

00:04:36.760 --> 00:04:40.736
because what is the point
of locking a house with a key

00:04:40.760 --> 00:04:43.680
if anyone can enter it
through a connected device?

00:04:45.640 --> 00:04:48.936
You may well think,
"This will not happen to me.

00:04:48.960 --> 00:04:51.560
I will just stay away
from these flawed devices."

00:04:52.600 --> 00:04:54.656
But that won't keep you safe,

00:04:54.680 --> 00:04:57.856
because simply by
connecting to the internet,

00:04:57.880 --> 00:05:02.456
you are put in an impossible
take-it-or-leave-it position.

00:05:02.480 --> 00:05:03.680
Let me show you.

00:05:04.400 --> 00:05:07.496
Like most of you,
I have dozens of apps on my phone,

00:05:07.520 --> 00:05:10.376
and used properly,
they can make our lives easier,

00:05:10.400 --> 00:05:12.840
more convenient and maybe even healthier.

00:05:13.960 --> 00:05:17.480
But have we been lulled
into a false sense of security?

00:05:18.600 --> 00:05:21.040
It starts simply by ticking a box.

00:05:21.880 --> 00:05:23.656
Yes, we say,

00:05:23.680 --> 00:05:25.120
I've read the terms.

00:05:27.240 --> 00:05:30.280
But have you really read the terms?

00:05:31.200 --> 00:05:33.496
Are you sure they didn't look too long

00:05:33.520 --> 00:05:35.576
and your phone was running out of battery,

00:05:35.600 --> 00:05:38.816
and the last time you tried
they were impossible to understand,

00:05:38.840 --> 00:05:40.680
and you needed to use the service now?

00:05:41.840 --> 00:05:45.496
And now, the power
imbalance is established,

00:05:45.520 --> 00:05:49.176
because we have agreed
to our personal information

00:05:49.200 --> 00:05:52.320
being gathered and used
on a scale we could never imagine.

00:05:53.640 --> 00:05:57.336
This is why my colleagues and I
decided to take a deeper look at this.

00:05:57.360 --> 00:06:00.696
We set out to read the terms

00:06:00.720 --> 00:06:03.416
of popular apps on an average phone.

00:06:03.440 --> 00:06:07.176
And to show the world
how unrealistic it is

00:06:07.200 --> 00:06:10.416
to expect consumers
to actually read the terms,

00:06:10.440 --> 00:06:11.936
we printed them,

00:06:11.960 --> 00:06:13.800
more than 900 pages,

00:06:14.800 --> 00:06:18.400
and sat down in our office
and read them out loud ourselves,

00:06:19.800 --> 00:06:22.336
streaming the experiment
live on our websites.

00:06:22.360 --> 00:06:24.896
As you can see, it took quite a long time.

00:06:24.920 --> 00:06:29.336
It took us 31 hours,
49 minutes and 11 seconds

00:06:29.360 --> 00:06:31.936
to read the terms on an average phone.

00:06:31.960 --> 00:06:36.336
That is longer than a movie marathon
of the "Harry Potter" movies

00:06:36.360 --> 00:06:38.856
and the "Godfather" movies combined.

00:06:38.880 --> 00:06:40.280
(Laughter)

00:06:41.600 --> 00:06:43.536
And reading is one thing.

00:06:43.560 --> 00:06:45.536
Understanding is another story.

00:06:45.560 --> 00:06:49.136
That would have taken us
much, much longer.

00:06:49.160 --> 00:06:50.936
And this is a real problem,

00:06:50.960 --> 00:06:54.176
because companies have argued
for 20 to 30 years

00:06:54.200 --> 00:06:57.256
against regulating the internet better,

00:06:57.280 --> 00:07:00.440
because users have consented
to the terms and conditions.

00:07:02.520 --> 00:07:04.496
As we've shown with this experiment,

00:07:04.520 --> 00:07:07.400
achieving informed consent
is close to impossible.

00:07:09.080 --> 00:07:12.604
Do you think it's fair to put the burden
of responsibility on the consumer?

00:07:14.000 --> 00:07:15.736
I don't.

00:07:15.760 --> 00:07:18.856
I think we should demand
less take-it-or-leave-it

00:07:18.880 --> 00:07:22.056
and more understandable terms
before we agree to them.

00:07:22.080 --> 00:07:23.616
(Applause)

00:07:23.640 --> 00:07:24.840
Thank you.

00:07:28.200 --> 00:07:33.080
Now, I would like to tell you
a story about love.

00:07:34.080 --> 00:07:37.616
Some of the world's
most popular apps are dating apps,

00:07:37.640 --> 00:07:42.280
an industry now worth more than,
or close to, three billion dollars a year.

00:07:43.160 --> 00:07:47.336
And of course, we're OK
sharing our intimate details

00:07:47.360 --> 00:07:48.600
with our other half.

00:07:49.240 --> 00:07:51.216
But who else is snooping,

00:07:51.240 --> 00:07:54.176
saving and sharing our information

00:07:54.200 --> 00:07:55.840
while we are baring our souls?

00:07:56.520 --> 00:07:58.720
My team and I decided to investigate this.

00:08:00.920 --> 00:08:03.936
And in order to understand
the issue from all angles

00:08:03.960 --> 00:08:06.200
and to truly do a thorough job,

00:08:07.400 --> 00:08:09.376
I realized I had to download

00:08:09.400 --> 00:08:12.840
one of the world's
most popular dating apps myself.

00:08:14.440 --> 00:08:16.736
So I went home to my wife ...

00:08:16.760 --> 00:08:18.696
(Laughter)

00:08:18.720 --> 00:08:20.376
who I had just married.

00:08:20.400 --> 00:08:25.016
"Is it OK if I establish a profile
on a very popular dating app

00:08:25.040 --> 00:08:26.936
for purely scientific purposes?"

00:08:26.960 --> 00:08:28.816
(Laughter)

00:08:28.840 --> 00:08:30.336
This is what we found.

00:08:30.360 --> 00:08:34.336
Hidden behind the main menu
was a preticked box

00:08:34.360 --> 00:08:40.416
that gave the dating company access
to all my personal pictures on Facebook,

00:08:40.440 --> 00:08:43.296
in my case more than 2,000 of them,

00:08:43.320 --> 00:08:45.440
and some were quite personal.

00:08:46.400 --> 00:08:48.616
And to make matters worse,

00:08:48.640 --> 00:08:50.696
when we read the terms and conditions,

00:08:50.720 --> 00:08:52.096
we discovered the following,

00:08:52.120 --> 00:08:55.240
and I'm going to need to take out
my reading glasses for this one.

00:08:56.400 --> 00:08:59.336
And I'm going to read it for you,
because this is complicated.

00:08:59.360 --> 00:09:00.560
All right.

00:09:01.440 --> 00:09:02.976
"By posting content" --

00:09:03.000 --> 00:09:04.976
and content refers to your pictures, chat

00:09:05.000 --> 00:09:07.216
and other interactions
in the dating service --

00:09:07.240 --> 00:09:08.496
"as a part of the service,

00:09:08.520 --> 00:09:10.496
you automatically grant to the company,

00:09:10.520 --> 00:09:12.696
its affiliates, licensees and successors

00:09:12.720 --> 00:09:16.336
an irrevocable" -- which means
you can't change your mind --

00:09:16.360 --> 00:09:19.136
"perpetual" -- which means forever --

00:09:19.160 --> 00:09:22.056
"nonexclusive, transferrable,
sublicensable, fully paid-up,

00:09:22.080 --> 00:09:24.776
worldwide right and license
to use, copy, store, perform,

00:09:24.800 --> 00:09:26.136
display, reproduce, record,

00:09:26.160 --> 00:09:28.376
play, adapt, modify
and distribute the content,

00:09:28.400 --> 00:09:30.336
prepare derivative works of the content,

00:09:30.360 --> 00:09:32.376
or incorporate the content
into other works

00:09:32.400 --> 00:09:35.456
and grant and authorize sublicenses
of the foregoing in any media

00:09:35.480 --> 00:09:37.040
now known or hereafter created."

00:09:40.640 --> 00:09:44.456
That basically means
that all your dating history

00:09:44.480 --> 00:09:49.560
and everything related to it
can be used for any purpose for all time.

00:09:50.520 --> 00:09:55.496
Just imagine your children
seeing your sassy dating photos

00:09:55.520 --> 00:09:58.080
in a birth control ad 20 years from now.

00:10:00.400 --> 00:10:01.616
But seriously, though --

00:10:01.640 --> 00:10:03.240
(Laughter)

00:10:04.880 --> 00:10:07.240
what might these commercial
practices mean to you?

00:10:08.320 --> 00:10:10.560
For example, financial loss:

00:10:11.480 --> 00:10:13.176
based on your web browsing history,

00:10:13.200 --> 00:10:16.160
algorithms might decide
whether you will get a mortgage or not.

00:10:16.840 --> 00:10:18.320
Subconscious manipulation:

00:10:19.560 --> 00:10:23.256
companies can analyze your emotions
based on your photos and chats,

00:10:23.280 --> 00:10:26.536
targeting you with ads
when you are at your most vulnerable.

00:10:26.560 --> 00:10:28.056
Discrimination:

00:10:28.080 --> 00:10:31.096
a fitness app can sell your data
to a health insurance company,

00:10:31.120 --> 00:10:34.176
preventing you from getting
coverage in the future.

00:10:34.200 --> 00:10:36.720
All of this is happening
in the world today.

00:10:37.800 --> 00:10:41.136
But of course, not all uses
of data are malign.

00:10:41.160 --> 00:10:43.136
Some are just flawed or need more work,

00:10:43.160 --> 00:10:44.680
and some are truly great.

00:10:47.560 --> 00:10:51.256
And there is some good news as well.

00:10:51.280 --> 00:10:54.576
The dating companies
changed their policies globally

00:10:54.600 --> 00:10:56.280
after we filed a legal complaint.

00:10:57.720 --> 00:11:00.416
But organizations such as mine

00:11:00.440 --> 00:11:03.416
that fight for consumers' rights
can't be everywhere.

00:11:03.440 --> 00:11:05.976
Nor can consumers fix this on their own,

00:11:06.000 --> 00:11:09.576
because if we know
that something innocent we said

00:11:09.600 --> 00:11:11.056
will come back to haunt us,

00:11:11.080 --> 00:11:12.976
we will stop speaking.

00:11:13.000 --> 00:11:16.376
If we know that we are being
watched and monitored,

00:11:16.400 --> 00:11:18.496
we will change our behavior.

00:11:18.520 --> 00:11:22.416
And if we can't control who has our data
and how it is being used,

00:11:22.440 --> 00:11:24.280
we have lost the control of our lives.

00:11:26.400 --> 00:11:29.896
The stories I have told you today
are not random examples.

00:11:29.920 --> 00:11:31.696
They are everywhere,

00:11:31.720 --> 00:11:34.576
and they are a sign
that things need to change.

00:11:34.600 --> 00:11:36.696
And how can we achieve that change?

00:11:36.720 --> 00:11:42.296
Well, companies need to realize
that by prioritizing privacy and security,

00:11:42.320 --> 00:11:45.280
they can build trust
and loyalty to their users.

00:11:46.520 --> 00:11:49.616
Governments must create a safer internet

00:11:49.640 --> 00:11:52.520
by ensuring enforcement
and up-to-date rules.

00:11:53.400 --> 00:11:55.616
And us, the citizens?

00:11:55.640 --> 00:11:57.456
We can use our voice

00:11:57.480 --> 00:12:02.576
to remind the world that technology
can only truly benefit society

00:12:02.600 --> 00:12:05.200
if it respects basic rights.

00:12:05.720 --> 00:12:07.296
Thank you so much.

00:12:07.320 --> 00:12:11.400
(Applause)

