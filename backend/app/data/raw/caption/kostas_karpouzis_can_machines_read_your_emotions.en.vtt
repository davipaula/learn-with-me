WEBVTT
Kind: captions
Language: en

00:00:07.052 --> 00:00:11.642
With every year, machines surpass humans
in more and more activities

00:00:11.642 --> 00:00:14.848
we once thought only we were capable of.

00:00:14.848 --> 00:00:18.423
Today's computers can beat us
in complex board games,

00:00:18.423 --> 00:00:21.294
transcribe speech in dozens of languages,

00:00:21.294 --> 00:00:24.746
and instantly identify almost any object.

00:00:24.746 --> 00:00:27.112
But the robots of tomorrow may go futher

00:00:27.112 --> 00:00:30.243
by learning to figure out 
what we're feeling.

00:00:30.243 --> 00:00:32.381
And why does that matter?

00:00:32.381 --> 00:00:34.673
Because if machines 
and the people who run them

00:00:34.673 --> 00:00:37.223
can accurately read our emotional states,

00:00:37.223 --> 00:00:40.193
they may be able to assist us
or manipulate us

00:00:40.193 --> 00:00:43.102
at unprecedented scales.

00:00:43.102 --> 00:00:44.614
But before we get there,

00:00:44.614 --> 00:00:49.653
how can something so complex as emotion
be converted into mere numbers,

00:00:49.653 --> 00:00:53.253
the only language machines understand?

00:00:53.253 --> 00:00:56.843
Essentially the same way our own brains
interpret emotions,

00:00:56.843 --> 00:00:58.994
by learning how to spot them.

00:00:58.994 --> 00:01:04.120
American psychologist Paul Ekman
identified certain universal emotions

00:01:04.120 --> 00:01:09.174
whose visual cues are understood
the same way across cultures.

00:01:09.174 --> 00:01:14.193
For example, an image of a smile
signals joy to modern urban dwellers

00:01:14.193 --> 00:01:16.965
and aboriginal tribesmen alike.

00:01:16.965 --> 00:01:18.094
And according to Ekman,

00:01:18.094 --> 00:01:18.823
anger,

00:01:18.823 --> 00:01:19.533
disgust,

00:01:19.533 --> 00:01:20.275
fear,

00:01:20.275 --> 00:01:21.092
joy,

00:01:21.092 --> 00:01:21.848
sadness,

00:01:21.848 --> 00:01:25.433
and surprise are equally recognizable.

00:01:25.433 --> 00:01:29.836
As it turns out, computers are rapidly
getting better at image recognition

00:01:29.836 --> 00:01:34.015
thanks to machine learning algorithms,
such as neural networks.

00:01:34.015 --> 00:01:38.205
These consist of artificial nodes that
mimic our biological neurons

00:01:38.205 --> 00:01:41.784
by forming connections 
and exchanging information.

00:01:41.784 --> 00:01:46.285
To train the network, sample inputs
pre-classified into different categories,

00:01:46.285 --> 00:01:49.175
such as photos marked happy or sad,

00:01:49.175 --> 00:01:51.285
are fed into the system.

00:01:51.285 --> 00:01:53.745
The network then learns to classify
those samples

00:01:53.745 --> 00:01:58.405
by adjusting the relative weights
assigned to particular features.

00:01:58.405 --> 00:02:00.025
The more training data it's given,

00:02:00.025 --> 00:02:04.795
the better the algorithm becomes
at correctly identifying new images.

00:02:04.795 --> 00:02:06.527
This is similar to our own brains,

00:02:06.527 --> 00:02:11.725
which learn from previous experiences
to shape how new stimuli are processed.

00:02:11.725 --> 00:02:15.466
Recognition algorithms aren't just
limited to facial expressions.

00:02:15.466 --> 00:02:17.886
Our emotions manifest in many ways.

00:02:17.886 --> 00:02:20.116
There's body language and vocal tone,

00:02:20.116 --> 00:02:23.237
changes in heart rate, complexion,
and skin temperature,

00:02:23.237 --> 00:02:28.046
or even word frequency and sentence
structure in our writing.

00:02:28.046 --> 00:02:31.205
You might think that training
neural networks to recognize these

00:02:31.205 --> 00:02:33.637
would be a long and complicated task

00:02:33.637 --> 00:02:36.966
until you realize just how much 
data is out there,

00:02:36.966 --> 00:02:40.375
and how quickly modern computers
can process it.

00:02:40.375 --> 00:02:41.917
From social media posts,

00:02:41.917 --> 00:02:43.586
uploaded photos and videos,

00:02:43.586 --> 00:02:44.987
and phone recordings,

00:02:44.987 --> 00:02:46.767
to heat-sensitive security cameras

00:02:46.767 --> 00:02:50.437
and wearables that monitor
physiological signs,

00:02:50.437 --> 00:02:52.947
the big question is not how to collect
enough data,

00:02:52.947 --> 00:02:55.255
but what we're going to do with it.

00:02:55.255 --> 00:02:59.706
There are plenty of beneficial uses
for computerized emotion recognition.

00:02:59.706 --> 00:03:02.627
Robots using algorithms to identify
facial expressions

00:03:02.627 --> 00:03:04.246
can help children learn

00:03:04.246 --> 00:03:07.636
or provide lonely people
with a sense of companionship.

00:03:07.636 --> 00:03:10.637
Social media companies are considering
using algorithms

00:03:10.637 --> 00:03:17.047
to help prevent suicides by flagging posts
that contain specific words or phrases.

00:03:17.047 --> 00:03:21.287
And emotion recognition software can help
treat mental disorders

00:03:21.287 --> 00:03:25.578
or even provide people with low-cost
automated psychotherapy.

00:03:25.578 --> 00:03:27.188
Despite the potential benefits,

00:03:27.188 --> 00:03:30.869
the prospect of a massive network
automatically scanning our photos,

00:03:30.869 --> 00:03:31.958
communications,

00:03:31.958 --> 00:03:36.877
and physiological signs
is also quite disturbing.

00:03:36.877 --> 00:03:40.796
What are the implications for our privacy
when such impersonal systems

00:03:40.796 --> 00:03:45.208
are used by corporations to exploit
our emotions through advertising?

00:03:45.208 --> 00:03:46.718
And what becomes of our rights

00:03:46.718 --> 00:03:50.737
if authorities think they can identify
the people likely to commit crimes

00:03:50.737 --> 00:03:54.927
before they even make 
a conscious decision to act?

00:03:54.927 --> 00:03:57.150
Robots currently have a long way to go

00:03:57.150 --> 00:04:00.258
in distinguishing emotional nuances,
like irony,

00:04:00.258 --> 00:04:04.758
and scales of emotions,
just how happy or sad someone is.

00:04:04.758 --> 00:04:09.288
Nonetheless, they may eventually be able
to accurately read our emotions

00:04:09.288 --> 00:04:11.138
and respond to them.

00:04:11.138 --> 00:04:15.389
Whether they can empathize with our fear
of unwanted intrusion, however,

00:04:15.389 --> 00:04:16.887
that's another story.

