WEBVTT
Kind: captions
Language: en

00:00:12.876 --> 00:00:14.027
Look at these images.

00:00:14.051 --> 00:00:16.686
Now, tell me which Obama here is real.

00:00:16.710 --> 00:00:19.571
(Video) Barack Obama: To help families
refinance their homes,

00:00:19.595 --> 00:00:22.242
to invest in things
like high-tech manufacturing,

00:00:22.266 --> 00:00:23.425
clean energy

00:00:23.449 --> 00:00:26.228
and the infrastructure
that creates good new jobs.

00:00:26.647 --> 00:00:28.131
Supasorn Suwajanakorn: Anyone?

00:00:28.155 --> 00:00:30.029
The answer is none of them.

00:00:30.053 --> 00:00:31.167
(Laughter)

00:00:31.191 --> 00:00:32.977
None of these is actually real.

00:00:33.001 --> 00:00:34.841
So let me tell you how we got here.

00:00:35.940 --> 00:00:37.518
My inspiration for this work

00:00:37.542 --> 00:00:42.953
was a project meant to preserve our last
chance for learning about the Holocaust

00:00:42.977 --> 00:00:44.745
from the survivors.

00:00:44.769 --> 00:00:47.396
It's called New Dimensions in Testimony,

00:00:47.420 --> 00:00:50.546
and it allows you to have
interactive conversations

00:00:50.570 --> 00:00:53.126
with a hologram
of a real Holocaust survivor.

00:00:53.793 --> 00:00:55.759
(Video) Man: How did you
survive the Holocaust?

00:00:55.783 --> 00:00:57.451
(Video) Hologram: How did I survive?

00:00:57.912 --> 00:00:59.719
I survived,

00:01:00.419 --> 00:01:01.946
I believe,

00:01:01.970 --> 00:01:04.993
because providence watched over me.

00:01:05.573 --> 00:01:09.027
SS: Turns out these answers
were prerecorded in a studio.

00:01:09.051 --> 00:01:11.503
Yet the effect is astounding.

00:01:11.527 --> 00:01:15.146
You feel so connected to his story
and to him as a person.

00:01:16.011 --> 00:01:19.312
I think there's something special
about human interaction

00:01:19.336 --> 00:01:22.093
that makes it much more profound

00:01:22.117 --> 00:01:24.315
and personal

00:01:24.339 --> 00:01:27.824
than what books or lectures
or movies could ever teach us.

00:01:28.267 --> 00:01:30.692
So I saw this and began to wonder,

00:01:30.716 --> 00:01:33.526
can we create a model
like this for anyone?

00:01:33.550 --> 00:01:36.525
A model that looks, talks
and acts just like them?

00:01:37.573 --> 00:01:39.580
So I set out to see if this could be done

00:01:39.604 --> 00:01:41.914
and eventually came up with a new solution

00:01:41.938 --> 00:01:45.158
that can build a model of a person
using nothing but these:

00:01:45.747 --> 00:01:47.961
existing photos and videos of a person.

00:01:48.701 --> 00:01:51.318
If you can leverage
this kind of passive information,

00:01:51.342 --> 00:01:53.349
just photos and video that are out there,

00:01:53.373 --> 00:01:55.429
that's the key to scaling to anyone.

00:01:56.119 --> 00:01:57.896
By the way, here's Richard Feynman,

00:01:57.920 --> 00:02:01.333
who in addition to being
a Nobel Prize winner in physics

00:02:01.357 --> 00:02:03.810
was also known as a legendary teacher.

00:02:05.080 --> 00:02:07.278
Wouldn't it be great
if we could bring him back

00:02:07.302 --> 00:02:10.567
to give his lectures
and inspire millions of kids,

00:02:10.591 --> 00:02:13.583
perhaps not just in English
but in any language?

00:02:14.441 --> 00:02:19.043
Or if you could ask our grandparents
for advice and hear those comforting words

00:02:19.067 --> 00:02:20.837
even if they're no longer with us?

00:02:21.683 --> 00:02:25.079
Or maybe using this tool,
book authors, alive or not,

00:02:25.103 --> 00:02:28.040
could read aloud all of their books
for anyone interested.

00:02:29.199 --> 00:02:31.636
The creative possibilities
here are endless,

00:02:31.660 --> 00:02:33.373
and to me, that's very exciting.

00:02:34.595 --> 00:02:36.597
And here's how it's working so far.

00:02:36.621 --> 00:02:38.288
First, we introduce a new technique

00:02:38.312 --> 00:02:42.884
that can reconstruct a high-detailed
3D face model from any image

00:02:42.908 --> 00:02:45.027
without ever 3D-scanning the person.

00:02:45.890 --> 00:02:48.532
And here's the same output model
from different views.

00:02:49.969 --> 00:02:51.471
This also works on videos,

00:02:51.495 --> 00:02:54.347
by running the same algorithm
on each video frame

00:02:54.371 --> 00:02:56.593
and generating a moving 3D model.

00:02:57.538 --> 00:03:00.310
And here's the same
output model from different angles.

00:03:01.933 --> 00:03:04.467
It turns out this problem
is very challenging,

00:03:04.491 --> 00:03:07.016
but the key trick
is that we are going to analyze

00:03:07.040 --> 00:03:10.006
a large photo collection
of the person beforehand.

00:03:10.650 --> 00:03:13.189
For George W. Bush,
we can just search on Google,

00:03:14.309 --> 00:03:16.808
and from that, we are able
to build an average model,

00:03:16.832 --> 00:03:19.943
an iterative, refined model
to recover the expression

00:03:19.967 --> 00:03:22.303
in fine details,
like creases and wrinkles.

00:03:23.326 --> 00:03:24.729
What's fascinating about this

00:03:24.753 --> 00:03:28.176
is that the photo collection
can come from your typical photos.

00:03:28.200 --> 00:03:30.803
It doesn't really matter
what expression you're making

00:03:30.827 --> 00:03:32.712
or where you took those photos.

00:03:32.736 --> 00:03:35.136
What matters is
that there are a lot of them.

00:03:35.160 --> 00:03:36.896
And we are still missing color here,

00:03:36.920 --> 00:03:39.268
so next, we develop
a new blending technique

00:03:39.292 --> 00:03:42.128
that improves upon
a single averaging method

00:03:42.152 --> 00:03:44.970
and produces sharp
facial textures and colors.

00:03:45.779 --> 00:03:48.550
And this can be done for any expression.

00:03:49.485 --> 00:03:51.984
Now we have a control
of a model of a person,

00:03:52.008 --> 00:03:55.803
and the way it's controlled now
is by a sequence of static photos.

00:03:55.827 --> 00:03:58.953
Notice how the wrinkles come and go,
depending on the expression.

00:04:00.109 --> 00:04:02.855
We can also use a video
to drive the model.

00:04:02.879 --> 00:04:05.472
(Video) Daniel Craig: Right, but somehow,

00:04:05.496 --> 00:04:09.267
we've managed to attract
some more amazing people.

00:04:10.021 --> 00:04:11.663
SS: And here's another fun demo.

00:04:11.687 --> 00:04:13.933
So what you see here
are controllable models

00:04:13.957 --> 00:04:16.401
of people I built
from their internet photos.

00:04:16.425 --> 00:04:19.329
Now, if you transfer
the motion from the input video,

00:04:19.353 --> 00:04:21.505
we can actually drive the entire party.

00:04:21.529 --> 00:04:23.701
George W. Bush:
It's a difficult bill to pass,

00:04:23.725 --> 00:04:26.028
because there's a lot of moving parts,

00:04:26.052 --> 00:04:31.283
and the legislative processes can be ugly.

00:04:31.307 --> 00:04:32.937
(Applause)

00:04:32.961 --> 00:04:34.798
SS: So coming back a little bit,

00:04:34.822 --> 00:04:38.013
our ultimate goal, rather,
is to capture their mannerisms

00:04:38.037 --> 00:04:41.082
or the unique way each
of these people talks and smiles.

00:04:41.106 --> 00:04:43.419
So to do that, can we
actually teach the computer

00:04:43.443 --> 00:04:45.665
to imitate the way someone talks

00:04:45.689 --> 00:04:48.109
by only showing it
video footage of the person?

00:04:48.898 --> 00:04:51.475
And what I did exactly was,
I let a computer watch

00:04:51.499 --> 00:04:54.776
14 hours of pure Barack Obama
giving addresses.

00:04:55.443 --> 00:04:58.959
And here's what we can produce
given only his audio.

00:04:58.983 --> 00:05:00.760
(Video) BO: The results are clear.

00:05:00.784 --> 00:05:05.133
America's businesses have created
14.5 million new jobs

00:05:05.157 --> 00:05:07.931
over 75 straight months.

00:05:07.955 --> 00:05:10.860
SS: So what's being synthesized here
is only the mouth region,

00:05:10.884 --> 00:05:12.424
and here's how we do it.

00:05:12.764 --> 00:05:14.590
Our pipeline uses a neural network

00:05:14.614 --> 00:05:17.550
to convert and input audio
into these mouth points.

00:05:18.547 --> 00:05:22.772
(Video) BO: We get it through our job
or through Medicare or Medicaid.

00:05:22.796 --> 00:05:26.216
SS: Then we synthesize the texture,
enhance details and teeth,

00:05:26.240 --> 00:05:29.314
and blend it into the head
and background from a source video.

00:05:29.338 --> 00:05:31.243
(Video) BO: Women can get free checkups,

00:05:31.267 --> 00:05:34.235
and you can't get charged more
just for being a woman.

00:05:34.973 --> 00:05:38.279
Young people can stay
on a parent's plan until they turn 26.

00:05:39.267 --> 00:05:42.219
SS: I think these results
seem very realistic and intriguing,

00:05:42.243 --> 00:05:45.416
but at the same time
frightening, even to me.

00:05:45.440 --> 00:05:49.455
Our goal was to build an accurate model
of a person, not to misrepresent them.

00:05:49.956 --> 00:05:53.067
But one thing that concerns me
is its potential for misuse.

00:05:53.958 --> 00:05:56.929
People have been thinking
about this problem for a long time,

00:05:56.953 --> 00:05:59.334
since the days when Photoshop
first hit the market.

00:05:59.862 --> 00:06:03.663
As a researcher, I'm also working
on countermeasure technology,

00:06:03.687 --> 00:06:06.629
and I'm part of an ongoing
effort at AI Foundation,

00:06:06.653 --> 00:06:10.050
which uses a combination
of machine learning and human moderators

00:06:10.074 --> 00:06:12.218
to detect fake images and videos,

00:06:12.242 --> 00:06:13.756
fighting against my own work.

00:06:14.675 --> 00:06:17.865
And one of the tools we plan to release
is called Reality Defender,

00:06:17.889 --> 00:06:21.928
which is a web-browser plug-in
that can flag potentially fake content

00:06:21.952 --> 00:06:24.485
automatically, right in the browser.

00:06:24.509 --> 00:06:28.737
(Applause)

00:06:28.761 --> 00:06:30.214
Despite all this, though,

00:06:30.238 --> 00:06:32.078
fake videos could do a lot of damage,

00:06:32.102 --> 00:06:35.396
even before anyone has a chance to verify,

00:06:35.420 --> 00:06:38.142
so it's very important
that we make everyone aware

00:06:38.166 --> 00:06:40.173
of what's currently possible

00:06:40.197 --> 00:06:43.566
so we can have the right assumption
and be critical about what we see.

00:06:44.423 --> 00:06:49.430
There's still a long way to go before
we can fully model individual people

00:06:49.454 --> 00:06:52.240
and before we can ensure
the safety of this technology.

00:06:53.097 --> 00:06:54.684
But I'm excited and hopeful,

00:06:54.708 --> 00:06:58.247
because if we use it right and carefully,

00:06:58.271 --> 00:07:02.580
this tool can allow any individual's
positive impact on the world

00:07:02.604 --> 00:07:04.794
to be massively scaled

00:07:04.818 --> 00:07:07.560
and really help shape our future
the way we want it to be.

00:07:07.584 --> 00:07:08.735
Thank you.

00:07:08.759 --> 00:07:13.849
(Applause)

