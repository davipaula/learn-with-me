WEBVTT
Kind: captions
Language: en

00:00:18.948 --> 00:00:22.045
Suppose that two American friends
are traveling together in Italy.

00:00:22.069 --> 00:00:23.994
They go to see Michelangelo's "David,"

00:00:24.018 --> 00:00:26.648
and when they finally come
face-to-face with the statue,

00:00:26.672 --> 00:00:28.500
they both freeze dead in their tracks.

00:00:28.524 --> 00:00:30.391
The first guy -- we'll call him Adam --

00:00:30.415 --> 00:00:33.135
is transfixed by the beauty
of the perfect human form.

00:00:33.785 --> 00:00:35.710
The second guy -- we'll call him Bill --

00:00:35.734 --> 00:00:40.188
is transfixed by embarrassment, at staring
at the thing there in the center.

00:00:40.998 --> 00:00:42.901
So here's my question for you:

00:00:42.925 --> 00:00:46.542
Which one of these two guys was more
likely to have voted for George Bush,

00:00:46.566 --> 00:00:48.306
which for Al Gore?

00:00:48.330 --> 00:00:49.714
I don't need a show of hands,

00:00:49.738 --> 00:00:52.127
because we all have the same
political stereotypes.

00:00:52.151 --> 00:00:54.306
We all know that it's Bill.

00:00:54.330 --> 00:00:57.759
And in this case, the stereotype
corresponds to reality.

00:00:57.783 --> 00:01:01.157
It really is a fact that liberals
are much higher than conservatives

00:01:01.181 --> 00:01:04.330
on a major personality trait
called openness to experience.

00:01:04.813 --> 00:01:06.924
People who are high
in openness to experience

00:01:06.948 --> 00:01:10.392
just crave novelty, variety,
diversity, new ideas, travel.

00:01:10.416 --> 00:01:12.653
People low on it like things
that are familiar,

00:01:12.677 --> 00:01:15.097
that are safe and dependable.

00:01:16.282 --> 00:01:17.665
If you know about this trait,

00:01:17.689 --> 00:01:20.360
you can understand a lot of puzzles
about human behavior,

00:01:20.384 --> 00:01:22.772
like why artists are so different
from accountants.

00:01:22.796 --> 00:01:25.329
You can predict what kinds of books
they like to read,

00:01:25.353 --> 00:01:27.368
what kinds of places
they like to travel to

00:01:27.392 --> 00:01:29.309
and what kinds of food they like to eat.

00:01:29.333 --> 00:01:30.825
Once you understand this trait,

00:01:30.849 --> 00:01:33.454
you can understand why anybody
would eat at Applebee's,

00:01:33.478 --> 00:01:34.956
but not anybody that you know.

00:01:34.980 --> 00:01:40.029
(Laughter)

00:01:40.900 --> 00:01:43.242
This trait also tells us
a lot about politics.

00:01:43.266 --> 00:01:45.655
The main researcher of this trait,
Robert McCrae,

00:01:45.679 --> 00:01:48.026
says that "Open individuals
have an affinity

00:01:48.050 --> 00:01:50.785
for liberal, progressive,
left-wing political views ..."

00:01:50.809 --> 00:01:53.299
They like a society
which is open and changing,

00:01:53.323 --> 00:01:55.199
"... whereas closed individuals prefer

00:01:55.223 --> 00:01:57.349
conservative, traditional,
right-wing views."

00:01:57.956 --> 00:02:01.202
This trait also tells us a lot
about the kinds of groups people join.

00:02:01.226 --> 00:02:03.715
Here's the description
of a group I found on the web.

00:02:03.739 --> 00:02:05.217
What kinds of people would join

00:02:05.241 --> 00:02:08.993
"a global community ... welcoming
people from every discipline and culture,

00:02:09.017 --> 00:02:11.114
who seek a deeper
understanding of the world,

00:02:11.138 --> 00:02:14.568
and who hope to turn that understanding
into a better future for us all"?

00:02:14.592 --> 00:02:16.121
This is from some guy named Ted.

00:02:16.145 --> 00:02:17.297
Well, let's see now.

00:02:17.321 --> 00:02:20.155
If openness predicts who becomes liberal,

00:02:20.179 --> 00:02:22.908
and openness predicts
who becomes a TEDster,

00:02:22.932 --> 00:02:25.432
then might we predict
that most TEDsters are liberal?

00:02:25.964 --> 00:02:27.115
Let's find out.

00:02:27.139 --> 00:02:30.696
I'll ask you to raise your hand,
whether you are liberal, left of center --

00:02:30.720 --> 00:02:32.176
on social issues, primarily --

00:02:32.200 --> 00:02:33.351
or conservative.

00:02:33.375 --> 00:02:34.769
And I'll give a third option,

00:02:34.793 --> 00:02:37.338
because I know there are
libertarians in the audience.

00:02:37.362 --> 00:02:40.038
So please raise your hand --
in the simulcast rooms too.

00:02:40.062 --> 00:02:41.745
Let's let everybody see who's here.

00:02:41.769 --> 00:02:45.279
Please raise your hand if you'd say
that you're liberal or left of center.

00:02:45.303 --> 00:02:47.372
Please raise your hand high right now. OK.

00:02:47.833 --> 00:02:50.504
Please raise your hand
if you'd say you're libertarian.

00:02:50.914 --> 00:02:52.878
OK. About two dozen.

00:02:53.234 --> 00:02:57.335
And please raise your hand if you'd say
you are right of center or conservative.

00:02:57.359 --> 00:03:01.958
One, two, three, four,
five -- about eight or 10.

00:03:01.982 --> 00:03:03.156
OK.

00:03:03.745 --> 00:03:05.230
This is a bit of a problem.

00:03:06.346 --> 00:03:09.872
Because if our goal is to seek
a deeper understanding of the world,

00:03:09.896 --> 00:03:13.607
our general lack of moral diversity here
is going to make it harder.

00:03:13.631 --> 00:03:17.112
Because when people all share values,
when people all share morals,

00:03:17.136 --> 00:03:18.378
they become a team.

00:03:18.402 --> 00:03:20.627
And once you engage
the psychology of teams,

00:03:20.651 --> 00:03:22.651
it shuts down open-minded thinking.

00:03:25.131 --> 00:03:27.402
When the liberal team loses,

00:03:27.426 --> 00:03:29.248
[United States of Canada / Jesusland]

00:03:29.272 --> 00:03:31.928
as it did in 2004,
and as it almost did in 2000,

00:03:31.952 --> 00:03:33.306
we comfort ourselves.

00:03:33.330 --> 00:03:34.505
(Laughter)

00:03:34.529 --> 00:03:38.777
We try to explain why half of America
voted for the other team.

00:03:38.801 --> 00:03:41.718
We think they must be blinded by religion

00:03:41.742 --> 00:03:43.981
[Post-election US map:
America / Dumbf*ckistan]

00:03:44.005 --> 00:03:45.334
or by simple stupidity.

00:03:45.358 --> 00:03:47.153
(Laughter)

00:03:47.177 --> 00:03:50.001
(Applause)

00:03:50.025 --> 00:03:56.510
(Laughter)

00:03:56.534 --> 00:04:01.667
So if you think that half
of America votes Republican

00:04:01.691 --> 00:04:04.129
because they are blinded in this way,

00:04:04.153 --> 00:04:07.378
then my message to you
is that you're trapped in a moral Matrix,

00:04:07.402 --> 00:04:08.804
in a particular moral Matrix.

00:04:08.828 --> 00:04:12.503
And by "the Matrix," I mean literally
the Matrix, like the movie "The Matrix."

00:04:12.527 --> 00:04:14.512
But I'm here today to give you a choice.

00:04:14.536 --> 00:04:18.991
You can either take the blue pill
and stick to your comforting delusions,

00:04:19.015 --> 00:04:20.428
or you can take the red pill,

00:04:20.452 --> 00:04:21.753
learn some moral psychology

00:04:21.777 --> 00:04:23.585
and step outside the moral Matrix.

00:04:23.609 --> 00:04:24.815
Now, because I know --

00:04:24.839 --> 00:04:28.519
(Applause)

00:04:28.543 --> 00:04:30.267
I assume that answers my question.

00:04:30.291 --> 00:04:32.784
I was going to ask
which one you picked, but no need.

00:04:32.808 --> 00:04:34.824
You're all high in openness to experience,

00:04:34.848 --> 00:04:38.048
and it looks like it might even taste
good, and you're all epicures.

00:04:38.072 --> 00:04:41.035
Anyway, let's go with the red pill,
study some moral psychology

00:04:41.059 --> 00:04:42.307
and see where it takes us.

00:04:42.331 --> 00:04:45.725
Let's start at the beginning:
What is morality, where does it come from?

00:04:45.749 --> 00:04:47.451
The worst idea in all of psychology

00:04:47.475 --> 00:04:49.999
is the idea that the mind
is a blank slate at birth.

00:04:50.023 --> 00:04:53.047
Developmental psychology has shown
that kids come into the world

00:04:53.071 --> 00:04:56.012
already knowing so much
about the physical and social worlds

00:04:56.036 --> 00:05:00.224
and programmed to make it really easy
for them to learn certain things

00:05:00.248 --> 00:05:01.676
and hard to learn others.

00:05:01.700 --> 00:05:03.871
The best definition
of innateness I've seen,

00:05:03.895 --> 00:05:05.712
which clarifies so many things for me,

00:05:05.736 --> 00:05:07.651
is from the brain scientist Gary Marcus.

00:05:07.675 --> 00:05:09.885
He says, "The initial
organization of the brain

00:05:09.909 --> 00:05:11.878
does not depend that much on experience.

00:05:11.902 --> 00:05:15.261
Nature provides a first draft,
which experience then revises.

00:05:15.285 --> 00:05:17.029
'Built-in' doesn't mean unmalleable;

00:05:17.053 --> 00:05:20.063
it means organized
in advance of experience."

00:05:20.087 --> 00:05:22.964
OK, so what's on the first draft
of the moral mind?

00:05:22.988 --> 00:05:26.675
To find out, my colleague Craig Joseph
and I read through the literature

00:05:26.699 --> 00:05:29.001
on anthropology,
on culture variation in morality

00:05:29.025 --> 00:05:30.803
and also on evolutionary psychology,

00:05:30.827 --> 00:05:31.984
looking for matches:

00:05:32.008 --> 00:05:34.924
What sorts of things do people
talk about across disciplines

00:05:34.948 --> 00:05:37.157
that you find across cultures
and even species?

00:05:37.181 --> 00:05:40.841
We found five best matches, which we call
the five foundations of morality.

00:05:40.865 --> 00:05:42.440
The first one is harm/care.

00:05:42.464 --> 00:05:46.055
We're all mammals here, we all have a lot
of neural and hormonal programming

00:05:46.079 --> 00:05:48.675
that makes us really bond
with others, care for others,

00:05:48.699 --> 00:05:51.700
feel compassion for others,
especially the weak and vulnerable.

00:05:51.724 --> 00:05:54.676
It gives us very strong feelings
about those who cause harm.

00:05:55.197 --> 00:05:57.486
This moral foundation
underlies about 70 percent

00:05:57.510 --> 00:05:59.723
of the moral statements
I've heard here at TED.

00:05:59.747 --> 00:06:02.306
The second foundation
is fairness/reciprocity.

00:06:02.330 --> 00:06:04.079
There's actually ambiguous evidence

00:06:04.103 --> 00:06:06.540
as to whether you find reciprocity
in other animals,

00:06:06.564 --> 00:06:08.866
but the evidence for people
could not be clearer.

00:06:08.890 --> 00:06:11.700
This Norman Rockwell painting
is called "The Golden Rule" --

00:06:11.724 --> 00:06:15.225
as we heard from Karen Armstrong,
it's the foundation of many religions.

00:06:15.249 --> 00:06:17.728
That second foundation
underlies the other 30 percent

00:06:17.752 --> 00:06:19.950
of the moral statements
I've heard here at TED.

00:06:19.974 --> 00:06:21.954
The third foundation is in-group/loyalty.

00:06:21.978 --> 00:06:24.912
You do find cooperative groups
in the animal kingdom,

00:06:24.936 --> 00:06:28.306
but these groups are always
either very small or they're all siblings.

00:06:28.330 --> 00:06:31.378
It's only among humans that you find
very large groups of people

00:06:31.402 --> 00:06:34.306
who are able to cooperate
and join together into groups,

00:06:34.330 --> 00:06:37.903
but in this case, groups that are united
to fight other groups.

00:06:37.927 --> 00:06:41.777
This probably comes from our long history
of tribal living, of tribal psychology.

00:06:41.801 --> 00:06:44.784
And this tribal psychology
is so deeply pleasurable

00:06:44.808 --> 00:06:47.811
that even when we don't have tribes,
we go ahead and make them,

00:06:47.835 --> 00:06:49.070
because it's fun.

00:06:49.094 --> 00:06:52.479
(Laughter)

00:06:52.503 --> 00:06:55.370
Sports is to war as pornography is to sex.

00:06:55.394 --> 00:06:59.115
We get to exercise some ancient drives.

00:06:59.139 --> 00:07:01.154
The fourth foundation
is authority/respect.

00:07:01.178 --> 00:07:02.715
Here you see submissive gestures

00:07:02.739 --> 00:07:05.028
from two members
of very closely related species.

00:07:05.052 --> 00:07:08.767
But authority in humans is not so closely
based on power and brutality

00:07:08.791 --> 00:07:10.152
as it is in other primates.

00:07:10.176 --> 00:07:13.882
It's based on more voluntary deference
and even elements of love, at times.

00:07:14.541 --> 00:07:16.601
The fifth foundation is purity/sanctity.

00:07:16.625 --> 00:07:19.146
This painting is called
"The Allegory Of Chastity,"

00:07:19.170 --> 00:07:22.162
but purity is not just about
suppressing female sexuality.

00:07:22.186 --> 00:07:25.130
It's about any kind of ideology,
any kind of idea

00:07:25.154 --> 00:07:29.135
that tells you that you can attain virtue
by controlling what you do with your body

00:07:29.159 --> 00:07:30.718
and what you put into your body.

00:07:30.742 --> 00:07:34.023
And while the political right
may moralize sex much more,

00:07:34.047 --> 00:07:36.396
the political left is doing
a lot of it with food.

00:07:36.420 --> 00:07:38.572
Food is becoming extremely
moralized nowadays.

00:07:38.596 --> 00:07:40.227
A lot of it is ideas about purity,

00:07:40.251 --> 00:07:43.037
about what you're willing
to touch or put into your body.

00:07:43.061 --> 00:07:45.952
I believe these
are the five best candidates

00:07:45.976 --> 00:07:48.610
for what's written on the first draft
of the moral mind.

00:07:48.634 --> 00:07:52.291
I think this is what we come with,
a preparedness to learn all these things.

00:07:52.315 --> 00:07:55.601
But as my son Max grows up
in a liberal college town,

00:07:55.625 --> 00:07:58.028
how is this first draft
going to get revised?

00:07:58.052 --> 00:07:59.882
And how will it end up being different

00:07:59.906 --> 00:08:02.962
from a kid born 60 miles south of us,
in Lynchburg, Virginia?

00:08:02.986 --> 00:08:06.055
To think about culture variation,
let's try a different metaphor.

00:08:06.079 --> 00:08:08.561
If there really are five systems
at work in the mind,

00:08:08.585 --> 00:08:10.495
five sources of intuitions and emotions,

00:08:10.519 --> 00:08:13.717
then we can think of the moral mind
as one of those audio equalizers

00:08:13.741 --> 00:08:14.892
that has five channels,

00:08:14.916 --> 00:08:17.793
where you can set it to a different
setting on every channel.

00:08:17.817 --> 00:08:20.072
My colleagues Brian Nosek
and Jesse Graham and I

00:08:20.096 --> 00:08:24.980
made a questionnaire, which we put up
on the web at www.YourMorals.org.

00:08:25.004 --> 00:08:28.985
And so far, 30,000 people have taken
this questionnaire, and you can, too.

00:08:29.009 --> 00:08:33.211
Here are the results
from about 23,000 American citizens.

00:08:33.235 --> 00:08:35.150
On the left are the scores for liberals;

00:08:35.174 --> 00:08:37.711
on the right, conservatives;
in the middle, moderates.

00:08:37.735 --> 00:08:41.530
The blue line shows people's responses
on the average of all the harm questions.

00:08:41.554 --> 00:08:44.147
So as you see, people care
about harm and care issues.

00:08:44.171 --> 00:08:47.334
They highly endorse these sorts
of statements all across the board,

00:08:47.358 --> 00:08:48.509
but as you also see,

00:08:48.533 --> 00:08:52.261
liberals care about it a little more
than conservatives; the line slopes down.

00:08:52.285 --> 00:08:53.660
Same story for fairness.

00:08:53.684 --> 00:08:55.306
But look at the other three lines.

00:08:55.330 --> 00:08:57.153
For liberals, the scores are very low.

00:08:57.177 --> 00:08:59.417
They're basically saying,
"This is not morality.

00:08:59.441 --> 00:09:03.301
In-group, authority, purity -- this has
nothing to do with morality. I reject it."

00:09:03.325 --> 00:09:05.810
But as people get more
conservative, the values rise.

00:09:05.834 --> 00:09:08.947
We can say liberals have
a two-channel or two-foundation morality.

00:09:08.971 --> 00:09:11.070
Conservatives have more
of a five-foundation,

00:09:11.094 --> 00:09:12.287
or five-channel morality.

00:09:12.311 --> 00:09:14.269
We find this in every country we look at.

00:09:14.293 --> 00:09:17.788
Here's the data for 1,100 Canadians.
I'll flip through a few other slides.

00:09:17.812 --> 00:09:20.769
The UK, Australia, New Zealand,
Western Europe, Eastern Europe,

00:09:20.793 --> 00:09:24.306
Latin America, the Middle East,
East Asia and South Asia.

00:09:24.330 --> 00:09:26.242
Notice also that on all of these graphs,

00:09:26.266 --> 00:09:29.069
the slope is steeper
on in-group, authority, purity,

00:09:29.093 --> 00:09:31.805
which shows that, within any country,

00:09:31.829 --> 00:09:33.975
the disagreement
isn't over harm and fairness.

00:09:33.999 --> 00:09:35.710
I mean, we debate over what's fair,

00:09:35.734 --> 00:09:39.004
but everybody agrees
that harm and fairness matter.

00:09:39.028 --> 00:09:41.164
Moral arguments within cultures

00:09:41.188 --> 00:09:44.366
are especially about issues
of in-group, authority, purity.

00:09:44.390 --> 00:09:47.801
This effect is so robust, we find
it no matter how we ask the question.

00:09:47.825 --> 00:09:49.498
In a recent study, we asked people,

00:09:49.522 --> 00:09:51.147
suppose you're about to get a dog,

00:09:51.171 --> 00:09:53.765
you picked a particular breed,
learned about the breed.

00:09:53.789 --> 00:09:56.899
Suppose you learn that this particular
breed is independent-minded

00:09:56.923 --> 00:09:59.272
and relates to its owner
as a friend and an equal.

00:09:59.296 --> 00:10:01.400
If you're a liberal,
you say, "That's great!"

00:10:01.424 --> 00:10:03.578
because liberals like to say,
"Fetch! Please."

00:10:03.602 --> 00:10:08.211
(Laughter)

00:10:08.235 --> 00:10:11.249
But if you're a conservative,
that's not so attractive.

00:10:11.273 --> 00:10:14.132
If you're conservative and learn
that a dog's extremely loyal

00:10:14.156 --> 00:10:15.307
to its home and family

00:10:15.331 --> 00:10:16.907
and doesn't warm up to strangers,

00:10:16.931 --> 00:10:19.702
for conservatives, loyalty is good;
dogs ought to be loyal.

00:10:19.726 --> 00:10:20.878
But to a liberal,

00:10:20.902 --> 00:10:23.961
it sounds like this dog is running
for the Republican nomination.

00:10:23.985 --> 00:10:24.987
(Laughter)

00:10:25.011 --> 00:10:28.597
You might say, OK, there are differences
between liberals and conservatives,

00:10:28.621 --> 00:10:30.909
but what makes the three
other foundations moral?

00:10:30.933 --> 00:10:34.463
Aren't they the foundations of xenophobia,
authoritarianism and puritanism?

00:10:34.487 --> 00:10:35.642
What makes them moral?

00:10:35.666 --> 00:10:39.633
The answer, I think, is contained in this
incredible triptych from Hieronymus Bosch,

00:10:39.657 --> 00:10:41.237
"The Garden of Earthly Delights."

00:10:41.261 --> 00:10:43.890
In the first panel, we see
the moment of creation.

00:10:43.914 --> 00:10:45.831
All is ordered, all is beautiful,

00:10:45.855 --> 00:10:49.197
all the people and animals are doing
what they're supposed to be doing,

00:10:49.221 --> 00:10:50.807
are where they're supposed to be.

00:10:50.831 --> 00:10:53.263
But then, given the way
of the world, things change.

00:10:53.287 --> 00:10:55.350
We get every person doing
whatever he wants,

00:10:55.374 --> 00:10:58.426
with every aperture of every other
person and every other animal.

00:10:58.450 --> 00:11:00.549
Some of you might recognize
this as the '60s.

00:11:00.573 --> 00:11:01.985
(Laughter)

00:11:02.009 --> 00:11:05.437
But the '60s inevitably
gives way to the '70s,

00:11:05.461 --> 00:11:08.876
where the cuttings of the apertures
hurt a little bit more.

00:11:08.900 --> 00:11:11.054
Of course, Bosch called this hell.

00:11:11.078 --> 00:11:15.207
So this triptych, these three panels,

00:11:15.231 --> 00:11:19.520
portray the timeless truth
that order tends to decay.

00:11:19.544 --> 00:11:21.349
The truth of social entropy.

00:11:21.373 --> 00:11:24.664
But lest you think this is just
some part of the Christian imagination

00:11:24.688 --> 00:11:27.272
where Christians have
this weird problem with pleasure,

00:11:27.296 --> 00:11:29.358
here's the same story,
the same progression,

00:11:29.382 --> 00:11:32.351
told in a paper that was published
in "Nature" a few years ago,

00:11:32.375 --> 00:11:36.372
in which Ernst Fehr and Simon Gächter
had people play a commons dilemma,

00:11:36.396 --> 00:11:38.306
a game in which you give people money,

00:11:38.330 --> 00:11:40.048
and then, on each round of the game,

00:11:40.072 --> 00:11:42.105
they can put money into a common pot,

00:11:42.129 --> 00:11:44.137
then the experimenter
doubles what's there,

00:11:44.161 --> 00:11:46.213
and then it's all divided
among the players.

00:11:46.237 --> 00:11:49.134
So it's a nice analog
for all sorts of environmental issues,

00:11:49.158 --> 00:11:51.256
where we're asking people
to make a sacrifice

00:11:51.280 --> 00:11:53.859
and they don't really benefit
from their own sacrifice.

00:11:53.883 --> 00:11:55.944
You really want everybody
else to sacrifice,

00:11:55.968 --> 00:11:58.024
but everybody has
a temptation to free ride.

00:11:58.048 --> 00:12:01.440
What happens is that, at first,
people start off reasonably cooperative.

00:12:01.464 --> 00:12:03.306
This is all played anonymously.

00:12:03.330 --> 00:12:06.880
On the first round, people give
about half of the money that they can.

00:12:06.904 --> 00:12:09.574
But they quickly see
other people aren't doing so much.

00:12:09.598 --> 00:12:11.910
"I don't want to be a sucker.
I won't cooperate."

00:12:11.934 --> 00:12:13.376
So cooperation quickly decays

00:12:13.400 --> 00:12:15.965
from reasonably good
down to close to zero.

00:12:15.989 --> 00:12:17.669
But then -- and here's the trick --

00:12:17.693 --> 00:12:20.125
Fehr and Gächter,
on the seventh round, told people,

00:12:20.149 --> 00:12:21.357
"You know what? New rule.

00:12:21.381 --> 00:12:23.516
If you want to give some of your own money

00:12:23.540 --> 00:12:26.049
to punish people who aren't contributing,

00:12:26.073 --> 00:12:27.428
you can do that."

00:12:27.452 --> 00:12:30.862
And as soon as people heard
about the punishment issue going on,

00:12:30.886 --> 00:12:32.112
cooperation shoots up.

00:12:32.136 --> 00:12:33.825
It shoots up and it keeps going up.

00:12:33.849 --> 00:12:37.384
Lots of research shows that to solve
cooperative problems, it really helps.

00:12:37.408 --> 00:12:39.813
It's not enough to appeal
to people's good motives.

00:12:39.837 --> 00:12:41.814
It helps to have some sort of punishment.

00:12:41.838 --> 00:12:44.229
Even if it's just shame
or embarrassment or gossip,

00:12:44.253 --> 00:12:45.793
you need some sort of punishment

00:12:45.817 --> 00:12:48.630
to bring people, when they're in large
groups, to cooperate.

00:12:48.654 --> 00:12:51.594
There's even some recent research
suggesting that religion --

00:12:51.618 --> 00:12:53.762
priming God, making
people think about God --

00:12:53.786 --> 00:12:57.954
often, in some situations, leads to more
cooperative, more pro-social behavior.

00:12:58.574 --> 00:13:00.814
Some people think
that religion is an adaptation

00:13:00.838 --> 00:13:03.130
evolved both by cultural
and biological evolution

00:13:03.154 --> 00:13:04.880
to make groups to cohere,

00:13:04.904 --> 00:13:07.102
in part for the purpose
of trusting each other

00:13:07.126 --> 00:13:09.758
and being more effective
at competing with other groups.

00:13:09.782 --> 00:13:12.694
That's probably right,
although this is a controversial issue.

00:13:12.718 --> 00:13:16.075
But I'm particularly interested
in religion and the origin of religion

00:13:16.099 --> 00:13:18.185
and in what it does to us and for us,

00:13:18.209 --> 00:13:21.656
because I think the greatest wonder
in the world is not the Grand Canyon.

00:13:21.680 --> 00:13:23.508
The Grand Canyon is really simple --

00:13:23.532 --> 00:13:26.703
a lot of rock and a lot of water
and wind and a lot of time,

00:13:26.727 --> 00:13:28.120
and you get the Grand Canyon.

00:13:28.144 --> 00:13:29.385
It's not that complicated.

00:13:29.409 --> 00:13:30.699
This is what's complicated:

00:13:30.723 --> 00:13:34.572
that people lived in places like the Grand
Canyon, cooperating with each other,

00:13:34.596 --> 00:13:37.473
or on the savannahs of Africa
or the frozen shores of Alaska.

00:13:37.497 --> 00:13:40.848
And some of these villages
grew into the mighty cities of Babylon

00:13:40.872 --> 00:13:42.306
and Rome and Tenochtitlan.

00:13:42.330 --> 00:13:43.481
How did this happen?

00:13:43.505 --> 00:13:46.868
It's an absolute miracle, much harder
to explain than the Grand Canyon.

00:13:46.892 --> 00:13:49.985
The answer, I think, is that they used
every tool in the toolbox.

00:13:50.009 --> 00:13:53.361
It took all of our moral psychology
to create these cooperative groups.

00:13:53.385 --> 00:13:56.957
Yes, you need to be concerned about harm,
you need a psychology of justice.

00:13:56.981 --> 00:13:59.585
But it helps to organize a group
if you have subgroups,

00:13:59.609 --> 00:14:02.306
and if those subgroups
have some internal structure,

00:14:02.330 --> 00:14:04.569
and if you have some ideology
that tells people

00:14:04.593 --> 00:14:08.105
to suppress their carnality --
to pursue higher, nobler ends.

00:14:09.118 --> 00:14:12.824
Now we get to the crux of the disagreement
between liberals and conservatives:

00:14:12.848 --> 00:14:15.093
liberals reject
three of these foundations.

00:14:15.117 --> 00:14:18.457
They say, "Let's celebrate diversity,
not common in-group membership,"

00:14:18.481 --> 00:14:21.695
and, "Let's question authority,"
and, "Keep your laws off my body."

00:14:21.719 --> 00:14:23.968
Liberals have very noble
motives for doing this.

00:14:23.992 --> 00:14:27.542
Traditional authority and morality
can be quite repressive and restrictive

00:14:27.566 --> 00:14:30.433
to those at the bottom, to women,
to people who don't fit in.

00:14:30.457 --> 00:14:32.469
Liberals speak for the weak and oppressed.

00:14:32.493 --> 00:14:35.120
They want change and justice,
even at the risk of chaos.

00:14:35.144 --> 00:14:37.638
This shirt says, "Stop bitching,
start a revolution."

00:14:37.662 --> 00:14:41.640
If you're high in openness to experience,
revolution is good; it's change, it's fun.

00:14:41.664 --> 00:14:45.050
Conservatives, on the other hand,
speak for institutions and traditions.

00:14:45.074 --> 00:14:47.861
They want order, even at some cost,
to those at the bottom.

00:14:47.885 --> 00:14:51.233
The great conservative insight
is that order is really hard to achieve.

00:14:51.257 --> 00:14:53.540
It's precious,
and it's really easy to lose.

00:14:53.564 --> 00:14:55.823
So as Edmund Burke said,
"The restraints on men,

00:14:55.847 --> 00:14:59.000
as well as their liberties,
are to be reckoned among their rights."

00:14:59.024 --> 00:15:01.366
This was after the chaos
of the French Revolution.

00:15:01.390 --> 00:15:03.514
Once you see that liberals
and conservatives

00:15:03.538 --> 00:15:05.204
both have something to contribute,

00:15:05.228 --> 00:15:08.306
that they form a balance
on change versus stability,

00:15:08.330 --> 00:15:11.306
then I think the way is open
to step outside the moral Matrix.

00:15:11.979 --> 00:15:13.415
This is the great insight

00:15:13.439 --> 00:15:15.966
that all the Asian religions
have attained.

00:15:16.330 --> 00:15:17.572
Think about yin and yang.

00:15:17.596 --> 00:15:20.236
Yin and yang aren't enemies;
they don't hate each other.

00:15:20.260 --> 00:15:22.849
Yin and yang are both necessary,
like night and day,

00:15:22.873 --> 00:15:24.466
for the functioning of the world.

00:15:24.490 --> 00:15:26.216
You find the same thing in Hinduism.

00:15:26.240 --> 00:15:28.014
There are many high gods in Hinduism.

00:15:28.038 --> 00:15:31.053
Two of them are Vishnu, the preserver,
and Shiva, the destroyer.

00:15:31.077 --> 00:15:33.130
This image, actually,
is both of those gods

00:15:33.154 --> 00:15:34.379
sharing the same body.

00:15:34.403 --> 00:15:36.842
You have the markings
of Vishnu on the left,

00:15:36.866 --> 00:15:39.306
so we could think of Vishnu
as the conservative god.

00:15:39.330 --> 00:15:42.696
You have the markings of Shiva
on the right -- Shiva's the liberal god.

00:15:42.720 --> 00:15:43.879
And they work together.

00:15:43.903 --> 00:15:45.629
You find the same thing in Buddhism.

00:15:45.653 --> 00:15:48.278
These two stanzas contain,
I think, the deepest insights

00:15:48.302 --> 00:15:50.692
that have ever been attained
into moral psychology.

00:15:50.716 --> 00:15:52.893
From the Zen master Sēngcàn:

00:15:52.917 --> 00:15:57.020
"If you want the truth to stand clear
before you, never be 'for' or 'against.'

00:15:57.044 --> 00:16:00.364
The struggle between 'for' and 'against'
is the mind's worst disease."

00:16:00.821 --> 00:16:03.539
Unfortunately, it's a disease
that has been caught

00:16:03.563 --> 00:16:05.055
by many of the world's leaders.

00:16:05.079 --> 00:16:07.170
But before you feel
superior to George Bush,

00:16:07.194 --> 00:16:09.388
before you throw a stone, ask yourself:

00:16:09.412 --> 00:16:10.592
Do you accept this?

00:16:11.418 --> 00:16:14.670
Do you accept stepping out
of the battle of good and evil?

00:16:14.694 --> 00:16:17.137
Can you be not for or against anything?

00:16:17.842 --> 00:16:20.612
So what's the point? What should you do?

00:16:20.636 --> 00:16:23.204
Well, if you take the greatest insights

00:16:23.228 --> 00:16:25.332
from ancient Asian
philosophies and religions

00:16:25.356 --> 00:16:28.293
and combine them with the latest
research on moral psychology,

00:16:28.317 --> 00:16:30.127
I think you come to these conclusions:

00:16:30.151 --> 00:16:33.306
that our righteous minds
were designed by evolution

00:16:33.330 --> 00:16:34.987
to unite us into teams,

00:16:35.011 --> 00:16:36.552
to divide us against other teams

00:16:36.576 --> 00:16:38.276
and then to blind us to the truth.

00:16:39.649 --> 00:16:41.566
So what should you do?

00:16:41.590 --> 00:16:43.450
Am I telling you to not strive?

00:16:43.474 --> 00:16:46.178
Am I telling you to embrace
Sēngcàn and stop,

00:16:46.202 --> 00:16:49.072
stop with the struggle of for and against?

00:16:49.096 --> 00:16:51.306
No, absolutely not. I'm not saying that.

00:16:51.330 --> 00:16:54.306
This is an amazing group of people
who are doing so much,

00:16:54.330 --> 00:16:56.068
using so much of their talent,

00:16:56.092 --> 00:16:58.150
their brilliance,
their energy, their money,

00:16:58.174 --> 00:16:59.770
to make the world a better place,

00:16:59.794 --> 00:17:01.525
to fight wrongs,

00:17:01.549 --> 00:17:02.829
to solve problems.

00:17:04.186 --> 00:17:06.506
But as we learned from Samantha Power

00:17:06.530 --> 00:17:11.338
in her story about Sérgio Vieira de Mello,

00:17:11.362 --> 00:17:15.607
you can't just go charging in,
saying, "You're wrong, and I'm right,"

00:17:15.631 --> 00:17:19.044
because, as we just heard,
everybody thinks they are right.

00:17:19.068 --> 00:17:20.926
A lot of the problems we have to solve

00:17:20.950 --> 00:17:23.447
are problems that require us
to change other people.

00:17:23.940 --> 00:17:25.883
And if you want to change other people,

00:17:25.907 --> 00:17:29.065
a much better way to do it
is to first understand who we are --

00:17:29.089 --> 00:17:30.727
understand our moral psychology,

00:17:30.751 --> 00:17:33.347
understand that we all
think we're right --

00:17:33.371 --> 00:17:34.634
and then step out,

00:17:34.658 --> 00:17:38.353
even if it's just for a moment,
step out -- check in with Sēngcàn.

00:17:38.898 --> 00:17:40.306
Step out of the moral Matrix,

00:17:40.330 --> 00:17:42.429
just try to see it
as a struggle playing out,

00:17:42.453 --> 00:17:46.071
in which everybody thinks they're right,
and even if you disagree with them,

00:17:46.095 --> 00:17:48.459
everybody has some reasons
for what they're doing.

00:17:48.483 --> 00:17:49.634
Step out.

00:17:49.658 --> 00:17:53.144
And if you do that, that's the essential
move to cultivate moral humility,

00:17:53.168 --> 00:17:55.370
to get yourself out
of this self-righteousness,

00:17:55.394 --> 00:17:57.113
which is the normal human condition.

00:17:57.137 --> 00:17:58.452
Think about the Dalai Lama.

00:17:58.476 --> 00:18:01.306
Think about the enormous
moral authority of the Dalai Lama.

00:18:01.330 --> 00:18:03.107
It comes from his moral humility.

00:18:05.028 --> 00:18:06.362
So I think the point --

00:18:06.386 --> 00:18:10.600
the point of my talk
and, I think, the point of TED --

00:18:10.624 --> 00:18:13.306
is that this is a group
that is passionately engaged

00:18:13.330 --> 00:18:15.807
in the pursuit of changing
the world for the better.

00:18:15.831 --> 00:18:17.833
People here are passionately engaged

00:18:17.857 --> 00:18:19.888
in trying to make
the world a better place.

00:18:19.912 --> 00:18:22.756
But there is also a passionate
commitment to the truth.

00:18:23.329 --> 00:18:28.203
And so I think the answer is to use
that passionate commitment to the truth

00:18:28.227 --> 00:18:31.070
to try to turn it
into a better future for us all.

00:18:31.094 --> 00:18:32.306
Thank you.

00:18:32.330 --> 00:18:37.583
(Applause)

