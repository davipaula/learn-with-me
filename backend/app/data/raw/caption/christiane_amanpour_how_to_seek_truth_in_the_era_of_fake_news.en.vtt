WEBVTT
Kind: captions
Language: en

00:00:12.931 --> 00:00:15.268
Chris Anderson: Christiane,
great to have you here.

00:00:15.292 --> 00:00:17.135
So you've had this amazing viewpoint,

00:00:17.159 --> 00:00:20.219
and perhaps it's fair to say
that in the last few years,

00:00:20.243 --> 00:00:23.996
there have been some alarming
developments that you're seeing.

00:00:24.020 --> 00:00:25.584
What's alarmed you most?

00:00:25.608 --> 00:00:28.800
Christiane Amanpour: Well, just listening
to the earlier speakers,

00:00:28.824 --> 00:00:31.296
I can frame it
in what they've been saying:

00:00:31.320 --> 00:00:34.742
climate change, for instance --
cities, the threat to our environment

00:00:34.766 --> 00:00:36.026
and our lives.

00:00:36.440 --> 00:00:40.334
It basically also boils down to
understanding the truth

00:00:40.358 --> 00:00:43.369
and to be able to get to the truth
of what we're talking about

00:00:43.393 --> 00:00:45.485
in order to really be able to solve it.

00:00:45.509 --> 00:00:49.436
So if 99.9 percent
of the science on climate

00:00:49.460 --> 00:00:52.517
is empirical, scientific evidence,

00:00:52.541 --> 00:00:57.436
but it's competing almost equally
with a handful of deniers,

00:00:57.460 --> 00:00:58.687
that is not the truth;

00:00:58.711 --> 00:01:01.209
that is the epitome of fake news.

00:01:01.233 --> 00:01:06.335
And so for me, the last few years --
certainly this last year --

00:01:06.359 --> 00:01:10.619
has crystallized the notion of fake news
in a way that's truly alarming

00:01:10.643 --> 00:01:13.302
and not just some slogan
to be thrown around.

00:01:13.326 --> 00:01:17.137
Because when you can't distinguish
between the truth and fake news,

00:01:17.161 --> 00:01:21.052
you have a very much more
difficult time trying to solve

00:01:21.076 --> 00:01:23.527
some of the great issues that we face.

00:01:24.512 --> 00:01:27.933
CA: Well, you've been involved
in this question of,

00:01:27.957 --> 00:01:30.869
what is balance, what is truth,
what is impartiality,

00:01:30.893 --> 00:01:32.148
for a long time.

00:01:32.172 --> 00:01:38.042
You were on the front lines
reporting the Balkan Wars 25 years ago.

00:01:38.066 --> 00:01:41.478
And back then, you famously said,

00:01:41.502 --> 00:01:44.123
by calling out human right abuses,

00:01:44.147 --> 00:01:48.476
you said, "Look, there are some situations
one simply cannot be neutral about,

00:01:48.500 --> 00:01:49.880
because when you're neutral,

00:01:49.904 --> 00:01:51.791
you are an accomplice."

00:01:53.243 --> 00:01:58.140
So, do you feel that today's journalists
aren't heeding that advice

00:01:58.164 --> 00:01:59.636
about balance?

00:01:59.660 --> 00:02:03.766
CA: Well, look, I think for journalists,
objectivity is the golden rule.

00:02:03.790 --> 00:02:08.206
But I think sometimes we don't understand
what objectivity means.

00:02:08.230 --> 00:02:11.224
And I actually learned this very,
very young in my career,

00:02:11.248 --> 00:02:12.820
which was during the Balkan Wars.

00:02:12.844 --> 00:02:14.060
I was young then.

00:02:14.084 --> 00:02:16.623
It was about 25 years ago.

00:02:16.647 --> 00:02:22.428
And what we faced was the wholesale
violation, not just of human rights,

00:02:22.452 --> 00:02:25.431
but all the way to ethnic
cleansing and genocide,

00:02:25.455 --> 00:02:29.461
and that has been adjudicated
in the highest war crimes court

00:02:29.485 --> 00:02:30.649
in the world.

00:02:30.673 --> 00:02:32.326
So, we know what we were seeing.

00:02:32.350 --> 00:02:34.887
Trying to tell the world
what we were seeing

00:02:34.911 --> 00:02:37.686
brought us accusations of bias,

00:02:37.710 --> 00:02:39.599
of siding with one side,

00:02:39.623 --> 00:02:41.485
of not seeing the whole side,

00:02:41.509 --> 00:02:43.806
and just, you know,
trying to tell one story.

00:02:43.830 --> 00:02:48.137
I particularly and personally
was accused of siding with,

00:02:48.161 --> 00:02:50.143
for instance, the citizens of Sarajevo --

00:02:50.167 --> 00:02:51.594
"siding with the Muslims,"

00:02:51.618 --> 00:02:54.670
because they were the minority
who were being attacked

00:02:54.694 --> 00:02:58.432
by Christians on the Serb side

00:02:58.456 --> 00:03:00.175
in this area.

00:03:00.199 --> 00:03:01.541
And it worried me.

00:03:01.565 --> 00:03:03.756
It worried me that I was being
accused of this.

00:03:03.780 --> 00:03:05.122
I thought maybe I was wrong,

00:03:05.146 --> 00:03:07.494
maybe I'd forgotten what objectivity was.

00:03:07.518 --> 00:03:10.525
But then I started to understand
that what people wanted

00:03:10.549 --> 00:03:12.347
was actually not to do anything --

00:03:12.371 --> 00:03:13.788
not to step in,

00:03:13.812 --> 00:03:15.382
not to change the situation,

00:03:15.406 --> 00:03:16.855
not to find a solution.

00:03:16.879 --> 00:03:19.232
And so, their fake news at that time,

00:03:19.256 --> 00:03:20.638
their lie at that time --

00:03:20.662 --> 00:03:24.192
including our government's,
our democratically elected government's,

00:03:24.216 --> 00:03:26.488
with values and principles
of human rights --

00:03:26.512 --> 00:03:30.019
their lie was to say
that all sides are equally guilty,

00:03:30.043 --> 00:03:32.836
that this has been centuries
of ethnic hatred,

00:03:32.860 --> 00:03:34.742
whereas we knew that wasn't true,

00:03:34.766 --> 00:03:38.413
that one side had decided to kill,
slaughter and ethnically cleanse

00:03:38.437 --> 00:03:39.594
another side.

00:03:39.618 --> 00:03:41.114
So that is where, for me,

00:03:41.138 --> 00:03:46.444
I understood that objectivity means
giving all sides an equal hearing

00:03:46.468 --> 00:03:48.573
and talking to all sides,

00:03:48.597 --> 00:03:52.219
but not treating all sides equally,

00:03:52.243 --> 00:03:57.031
not creating a forced moral equivalence
or a factual equivalence.

00:03:57.055 --> 00:04:01.534
And when you come up against
that crisis point

00:04:01.558 --> 00:04:07.229
in situations of grave violations
of international and humanitarian law,

00:04:07.253 --> 00:04:09.595
if you don't understand
what you're seeing,

00:04:09.619 --> 00:04:11.779
if you don't understand the truth

00:04:11.803 --> 00:04:15.316
and if you get trapped
in the fake news paradigm,

00:04:15.340 --> 00:04:16.930
then you are an accomplice.

00:04:17.658 --> 00:04:20.655
And I refuse to be
an accomplice to genocide.

00:04:20.679 --> 00:04:23.962
(Applause)

00:04:26.402 --> 00:04:29.180
CH: So there have always been
these propaganda battles,

00:04:29.204 --> 00:04:33.230
and you were courageous in taking
the stand you took back then.

00:04:33.652 --> 00:04:37.379
Today, there's a whole new way, though,

00:04:37.403 --> 00:04:39.607
in which news seems to be becoming fake.

00:04:39.631 --> 00:04:41.265
How would you characterize that?

00:04:41.289 --> 00:04:43.373
CA: Well, look -- I am really alarmed.

00:04:43.397 --> 00:04:45.599
And everywhere I look,

00:04:45.623 --> 00:04:47.460
you know, we're buffeted by it.

00:04:47.484 --> 00:04:49.686
Obviously, when the leader
of the free world,

00:04:49.710 --> 00:04:52.183
when the most powerful person
in the entire world,

00:04:52.207 --> 00:04:54.453
which is the president
of the United States --

00:04:54.477 --> 00:04:59.296
this is the most important, most powerful
country in the whole world,

00:04:59.320 --> 00:05:03.560
economically, militarily, politically
in every which way --

00:05:04.415 --> 00:05:09.432
and it seeks to, obviously, promote
its values and power around the world.

00:05:09.456 --> 00:05:13.432
So we journalists,
who only seek the truth --

00:05:13.456 --> 00:05:14.977
I mean, that is our mission --

00:05:15.001 --> 00:05:17.118
we go around the world
looking for the truth

00:05:17.142 --> 00:05:19.115
in order to be everybody's eyes and ears,

00:05:19.139 --> 00:05:21.658
people who can't go out
in various parts of the world

00:05:21.682 --> 00:05:25.051
to figure out what's going on
about things that are vitally important

00:05:25.075 --> 00:05:27.031
to everybody's health and security.

00:05:27.055 --> 00:05:33.741
So when you have a major world leader
accusing you of fake news,

00:05:33.765 --> 00:05:37.608
it has an exponential ripple effect.

00:05:37.632 --> 00:05:41.904
And what it does is,
it starts to chip away

00:05:42.472 --> 00:05:45.360
at not just our credibility,

00:05:45.384 --> 00:05:47.413
but at people's minds --

00:05:48.372 --> 00:05:50.736
people who look at us,
and maybe they're thinking,

00:05:50.760 --> 00:05:53.429
"Well, if the president
of the United States says that,

00:05:53.453 --> 00:05:55.588
maybe somewhere there's a truth in there."

00:05:56.148 --> 00:06:00.332
CH: Presidents have always
been critical of the media --

00:06:00.356 --> 00:06:01.957
CA: Not in this way.

00:06:01.981 --> 00:06:03.486
CH: So, to what extent --

00:06:03.510 --> 00:06:04.574
(Laughter)

00:06:04.598 --> 00:06:07.718
(Applause)

00:06:07.742 --> 00:06:14.638
CH: I mean, someone a couple years ago
looking at the avalanche of information

00:06:14.662 --> 00:06:17.898
pouring through Twitter
and Facebook and so forth,

00:06:17.922 --> 00:06:19.080
might have said,

00:06:19.104 --> 00:06:21.945
"Look, our democracies are healthier
than they've ever been.

00:06:21.969 --> 00:06:23.490
There's more news than ever.

00:06:23.514 --> 00:06:25.725
Of course presidents
will say what they'll say,

00:06:25.749 --> 00:06:27.982
but everyone else can say
what they will say.

00:06:28.006 --> 00:06:32.161
What's not to like?
How is there an extra danger?"

00:06:32.185 --> 00:06:33.727
CA: So, I wish that was true.

00:06:34.992 --> 00:06:41.085
I wish that the proliferation of platforms
upon which we get our information

00:06:41.109 --> 00:06:44.987
meant that there was a proliferation
of truth and transparency

00:06:45.011 --> 00:06:46.879
and depth and accuracy.

00:06:46.903 --> 00:06:49.358
But I think the opposite has happened.

00:06:49.382 --> 00:06:51.472
You know, I'm a little bit of a Luddite,

00:06:51.496 --> 00:06:52.692
I will confess.

00:06:53.147 --> 00:06:56.531
Even when we started to talk about
the information superhighway,

00:06:56.555 --> 00:06:58.183
which was a long time ago,

00:06:58.207 --> 00:07:00.858
before social media, Twitter
and all the rest of it,

00:07:00.882 --> 00:07:02.706
I was actually really afraid

00:07:02.730 --> 00:07:06.751
that that would put people
into certain lanes and tunnels

00:07:06.775 --> 00:07:11.117
and have them just focusing
on areas of their own interest

00:07:11.141 --> 00:07:13.474
instead of seeing the broad picture.

00:07:13.498 --> 00:07:18.084
And I'm afraid to say
that with algorithms, with logarithms,

00:07:18.108 --> 00:07:19.756
with whatever the "-ithms" are

00:07:19.780 --> 00:07:24.046
that direct us into all these particular
channels of information,

00:07:24.070 --> 00:07:25.940
that seems to be happening right now.

00:07:25.964 --> 00:07:28.508
I mean, people have written
about this phenomenon.

00:07:28.532 --> 00:07:30.730
People have said that yes,
the internet came,

00:07:30.754 --> 00:07:36.497
its promise was to exponentially explode
our access to more democracy,

00:07:36.521 --> 00:07:38.235
more information,

00:07:38.259 --> 00:07:40.151
less bias,

00:07:40.175 --> 00:07:42.564
more varied information.

00:07:42.588 --> 00:07:44.913
And, in fact, the opposite has happened.

00:07:44.937 --> 00:07:48.955
And so that, for me,
is incredibly dangerous.

00:07:48.979 --> 00:07:53.494
And again, when you are the president
of this country and you say things,

00:07:53.518 --> 00:07:58.943
it also gives leaders in other
undemocratic countries the cover

00:08:00.009 --> 00:08:02.315
to affront us even worse,

00:08:02.339 --> 00:08:05.199
and to really whack us --
and their own journalists --

00:08:05.223 --> 00:08:07.046
with this bludgeon of fake news.

00:08:08.000 --> 00:08:10.184
CH: To what extent
is what happened, though,

00:08:10.208 --> 00:08:12.274
in part, just an unintended consequence,

00:08:12.298 --> 00:08:15.100
that the traditional
media that you worked in

00:08:15.124 --> 00:08:17.204
had this curation-mediation role,

00:08:17.228 --> 00:08:19.254
where certain norms were observed,

00:08:19.278 --> 00:08:22.431
certain stories would be rejected
because they weren't credible,

00:08:22.455 --> 00:08:28.954
but now that the standard
for publication and for amplification

00:08:28.978 --> 00:08:32.306
is just interest, attention,
excitement, click,

00:08:32.330 --> 00:08:33.493
"Did it get clicked on?"

00:08:33.517 --> 00:08:34.672
"Send it out there!"

00:08:34.696 --> 00:08:38.200
and that's what's --
is that part of what's caused the problem?

00:08:38.224 --> 00:08:41.819
CA: I think it's a big problem,
and we saw this in the election of 2016,

00:08:41.843 --> 00:08:46.950
where the idea of "clickbait"
was very sexy and very attractive,

00:08:46.974 --> 00:08:51.280
and so all these fake news sites
and fake news items

00:08:51.304 --> 00:08:55.426
were not just haphazardly
and by happenstance being put out there,

00:08:55.450 --> 00:08:59.901
there's been a whole industry
in the creation of fake news

00:08:59.925 --> 00:09:02.915
in parts of Eastern Europe, wherever,

00:09:02.939 --> 00:09:06.199
and you know, it's planted
in real space and in cyberspace.

00:09:06.223 --> 00:09:08.582
So I think that, also,

00:09:08.606 --> 00:09:13.727
the ability of our technology
to proliferate this stuff

00:09:13.751 --> 00:09:17.262
at the speed of sound
or light, just about --

00:09:17.286 --> 00:09:19.269
we've never faced that before.

00:09:19.293 --> 00:09:24.160
And we've never faced
such a massive amount of information

00:09:24.184 --> 00:09:25.749
which is not curated

00:09:25.773 --> 00:09:31.069
by those whose profession
leads them to abide by the truth,

00:09:31.093 --> 00:09:32.295
to fact-check

00:09:32.319 --> 00:09:37.153
and to maintain a code of conduct
and a code of professional ethics.

00:09:37.177 --> 00:09:40.520
CH: Many people here may know
people who work at Facebook

00:09:40.544 --> 00:09:42.868
or Twitter and Google and so on.

00:09:42.892 --> 00:09:46.024
They all seem like great people
with good intention --

00:09:46.048 --> 00:09:47.428
let's assume that.

00:09:47.452 --> 00:09:51.127
If you could speak with the leaders
of those companies,

00:09:51.151 --> 00:09:52.442
what would you say to them?

00:09:52.466 --> 00:09:54.235
CA: Well, you know what --

00:09:54.259 --> 00:09:56.603
I'm sure they are
incredibly well-intentioned,

00:09:56.627 --> 00:10:01.845
and they certainly developed
an unbelievable, game-changing system,

00:10:01.869 --> 00:10:05.080
where everybody's connected
on this thing called Facebook.

00:10:05.104 --> 00:10:08.905
And they've created a massive
economy for themselves

00:10:08.929 --> 00:10:11.609
and an amazing amount of income.

00:10:11.633 --> 00:10:12.813
I would just say,

00:10:12.837 --> 00:10:17.071
"Guys, you know, it's time
to wake up and smell the coffee

00:10:17.095 --> 00:10:19.797
and look at what's happening
to us right now."

00:10:19.821 --> 00:10:22.753
Mark Zuckerberg wants to create
a global community.

00:10:22.777 --> 00:10:25.996
I want to know: What is that global
community going to look like?

00:10:26.020 --> 00:10:30.087
I want to know where the codes
of conduct actually are.

00:10:30.111 --> 00:10:31.936
Mark Zuckerberg said --

00:10:31.960 --> 00:10:34.678
and I don't blame him,
he probably believed this --

00:10:34.702 --> 00:10:37.058
that it was crazy to think

00:10:37.082 --> 00:10:41.191
that the Russians or anybody else
could be tinkering and messing around

00:10:41.215 --> 00:10:42.458
with this avenue.

00:10:42.482 --> 00:10:44.964
And what have we just learned
in the last few weeks?

00:10:44.988 --> 00:10:47.946
That, actually, there has been
a major problem in that regard,

00:10:47.970 --> 00:10:51.088
and now they're having to investigate it
and figure it out.

00:10:51.112 --> 00:10:54.391
Yes, they're trying to do
what they can now

00:10:54.415 --> 00:10:56.573
to prevent the rise of fake news,

00:10:56.597 --> 00:10:57.980
but, you know,

00:10:58.004 --> 00:11:03.095
it went pretty unrestricted
for a long, long time.

00:11:03.119 --> 00:11:05.019
So I guess I would say, you know,

00:11:05.043 --> 00:11:07.142
you guys are brilliant at technology;

00:11:07.166 --> 00:11:09.057
let's figure out another algorithm.

00:11:09.081 --> 00:11:10.252
Can we not?

00:11:10.276 --> 00:11:13.163
CH: An algorithm that includes
journalistic investigation --

00:11:13.187 --> 00:11:16.543
CA: I don't really know how they do it,
but somehow, you know --

00:11:16.567 --> 00:11:18.386
filter out the crap!

00:11:18.410 --> 00:11:19.560
(Laughter)

00:11:19.584 --> 00:11:21.586
And not just the unintentional --

00:11:21.610 --> 00:11:24.864
(Applause)

00:11:24.888 --> 00:11:27.094
but the deliberate lies that are planted

00:11:27.118 --> 00:11:31.443
by people who've been doing this
as a matter of warfare

00:11:31.467 --> 00:11:32.769
for decades.

00:11:32.793 --> 00:11:34.726
The Soviets, the Russians --

00:11:34.750 --> 00:11:39.994
they are the masters of war
by other means, of hybrid warfare.

00:11:40.618 --> 00:11:42.062
And this is a --

00:11:42.689 --> 00:11:45.673
this is what they've decided to do.

00:11:45.697 --> 00:11:47.302
It worked in the United States,

00:11:47.326 --> 00:11:48.647
it didn't work in France,

00:11:48.671 --> 00:11:50.344
it hasn't worked in Germany.

00:11:50.368 --> 00:11:53.309
During the elections there,
where they've tried to interfere,

00:11:53.333 --> 00:11:55.935
the president of France
right now, Emmanuel Macron,

00:11:55.959 --> 00:11:58.482
took a very tough stand
and confronted it head on,

00:11:58.506 --> 00:11:59.664
as did Angela Merkel.

00:11:59.688 --> 00:12:02.673
CH: There's some hope to be had
from some of this, isn't there?

00:12:02.697 --> 00:12:03.848
That the world learns.

00:12:03.872 --> 00:12:05.190
We get fooled once,

00:12:05.214 --> 00:12:06.546
maybe we get fooled again,

00:12:06.570 --> 00:12:08.025
but maybe not the third time.

00:12:08.049 --> 00:12:09.217
Is that true?

00:12:09.241 --> 00:12:10.397
CA: I mean, let's hope.

00:12:10.421 --> 00:12:13.808
But I think in this regard that so much
of it is also about technology,

00:12:13.832 --> 00:12:17.277
that the technology has to also be given
some kind of moral compass.

00:12:17.301 --> 00:12:20.117
I know I'm talking nonsense,
but you know what I mean.

00:12:20.141 --> 00:12:23.849
CH: We need a filter-the-crap algorithm
with a moral compass --

00:12:23.873 --> 00:12:25.030
CA: There you go.

00:12:25.054 --> 00:12:26.206
CH: I think that's good.

00:12:26.230 --> 00:12:27.901
CA: No -- "moral technology."

00:12:27.925 --> 00:12:31.031
We all have moral compasses --
moral technology.

00:12:31.055 --> 00:12:34.034
CH: I think that's a great challenge.
CA: You know what I mean.

00:12:34.058 --> 00:12:36.002
CH: Talk just a minute about leadership.

00:12:36.026 --> 00:12:39.162
You've had a chance to speak
with so many people across the world.

00:12:39.186 --> 00:12:40.425
I think for some of us --

00:12:40.449 --> 00:12:43.141
I speak for myself,
I don't know if others feel this --

00:12:43.165 --> 00:12:45.161
there's kind of been a disappointment of:

00:12:45.185 --> 00:12:47.044
Where are the leaders?

00:12:47.068 --> 00:12:49.382
So many of us have been disappointed --

00:12:49.406 --> 00:12:51.422
Aung San Suu Kyi,
what's happened recently,

00:12:51.446 --> 00:12:53.531
it's like, "No! Another one
bites the dust."

00:12:53.555 --> 00:12:55.154
You know, it's heartbreaking.

00:12:55.178 --> 00:12:56.413
(Laughter)

00:12:56.437 --> 00:12:58.458
Who have you met

00:12:58.482 --> 00:13:01.352
who you have been
impressed by, inspired by?

00:13:01.376 --> 00:13:03.880
CA: Well, you talk about
the world in crisis,

00:13:03.904 --> 00:13:05.258
which is absolutely true,

00:13:05.282 --> 00:13:09.769
and those of us who spend our whole lives
immersed in this crisis --

00:13:09.793 --> 00:13:12.786
I mean, we're all on the verge
of a nervous breakdown.

00:13:12.810 --> 00:13:15.486
So it's pretty stressful right now.

00:13:15.510 --> 00:13:16.669
And you're right --

00:13:16.693 --> 00:13:19.803
there is this perceived and actual
vacuum of leadership,

00:13:19.827 --> 00:13:22.677
and it's not me saying it,
I ask all these --

00:13:22.701 --> 00:13:25.154
whoever I'm talking to,
I ask about leadership.

00:13:25.178 --> 00:13:29.688
I was speaking to the outgoing
president of Liberia today,

00:13:29.712 --> 00:13:31.522
[Ellen Johnson Sirleaf,]

00:13:31.546 --> 00:13:32.700
who --

00:13:32.724 --> 00:13:34.939
(Applause)

00:13:34.963 --> 00:13:36.505
in three weeks' time,

00:13:36.529 --> 00:13:40.473
will be one of the very rare
heads of an African country

00:13:40.497 --> 00:13:42.675
who actually abides by the constitution

00:13:42.699 --> 00:13:46.311
and gives up power
after her prescribed term.

00:13:46.335 --> 00:13:50.192
She has said she wants
to do that as a lesson.

00:13:50.216 --> 00:13:52.248
But when I asked her about leadership,

00:13:52.272 --> 00:13:54.955
and I gave a quick-fire round
of certain names,

00:13:54.979 --> 00:13:57.956
I presented her with the name
of the new French president,

00:13:57.980 --> 00:13:59.413
Emmanuel Macron.

00:13:59.437 --> 00:14:00.773
And she said --

00:14:00.797 --> 00:14:03.303
I said, "So what do you think
when I say his name?"

00:14:03.327 --> 00:14:04.600
And she said,

00:14:05.578 --> 00:14:07.903
"Shaping up potentially to be

00:14:07.927 --> 00:14:11.993
a leader to fill our current
leadership vacuum."

00:14:12.017 --> 00:14:13.850
I thought that was really interesting.

00:14:13.874 --> 00:14:16.330
Yesterday, I happened to have
an interview with him.

00:14:16.354 --> 00:14:17.512
I'm very proud to say,

00:14:17.536 --> 00:14:20.955
I got his first international interview.
It was great. It was yesterday.

00:14:20.979 --> 00:14:22.271
And I was really impressed.

00:14:22.295 --> 00:14:25.223
I don't know whether I should be
saying that in an open forum,

00:14:25.247 --> 00:14:26.702
but I was really impressed.

00:14:26.726 --> 00:14:27.944
(Laughter)

00:14:28.867 --> 00:14:31.542
And it could be just because
it was his first interview,

00:14:31.566 --> 00:14:33.661
but -- I asked questions,
and you know what?

00:14:33.685 --> 00:14:34.893
He answered them!

00:14:34.917 --> 00:14:36.850
(Laughter)

00:14:36.874 --> 00:14:40.143
(Applause)

00:14:40.167 --> 00:14:41.760
There was no spin,

00:14:41.784 --> 00:14:44.175
there was no wiggle and waggle,

00:14:44.199 --> 00:14:47.028
there was no spend-five-minutes-
to-come-back-to-the-point.

00:14:47.052 --> 00:14:48.720
I didn't have to keep interrupting,

00:14:48.744 --> 00:14:50.827
which I've become rather
renowned for doing,

00:14:50.851 --> 00:14:53.383
because I want people
to answer the question.

00:14:53.407 --> 00:14:55.458
And he answered me,

00:14:55.482 --> 00:14:58.096
and it was pretty interesting.

00:14:58.120 --> 00:14:59.551
And he said --

00:14:59.575 --> 00:15:01.353
CH: Tell me what he said.

00:15:01.377 --> 00:15:02.597
CA: No, no, you go ahead.

00:15:02.621 --> 00:15:04.849
CH: You're the interrupter,
I'm the listener.

00:15:04.873 --> 00:15:06.031
CA: No, no, go ahead.

00:15:06.055 --> 00:15:07.210
CH: What'd he say?

00:15:07.234 --> 00:15:10.312
CA: OK. You've talked about
nationalism and tribalism here today.

00:15:10.336 --> 00:15:14.098
I asked him, "How did you have the guts
to confront the prevailing winds

00:15:14.122 --> 00:15:18.657
of anti-globalization,
nationalism, populism

00:15:18.681 --> 00:15:20.643
when you can see what happened in Brexit,

00:15:20.667 --> 00:15:23.222
when you could see what happened
in the United States

00:15:23.246 --> 00:15:25.841
and what might have happened
in many European elections

00:15:25.865 --> 00:15:27.582
at the beginning of 2017?"

00:15:27.606 --> 00:15:28.925
And he said,

00:15:29.597 --> 00:15:32.871
"For me, nationalism means war.

00:15:33.486 --> 00:15:35.159
We have seen it before,

00:15:35.183 --> 00:15:37.441
we have lived through it before
on my continent,

00:15:37.465 --> 00:15:40.151
and I am very clear about that."

00:15:40.175 --> 00:15:44.136
So he was not going to,
just for political expediency,

00:15:44.160 --> 00:15:47.602
embrace the, kind of, lowest
common denominator

00:15:47.626 --> 00:15:51.631
that had been embraced
in other political elections.

00:15:51.655 --> 00:15:56.096
And he stood against Marine Le Pen,
who is a very dangerous woman.

00:15:56.928 --> 00:15:58.960
CH: Last question for you, Christiane.

00:16:00.093 --> 00:16:02.091
TED is about ideas worth spreading.

00:16:02.115 --> 00:16:06.762
If you could plant one idea
into the minds of everyone here,

00:16:06.786 --> 00:16:07.983
what would that be?

00:16:08.007 --> 00:16:13.121
CA: I would say really be careful
where you get your information from;

00:16:13.145 --> 00:16:18.467
really take responsibility
for what you read, listen to and watch;

00:16:18.491 --> 00:16:23.378
make sure that you go to the trusted
brands to get your main information,

00:16:23.402 --> 00:16:28.091
no matter whether you have
a wide, eclectic intake,

00:16:28.115 --> 00:16:31.110
really stick with the brand
names that you know,

00:16:31.134 --> 00:16:34.726
because in this world right now,
at this moment right now,

00:16:34.750 --> 00:16:39.089
our crises, our challenges,
our problems are so severe,

00:16:39.113 --> 00:16:42.664
that unless we are all engaged
as global citizens

00:16:42.688 --> 00:16:44.591
who appreciate the truth,

00:16:44.615 --> 00:16:48.960
who understand science,
empirical evidence and facts,

00:16:48.984 --> 00:16:52.483
then we are just simply
going to be wandering along

00:16:52.507 --> 00:16:54.468
to a potential catastrophe.

00:16:54.492 --> 00:16:55.856
So I would say, the truth,

00:16:55.880 --> 00:16:58.136
and then I would come back
to Emmanuel Macron

00:16:58.160 --> 00:16:59.460
and talk about love.

00:17:00.022 --> 00:17:04.491
I would say that there's not
enough love going around.

00:17:04.515 --> 00:17:07.207
And I asked him to tell me about love.

00:17:07.231 --> 00:17:10.823
I said, "You know, your marriage
is the subject of global obsession."

00:17:10.847 --> 00:17:12.482
(Laughter)

00:17:12.506 --> 00:17:13.919
"Can you tell me about love?

00:17:13.943 --> 00:17:15.257
What does it mean to you?"

00:17:15.281 --> 00:17:18.222
I've never asked a president
or an elected leader about love.

00:17:18.246 --> 00:17:19.404
I thought I'd try it.

00:17:19.428 --> 00:17:23.343
And he said -- you know,
he actually answered it.

00:17:23.367 --> 00:17:27.528
And he said, "I love my wife,
she is part of me,

00:17:27.552 --> 00:17:29.179
we've been together for decades."

00:17:29.203 --> 00:17:30.888
But here's where it really counted,

00:17:30.912 --> 00:17:32.415
what really stuck with me.

00:17:32.439 --> 00:17:33.680
He said,

00:17:33.704 --> 00:17:37.224
"It is so important for me
to have somebody at home

00:17:37.248 --> 00:17:39.147
who tells me the truth."

00:17:40.618 --> 00:17:43.330
So you see, I brought it home.
It's all about the truth.

00:17:43.354 --> 00:17:44.360
(Laughter)

00:17:44.384 --> 00:17:47.191
CH: So there you go. Truth and love.
Ideas worth spreading.

00:17:47.215 --> 00:17:49.878
Christiane Amanpour, thank you
so much. That was great.

00:17:49.902 --> 00:17:50.970
(Applause)

00:17:50.994 --> 00:17:53.328
CA: Thank you.
CH: That was really lovely.

00:17:53.352 --> 00:17:54.567
(Applause)

00:17:54.591 --> 00:17:55.756
CA: Thank you.

