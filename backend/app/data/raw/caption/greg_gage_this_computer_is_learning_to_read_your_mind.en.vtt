WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Joseph Geni
Reviewer: Krystian Aparta

00:00:12.203 --> 00:00:15.062
Greg Gage: Mind-reading.
You've seen this in sci-fi movies:

00:00:15.086 --> 00:00:16.943
machines that can read our thoughts.

00:00:16.967 --> 00:00:18.765
However, there are devices today

00:00:18.789 --> 00:00:21.313
that can read the electrical
activity from our brains.

00:00:21.337 --> 00:00:22.609
We call this the EEG.

00:00:23.695 --> 00:00:26.524
Is there information
contained in these brainwaves?

00:00:26.548 --> 00:00:29.361
And if so, could we train a computer
to read our thoughts?

00:00:29.385 --> 00:00:32.289
My buddy Nathan
has been working to hack the EEG

00:00:32.313 --> 00:00:33.989
to build a mind-reading machine.

00:00:34.013 --> 00:00:36.470
[DIY Neuroscience]

00:00:36.939 --> 00:00:38.500
So this is how the EEG works.

00:00:38.524 --> 00:00:40.368
Inside your head is a brain,

00:00:40.392 --> 00:00:42.950
and that brain is made
out of billions of neurons.

00:00:42.974 --> 00:00:45.981
Each of those neurons sends
an electrical message to each other.

00:00:46.005 --> 00:00:48.819
These small messages can combine
to make an electrical wave

00:00:48.843 --> 00:00:50.413
that we can detect on a monitor.

00:00:50.437 --> 00:00:53.161
Now traditionally, the EEG
can tell us large-scale things,

00:00:53.185 --> 00:00:55.535
for example if you're asleep
or if you're alert.

00:00:55.559 --> 00:00:57.153
But can it tell us anything else?

00:00:57.177 --> 00:00:58.879
Can it actually read our thoughts?

00:00:58.903 --> 00:01:00.122
We're going to test this,

00:01:00.146 --> 00:01:02.769
and we're not going to start
with some complex thoughts.

00:01:02.793 --> 00:01:04.770
We're going to do something very simple.

00:01:04.794 --> 00:01:08.047
Can we interpret what someone is seeing
using only their brainwaves?

00:01:08.071 --> 00:01:11.071
Nathan's going to begin by placing
electrodes on Christy's head.

00:01:11.095 --> 00:01:12.618
Nathan: My life is tangled.

00:01:12.642 --> 00:01:13.792
(Laughter)

00:01:14.152 --> 00:01:16.736
GG: And then he's going to show her
a bunch of pictures

00:01:16.760 --> 00:01:18.281
from four different categories.

00:01:18.305 --> 00:01:20.959
Nathan: Face, house, scenery
and weird pictures.

00:01:20.983 --> 00:01:23.481
GG: As we show Christy
hundreds of these images,

00:01:23.505 --> 00:01:27.048
we are also capturing the electrical waves
onto Nathan's computer.

00:01:27.072 --> 00:01:30.458
We want to see if we can detect
any visual information about the photos

00:01:30.482 --> 00:01:31.834
contained in the brainwaves,

00:01:31.858 --> 00:01:34.189
so when we're done,
we're going to see if the EEG

00:01:34.213 --> 00:01:36.811
can tell us what kind of picture
Christy is looking at,

00:01:36.835 --> 00:01:40.419
and if it does, each category
should trigger a different brain signal.

00:01:40.443 --> 00:01:43.071
OK, so we collected all the raw EEG data,

00:01:43.095 --> 00:01:44.245
and this is what we got.

00:01:45.389 --> 00:01:48.327
It all looks pretty messy,
so let's arrange them by picture.

00:01:48.826 --> 00:01:51.482
Now, still a bit too noisy
to see any differences,

00:01:51.506 --> 00:01:54.546
but if we average the EEG
across all image types

00:01:54.570 --> 00:01:57.006
by aligning them
to when the image first appeared,

00:01:57.030 --> 00:01:58.647
we can remove this noise,

00:01:58.671 --> 00:02:01.005
and pretty soon, we can see
some dominant patterns

00:02:01.029 --> 00:02:02.593
emerge for each category.

00:02:02.617 --> 00:02:04.773
Now the signals all
still look pretty similar.

00:02:04.797 --> 00:02:06.012
Let's take a closer look.

00:02:06.036 --> 00:02:08.561
About a hundred milliseconds
after the image comes on,

00:02:08.585 --> 00:02:11.213
we see a positive bump in all four cases,

00:02:11.237 --> 00:02:14.026
and we call this the P100,
and what we think that is

00:02:14.050 --> 00:02:17.125
is what happens in your brain
when you recognize an object.

00:02:17.149 --> 00:02:19.235
But damn, look at
that signal for the face.

00:02:19.259 --> 00:02:20.970
It looks different than the others.

00:02:20.994 --> 00:02:23.884
There's a negative dip
about 170 milliseconds

00:02:23.908 --> 00:02:25.448
after the image comes on.

00:02:25.472 --> 00:02:27.222
What could be going on here?

00:02:27.246 --> 00:02:30.486
Research shows that our brain
has a lot of neurons that are dedicated

00:02:30.510 --> 00:02:31.969
to recognizing human faces,

00:02:31.993 --> 00:02:34.837
so this N170 spike could be
all those neurons

00:02:34.861 --> 00:02:36.846
firing at once in the same location,

00:02:36.870 --> 00:02:38.504
and we can detect that in the EEG.

00:02:39.083 --> 00:02:40.903
So there are two takeaways here.

00:02:40.927 --> 00:02:44.012
One, our eyes can't really detect
the differences in patterns

00:02:44.036 --> 00:02:45.607
without averaging out the noise,

00:02:45.631 --> 00:02:47.868
and two, even after removing the noise,

00:02:47.892 --> 00:02:50.893
our eyes can only pick up
the signals associated with faces.

00:02:50.917 --> 00:02:53.185
So this is where we turn
to machine learning.

00:02:53.209 --> 00:02:57.185
Now, our eyes are not very good
at picking up patterns in noisy data,

00:02:57.209 --> 00:03:00.155
but machine learning algorithms
are designed to do just that,

00:03:00.179 --> 00:03:03.380
so could we take a lot of pictures
and a lot of data

00:03:03.404 --> 00:03:05.194
and feed it in and train a computer

00:03:05.218 --> 00:03:08.599
to be able to interpret
what Christy is looking at in real time?

00:03:09.088 --> 00:03:13.205
We're trying to code the information
that's coming out of her EEG

00:03:13.229 --> 00:03:14.404
in real time

00:03:14.428 --> 00:03:16.889
and predict what it is
that her eyes are looking at.

00:03:16.913 --> 00:03:18.640
And if it works, what we should see

00:03:18.664 --> 00:03:21.045
is every time that she gets
a picture of scenery,

00:03:21.069 --> 00:03:23.355
it should say scenery,
scenery, scenery, scenery.

00:03:23.379 --> 00:03:25.336
A face -- face, face, face, face,

00:03:25.360 --> 00:03:28.891
but it's not quite working that way,
is what we're discovering.

00:03:33.385 --> 00:03:36.933
(Laughter)

00:03:36.957 --> 00:03:38.108
OK.

00:03:38.132 --> 00:03:41.514
Director: So what's going on here?
GG: We need a new career, I think.

00:03:41.538 --> 00:03:42.608
(Laughter)

00:03:42.632 --> 00:03:45.076
OK, so that was a massive failure.

00:03:45.100 --> 00:03:48.312
But we're still curious:
How far could we push this technology?

00:03:48.336 --> 00:03:49.976
And we looked back at what we did.

00:03:50.000 --> 00:03:53.143
We noticed that the data was coming
into our computer very quickly,

00:03:53.167 --> 00:03:55.408
without any timing
of when the images came on,

00:03:55.432 --> 00:03:58.308
and that's the equivalent
of reading a very long sentence

00:03:58.332 --> 00:03:59.937
without spaces between the words.

00:03:59.961 --> 00:04:01.399
It would be hard to read,

00:04:01.423 --> 00:04:05.136
but once we add the spaces,
individual words appear

00:04:05.160 --> 00:04:07.204
and it becomes a lot more understandable.

00:04:07.228 --> 00:04:09.075
But what if we cheat a little bit?

00:04:09.099 --> 00:04:12.636
By using a sensor, we can tell
the computer when the image first appears.

00:04:12.660 --> 00:04:16.262
That way, the brainwave stops being
a continuous stream of information,

00:04:16.286 --> 00:04:18.997
and instead becomes
individual packets of meaning.

00:04:19.021 --> 00:04:21.389
Also, we're going
to cheat a little bit more,

00:04:21.413 --> 00:04:23.225
by limiting the categories to two.

00:04:23.249 --> 00:04:25.632
Let's see if we can do
some real-time mind-reading.

00:04:25.656 --> 00:04:26.891
In this new experiment,

00:04:26.915 --> 00:04:29.012
we're going to constrict it
a little bit more

00:04:29.036 --> 00:04:31.288
so that we know the onset of the image

00:04:31.312 --> 00:04:34.694
and we're going to limit
the categories to "face" or "scenery."

00:04:35.097 --> 00:04:36.608
Nathan: Face. Correct.

00:04:37.780 --> 00:04:39.131
Scenery. Correct.

00:04:40.251 --> 00:04:42.624
GG: So right now,
every time the image comes on,

00:04:42.648 --> 00:04:44.914
we're taking a picture
of the onset of the image

00:04:44.938 --> 00:04:46.633
and decoding the EEG.

00:04:46.657 --> 00:04:47.913
It's getting correct.

00:04:47.937 --> 00:04:49.516
Nathan: Yes. Face. Correct.

00:04:49.540 --> 00:04:52.399
GG: So there is information
in the EEG signal, which is cool.

00:04:52.423 --> 00:04:54.960
We just had to align it
to the onset of the image.

00:04:55.307 --> 00:04:56.618
Nathan: Scenery. Correct.

00:04:59.344 --> 00:05:00.494
Face. Yeah.

00:05:00.518 --> 00:05:02.806
GG: This means there is some
information there,

00:05:02.830 --> 00:05:05.743
so if we know at what time
the picture came on,

00:05:05.767 --> 00:05:07.766
we can tell what type of picture it was,

00:05:07.790 --> 00:05:12.886
possibly, at least on average,
by looking at these evoked potentials.

00:05:12.910 --> 00:05:14.235
Nathan: Exactly.

00:05:14.259 --> 00:05:17.780
GG: If you had told me at the beginning
of this project this was possible,

00:05:17.804 --> 00:05:19.055
I would have said no way.

00:05:19.079 --> 00:05:21.079
I literally did not think
we could do this.

00:05:21.103 --> 00:05:23.169
Did our mind-reading
experiment really work?

00:05:23.193 --> 00:05:25.168
Yes, but we had to do a lot of cheating.

00:05:25.192 --> 00:05:28.097
It turns out you can find
some interesting things in the EEG,

00:05:28.121 --> 00:05:30.411
for example if you're
looking at someone's face,

00:05:30.435 --> 00:05:32.592
but it does have a lot of limitations.

00:05:32.616 --> 00:05:35.562
Perhaps advances in machine learning
will make huge strides,

00:05:35.586 --> 00:05:38.976
and one day we will be able to decode
what's going on in our thoughts.

00:05:39.000 --> 00:05:43.077
But for now, the next time a company says
that they can harness your brainwaves

00:05:43.101 --> 00:05:44.851
to be able to control devices,

00:05:44.875 --> 00:05:48.185
it is your right, it is your duty
to be skeptical.

