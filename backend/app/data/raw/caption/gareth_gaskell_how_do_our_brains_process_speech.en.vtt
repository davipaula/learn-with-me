WEBVTT
Kind: captions
Language: en

00:00:06.814 --> 00:00:14.045
The average 20 year old knows 
between 27,000 and 52,000 different words.

00:00:14.045 --> 00:00:20.053
By age 60, that number averages 
between 35,000 and 56,000.

00:00:20.053 --> 00:00:24.330
Spoken out loud, most of these words 
last less than a second.

00:00:24.330 --> 00:00:28.535
So with every word, the brain 
has a quick decision to make:

00:00:28.535 --> 00:00:32.235
which of those thousands of options 
matches the signal?

00:00:32.235 --> 00:00:36.345
About 98% of the time, the brain chooses
the correct word.

00:00:36.345 --> 00:00:37.475
But how?

00:00:37.475 --> 00:00:41.115
Speech comprehension is different
from reading comprehension,

00:00:41.115 --> 00:00:44.375
but it’s similar to sign language 
comprehension—

00:00:44.375 --> 00:00:48.861
though spoken word recognition 
has been studied more than sign language.

00:00:48.861 --> 00:00:51.421
The key to our ability 
to understand speech

00:00:51.421 --> 00:00:54.691
is the brain’s role 
as a parallel processor,

00:00:54.691 --> 00:00:58.691
meaning that it can do multiple 
different things at the same time.

00:00:58.691 --> 00:01:01.301
Most theories assume 
that each word we know

00:01:01.301 --> 00:01:05.771
is represented by a separate processing 
unit that has just one job:

00:01:05.771 --> 00:01:10.931
to assess the likelihood of incoming 
speech matching that particular word.

00:01:10.931 --> 00:01:15.139
In the context of the brain, 
the processing unit that represents a word

00:01:15.139 --> 00:01:19.796
is likely a pattern of firing activity 
across a group of neurons

00:01:19.796 --> 00:01:21.686
in the brain’s cortex.

00:01:21.686 --> 00:01:23.506
When we hear the beginning of a word,

00:01:23.506 --> 00:01:27.286
several thousand such units 
may become active,

00:01:27.286 --> 00:01:29.352
because with just the beginning 
of a word,

00:01:29.352 --> 00:01:31.532
there are many possible matches.

00:01:31.532 --> 00:01:35.535
Then, as the word goes on, 
more and more units register

00:01:35.535 --> 00:01:40.666
that some vital piece of information 
is missing and lose activity.

00:01:40.666 --> 00:01:43.126
Possibly well before the end of the word,

00:01:43.126 --> 00:01:48.090
just one firing pattern remains active, 
corresponding to one word.

00:01:48.090 --> 00:01:50.828
This is called the "recognition point."

00:01:50.828 --> 00:01:53.648
In the process of honing in on one word,

00:01:53.648 --> 00:01:56.718
the active units suppress 
the activity of others,

00:01:56.718 --> 00:01:58.838
saving vital milliseconds.

00:01:58.838 --> 00:02:03.635
Most people can comprehend 
up to about 8 syllables per second.

00:02:03.635 --> 00:02:06.965
Yet, the goal is not only 
to recognize the word,

00:02:06.965 --> 00:02:10.415
but also to access its stored meaning.

00:02:10.415 --> 00:02:14.195
The brain accesses many possible meanings
at the same time,

00:02:14.195 --> 00:02:16.875
before the word has been fully identified.

00:02:16.875 --> 00:02:22.018
We know this from studies which show 
that even upon hearing a word fragment—

00:02:22.018 --> 00:02:23.298
like "cap"—

00:02:23.298 --> 00:02:26.798
listeners will start to register 
multiple possible meanings,

00:02:26.798 --> 00:02:31.970
like captain or capital,
before the full word emerges.

00:02:31.970 --> 00:02:35.120
This suggests that every time 
we hear a word

00:02:35.120 --> 00:02:38.480
there’s a brief explosion of meanings 
in our minds,

00:02:38.480 --> 00:02:43.291
and by the recognition point the brain 
has settled on one interpretation.

00:02:43.291 --> 00:02:46.221
The recognition process moves 
more rapidly

00:02:46.221 --> 00:02:50.821
with a sentence that gives us context 
than in a random string of words.

00:02:50.821 --> 00:02:55.009
Context also helps guide us towards 
the intended meaning of words

00:02:55.009 --> 00:02:59.009
with multiple interpretations, 
like "bat," or "crane,"

00:02:59.009 --> 00:03:03.009
or in cases of homophones
like "no" or "know."

00:03:03.009 --> 00:03:07.393
For multilingual people, the language
they are listening to is another cue,

00:03:07.393 --> 00:03:12.706
used to eliminate potential words
that don’t match the language context.

00:03:12.706 --> 00:03:16.706
So, what about adding completely 
new words to this system?

00:03:16.706 --> 00:03:20.706
Even as adults, we may come across 
a new word every few days.

00:03:20.706 --> 00:03:25.109
But if every word is represented 
as a fine-tuned pattern of activity

00:03:25.109 --> 00:03:27.439
distributed over many neurons,

00:03:27.439 --> 00:03:31.992
how do we prevent new words 
from overwriting old ones?

00:03:31.992 --> 00:03:34.322
We think that to avoid this problem,

00:03:34.322 --> 00:03:39.085
new words are initially stored in a part 
of the brain called the hippocampus,

00:03:39.085 --> 00:03:42.693
well away from the main store 
of words in the cortex,

00:03:42.693 --> 00:03:46.063
so they don’t share neurons
with others words.

00:03:46.063 --> 00:03:49.073
Then, over multiple nights of sleep,

00:03:49.073 --> 00:03:54.470
the new words gradually transfer 
over and interweave with old ones.

00:03:54.470 --> 00:03:57.990
Researchers think this gradual
acquisition process

00:03:57.990 --> 00:04:01.354
helps avoid disrupting existing words.

00:04:01.354 --> 00:04:02.774
So in the daytime,

00:04:02.774 --> 00:04:07.304
unconscious activity generates explosions
of meaning as we chat away.

00:04:07.304 --> 00:04:12.305
At night, we rest, but our brains 
are busy integrating new knowledge

00:04:12.305 --> 00:04:14.125
into the word network.

00:04:14.125 --> 00:04:17.655
When we wake up, this process ensures 
that we’re ready

00:04:17.596 --> 00:04:20.696
for the ever-changing world of language.

