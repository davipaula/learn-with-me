WEBVTT
Kind: captions
Language: en

00:00:12.849 --> 00:00:15.993
Chris Anderson: I have been long
so fascinated and amazed

00:00:16.017 --> 00:00:17.856
by so many aspects of Netflix.

00:00:17.880 --> 00:00:20.152
You're full of surprises, if I may say so.

00:00:20.595 --> 00:00:24.150
One of those surprises happened,
I think about six years ago.

00:00:24.650 --> 00:00:28.586
So, the company back then
was doing really well,

00:00:28.610 --> 00:00:30.669
but you were basically a streaming service

00:00:30.693 --> 00:00:34.498
for other people's films and TV content.

00:00:34.522 --> 00:00:36.808
You'd persuaded Wall Street
that you were right

00:00:36.832 --> 00:00:40.889
to make the kind of radical shift
away from just sending people DVDs,

00:00:40.913 --> 00:00:42.551
so you were doing it by streaming.

00:00:42.575 --> 00:00:44.248
And you were growing like a weed --

00:00:44.272 --> 00:00:47.472
you had more than six million subscribers
and healthy growth rates,

00:00:47.496 --> 00:00:49.736
and yet, you chose that moment

00:00:49.760 --> 00:00:55.117
to kind of make a giant --
really, a bet-the-company decision.

00:00:55.141 --> 00:00:58.442
What was that decision,
and what motivated it?

00:00:58.466 --> 00:01:01.379
Reed Hastings: Well,
cable networks from all time

00:01:01.403 --> 00:01:03.522
have started on other people's content

00:01:03.546 --> 00:01:06.355
and then grown into doing
their own originals.

00:01:06.379 --> 00:01:09.875
So we knew of the general idea
for quite a while.

00:01:10.545 --> 00:01:14.831
And we had actually tried to get into
original content back in 2005,

00:01:14.855 --> 00:01:18.458
when we were on DVD only
and buying films at Sundance --

00:01:18.482 --> 00:01:21.318
Maggie Gyllenhaal, "Sherrybaby,"
we published on DVD --

00:01:21.342 --> 00:01:22.807
we were a mini studio.

00:01:22.831 --> 00:01:25.490
And it didn't work out,
because we were subscale.

00:01:25.514 --> 00:01:28.687
And then, as you said, in 2011,

00:01:28.711 --> 00:01:32.974
Ted Sarandos, my partner at Netflix
who runs content,

00:01:32.998 --> 00:01:35.014
got very excited about "House of Cards."

00:01:35.038 --> 00:01:37.958
And at that time,
it was 100 million dollars,

00:01:37.982 --> 00:01:41.815
it was a fantastic investment,

00:01:41.839 --> 00:01:44.220
and it was in competition with HBO.

00:01:44.244 --> 00:01:47.434
And that was really the breakthrough,
that he picked right upfront.

00:01:47.458 --> 00:01:50.887
CA: But that was a significant percentage
of the revenue of the company

00:01:50.911 --> 00:01:52.585
at that time.

00:01:52.958 --> 00:01:56.966
But how could you get confident
that that was actually worth doing?

00:01:56.990 --> 00:01:58.157
If you got that wrong,

00:01:58.181 --> 00:02:00.942
it might have been really
devastating for the company.

00:02:00.966 --> 00:02:04.680
RH: Yeah, we weren't confident.
I mean, that's the whole tension of it.

00:02:04.704 --> 00:02:07.182
We were like, "Holy ...!" --
I can't say that.

00:02:08.775 --> 00:02:09.925
Yeah, it was scary.

00:02:10.891 --> 00:02:13.074
(Laughter)

00:02:13.098 --> 00:02:17.074
CA: And with that, it wasn't just
producing new content.

00:02:17.098 --> 00:02:19.711
You also, pretty much with that,
if I understand right,

00:02:19.735 --> 00:02:21.759
introduced this idea of binge-viewing.

00:02:21.783 --> 00:02:25.042
It wasn't, "We're going to do
these episodes and build excitement" --

00:02:25.066 --> 00:02:27.057
boom! -- all at one time.

00:02:27.450 --> 00:02:29.746
And that consumer mode
hadn't really been tested.

00:02:29.770 --> 00:02:31.236
Why did you risk that?

00:02:31.600 --> 00:02:33.984
RH: Well, you know,
we had grown up shipping DVDs.

00:02:34.008 --> 00:02:36.498
And then there were series,
box sets, on DVD.

00:02:36.522 --> 00:02:41.535
And all of us had that experience
watching some of the great HBO content

00:02:41.559 --> 00:02:44.854
you know, with the DVD --
next episode, next episode.

00:02:44.878 --> 00:02:47.144
And so that was the trigger
to make us think,

00:02:47.168 --> 00:02:51.077
wow, you know, with episodic content,
especially serialized,

00:02:51.101 --> 00:02:54.289
it's so powerful to have
all the episodes at once.

00:02:54.313 --> 00:02:56.782
And it's something
that linear TV can't do.

00:02:57.100 --> 00:02:59.988
And so both of those
made it really positive.

00:03:01.179 --> 00:03:04.934
CA: And so, did it work out on the math
pretty much straight away,

00:03:04.958 --> 00:03:08.668
that an hour spent watching
"House of Cards," say,

00:03:08.692 --> 00:03:10.665
was more profitable to you

00:03:10.689 --> 00:03:14.417
than an hour spent watching
someone else's licensed content?

00:03:14.879 --> 00:03:19.211
RH: You know, because we're subscription,
we don't have to track it at that level.

00:03:19.235 --> 00:03:21.871
And so it's really about
making the brand stronger,

00:03:21.895 --> 00:03:23.743
so that more people want to join.

00:03:23.767 --> 00:03:25.729
And "House of Cards" absolutely did that,

00:03:25.753 --> 00:03:28.037
because then many people
would talk about it

00:03:28.061 --> 00:03:30.396
and associate that brand with us,

00:03:30.728 --> 00:03:34.188
whereas "Mad Men" we carried --
great show, AMC show --

00:03:34.212 --> 00:03:36.228
but they didn't associate it with Netflix,

00:03:36.252 --> 00:03:38.037
even if they watched it on Netflix.

00:03:38.061 --> 00:03:41.849
CA: And so you added
all these other remarkable series,

00:03:42.593 --> 00:03:47.172
"Narcos," "Jessica Jones,"
"Orange is the New Black," "The Crown,"

00:03:47.196 --> 00:03:50.244
"Black Mirror" -- personal favorite --

00:03:50.268 --> 00:03:51.633
"Stranger Things" and so on.

00:03:51.657 --> 00:03:53.984
And so, this coming year,

00:03:54.008 --> 00:03:57.474
the level of investment you're planning
to make in new content

00:03:57.498 --> 00:03:59.003
is not 100 million.

00:03:59.027 --> 00:04:00.283
It's what?

00:04:00.307 --> 00:04:03.061
RH: It's about eight billion dollars
around the world.

00:04:03.966 --> 00:04:06.148
And it's not enough.

00:04:06.855 --> 00:04:10.168
There are so many great shows
on other networks.

00:04:10.192 --> 00:04:12.125
And so we have a long way to go.

00:04:12.149 --> 00:04:14.736
CA: But eight billion --

00:04:14.760 --> 00:04:19.625
that's pretty much higher than any other
content commissioner at this point?

00:04:19.649 --> 00:04:21.403
RH: No, Disney is in that realm,

00:04:21.427 --> 00:04:24.828
and if they're able to acquire Fox,
they're even bigger.

00:04:26.299 --> 00:04:29.418
And then, really, that's spread globally,

00:04:29.442 --> 00:04:31.909
so it's not as much as it sounds.

00:04:32.560 --> 00:04:34.855
(Laughter)

00:04:34.879 --> 00:04:38.314
CA: But clearly, from the Barry Dillers
and others in the media business,

00:04:38.324 --> 00:04:40.107
it feels like from nowhere,

00:04:40.131 --> 00:04:43.230
this company has come and has
really revolutionized the business.

00:04:43.254 --> 00:04:45.569
It's like, as if Blockbuster one day said,

00:04:45.593 --> 00:04:47.672
"We're going to make Blockbuster videos,"

00:04:47.696 --> 00:04:50.962
and then, six years later,
was as big as Disney.

00:04:51.275 --> 00:04:55.831
I mean, that story would never
have happened, and yet it did.

00:04:55.855 --> 00:04:59.331
RH: That's the bitch about the internet --
it moves fast, you know?

00:05:00.037 --> 00:05:02.116
Everything around us moves really quick.

00:05:02.474 --> 00:05:07.207
CA: I mean, there must be something
unusual about Netflix's culture

00:05:07.231 --> 00:05:12.508
that allowed you to take such
bold -- I won't say "reckless" --

00:05:12.532 --> 00:05:14.450
bold, well thought-through decisions.

00:05:14.474 --> 00:05:15.649
RH: Yeah, absolutely.

00:05:15.673 --> 00:05:18.387
We did have one advantage,
which is we were born on DVD,

00:05:18.411 --> 00:05:20.656
and we knew that that
was going to be temporary.

00:05:20.680 --> 00:05:23.085
No one thought we'd be
mailing discs for 100 years.

00:05:23.109 --> 00:05:26.744
So then you have a lot of paranoia
about what's coming next,

00:05:26.768 --> 00:05:29.561
and that's part of the founding ethos,

00:05:29.585 --> 00:05:31.887
is really worrying
about what's coming next.

00:05:32.561 --> 00:05:33.712
So that's an advantage.

00:05:33.736 --> 00:05:35.333
And then in terms of the culture,

00:05:35.357 --> 00:05:37.452
it's very big on freedom
and responsibility.

00:05:37.476 --> 00:05:40.918
I pride myself on making as few decisions
as possible in a quarter.

00:05:41.717 --> 00:05:43.909
And we're getting better
and better at that.

00:05:43.933 --> 00:05:46.049
There are some times
I can go a whole quarter

00:05:46.073 --> 00:05:47.486
without making any decisions.

00:05:47.851 --> 00:05:49.107
(Laughter)

00:05:49.131 --> 00:05:51.949
(Applause)

00:05:51.973 --> 00:05:55.593
CA: But there are some really
surprising things about your people.

00:05:55.617 --> 00:05:57.950
For example, I looked at one survey.

00:05:58.315 --> 00:06:02.933
It looks like Netflix employees,
compared to your peers',

00:06:02.957 --> 00:06:05.602
are basically the highest paid
for equivalent jobs.

00:06:05.626 --> 00:06:08.543
And the least likely to want to leave.

00:06:08.863 --> 00:06:14.093
And if you Google
the Netflix culture deck,

00:06:14.117 --> 00:06:18.601
you see this list of quite surprising
admonitions to your employees.

00:06:18.625 --> 00:06:20.077
Talk about a few of them.

00:06:20.665 --> 00:06:24.821
RH: Well, you know, my first company --
we were very process obsessed.

00:06:24.845 --> 00:06:26.486
This was in the 1990s.

00:06:26.510 --> 00:06:28.416
And every time someone made a mistake,

00:06:28.440 --> 00:06:30.084
we tried to put a process in place

00:06:30.108 --> 00:06:32.442
to make sure that mistake
didn't happen again --

00:06:32.466 --> 00:06:35.628
so, very semiconductor-yield orientation.

00:06:36.173 --> 00:06:39.236
And the problem is, we were trying
to dummy-proof the system.

00:06:39.260 --> 00:06:42.024
And then, eventually,
only dummies wanted to work there.

00:06:43.404 --> 00:06:47.418
Then, of course, the market shifted --
in that case, it was C++ to Java.

00:06:47.442 --> 00:06:49.370
But you know, there's always some shift.

00:06:49.394 --> 00:06:51.371
And the company was unable to adapt,

00:06:51.395 --> 00:06:54.077
and it got acquired
by our largest competitor.

00:06:54.561 --> 00:07:00.069
And so with Netflix, I was super focused
on how to run with no process

00:07:00.093 --> 00:07:01.360
but not have chaos.

00:07:01.862 --> 00:07:04.276
And so then we've developed
all these mechanisms,

00:07:04.300 --> 00:07:07.466
super high-talented people, alignment,

00:07:07.490 --> 00:07:09.831
talking openly, sharing information --

00:07:09.855 --> 00:07:12.625
internally, people are stunned
at how much information --

00:07:12.649 --> 00:07:14.728
all the core strategies, etc.

00:07:14.752 --> 00:07:17.910
We're like the "anti-Apple" --
you know how they compartmentalize?

00:07:17.934 --> 00:07:21.680
We do the opposite, which is:
everybody gets all the information.

00:07:21.704 --> 00:07:25.298
So what we're trying to do is build
a sense of responsibility in people

00:07:25.322 --> 00:07:26.974
and the ability to do things.

00:07:26.998 --> 00:07:30.252
I find out about big decisions now
that are made all the time,

00:07:30.276 --> 00:07:32.668
I've never even heard about it,
which is great.

00:07:32.692 --> 00:07:34.240
And mostly, they go well.

00:07:35.166 --> 00:07:37.712
CA: So you just wake up
and read them on the internet.

00:07:37.736 --> 00:07:38.888
RH: Sometimes.

00:07:38.912 --> 00:07:40.553
CA: "Oh, we just entered China!"

00:07:40.577 --> 00:07:42.481
RH: Yeah, well that would be a big one.

00:07:43.354 --> 00:07:48.753
CA: But you allow employees to set
their own vacation time, and ...

00:07:48.777 --> 00:07:50.480
There's just --

00:07:50.504 --> 00:07:52.935
RH: Sure, that's a big
symbolic one, vacation,

00:07:53.512 --> 00:07:56.589
because most people, in practice,
do that, anyway.

00:07:56.934 --> 00:08:00.588
But yeah, there's a whole lot
of that freedom.

00:08:01.736 --> 00:08:05.894
CA: And courage, you ask for
as a fundamental value.

00:08:07.040 --> 00:08:09.286
RH: Yeah, we want people
to speak the truth.

00:08:09.310 --> 00:08:12.972
And we say, "To disagree
silently is disloyal."

00:08:13.896 --> 00:08:18.769
It's not OK to let some decision
go through without saying your piece,

00:08:18.793 --> 00:08:20.507
and typically, writing it down.

00:08:20.531 --> 00:08:23.738
And so we're very focused
on trying to get to good decisions

00:08:23.762 --> 00:08:27.028
through the debate that always happens.

00:08:27.052 --> 00:08:30.253
And we try not to make it intense,
like yelling at each other --

00:08:30.277 --> 00:08:31.448
nothing like that.

00:08:31.472 --> 00:08:34.163
You know, it's really curiosity
drawing people out.

00:08:35.252 --> 00:08:38.189
CA: You've got this other
secret weapon at Netflix, it seems,

00:08:38.213 --> 00:08:40.636
which is this vast trove of data,

00:08:40.660 --> 00:08:43.537
a word we've heard
a certain amount about this week.

00:08:43.561 --> 00:08:47.566
You've often taken
really surprising stances

00:08:47.590 --> 00:08:50.260
towards building smart
algorithms at Netflix.

00:08:50.284 --> 00:08:54.224
Back in the day, you opened up
your algorithm to the world

00:08:54.248 --> 00:08:57.668
and said, "Hey, can anyone do better
than this recommendation we've got?

00:08:57.692 --> 00:08:59.606
If so, we'll pay you a million dollars."

00:08:59.630 --> 00:09:01.317
You paid someone a million dollars,

00:09:01.341 --> 00:09:03.645
because it was like 10 percent
better than yours.

00:09:03.669 --> 00:09:04.820
RH: That's right.

00:09:04.844 --> 00:09:07.377
CA: Was that a good decision?
Would you do that again?

00:09:07.401 --> 00:09:10.521
RH: Yeah, it was super exciting
at the time; this was about 2007.

00:09:10.545 --> 00:09:12.537
But you know, we haven't done it again.

00:09:12.561 --> 00:09:15.172
So clearly, it's a very specialized tool.

00:09:15.728 --> 00:09:19.029
And so think of that as
a lucky break of good timing,

00:09:19.053 --> 00:09:20.921
rather than a general framework.

00:09:21.903 --> 00:09:26.387
So what we've done is invest a lot
on the algorithms,

00:09:26.411 --> 00:09:29.245
so that we feature the right content
to the right people

00:09:29.269 --> 00:09:31.741
and try to make it fun
and easy to explore.

00:09:32.330 --> 00:09:35.667
CA: And you made this, what seems
like a really interesting shift,

00:09:35.691 --> 00:09:36.846
a few years ago.

00:09:36.870 --> 00:09:41.800
You used to ask people,
"Here are 10 movies. What do you think?

00:09:41.824 --> 00:09:44.799
Which ones of these
are your best movies?"

00:09:44.823 --> 00:09:49.656
And then tried to match those movies
with recommendations for what was coming.

00:09:49.680 --> 00:09:51.807
And then you changed away from that.

00:09:51.831 --> 00:09:52.982
Talk about that.

00:09:53.006 --> 00:09:54.156
RH: Sure.

00:09:54.180 --> 00:09:56.628
Everyone would rate
"Schindler's List" five stars,

00:09:56.652 --> 00:10:01.180
and then they'd rate Adam Sandler,
"The Do-Over" three stars.

00:10:01.204 --> 00:10:03.599
But, in fact, when you looked
at what they watched,

00:10:03.623 --> 00:10:06.133
it was almost always Adam Sandler.

00:10:06.157 --> 00:10:10.983
And so what happens is, when we rate
and we're metacognitive about quality,

00:10:11.007 --> 00:10:13.259
that's sort of our aspirational self.

00:10:14.133 --> 00:10:16.482
And it works out much better
to please people

00:10:16.506 --> 00:10:18.958
to look at the actual choices
that they make,

00:10:18.982 --> 00:10:23.745
their revealed preferences
by how much they enjoy simple pleasures.

00:10:24.493 --> 00:10:27.267
CA: OK, I want to talk
for a couple of minutes about this,

00:10:27.291 --> 00:10:30.184
because this strikes me as a huge deal,
not just for Netflix,

00:10:30.208 --> 00:10:31.585
for the internet as a whole.

00:10:31.609 --> 00:10:34.323
The difference between aspirational values

00:10:34.347 --> 00:10:36.608
and revealed values.

00:10:36.632 --> 00:10:40.137
You, brilliantly, didn't pay too much
attention to what people said,

00:10:40.161 --> 00:10:43.585
you watched what they did,
and then found the stuff that,

00:10:43.609 --> 00:10:48.202
"Oh my God, I never knew I would like
a show about making horrible recipes,

00:10:48.226 --> 00:10:49.633
called 'Nailed It!'"

00:10:49.657 --> 00:10:51.138
RH: Called "Nailed It!" Right.

00:10:51.162 --> 00:10:54.061
CA: It's hilarious. I would never
have even thought of that.

00:10:54.085 --> 00:10:55.704
But aren't there risks with this,

00:10:55.728 --> 00:11:00.934
if this go-only-with-revealed-values
approach is taken too far?

00:11:01.434 --> 00:11:04.458
RH: Well, we get a lot of joy
from making people happy,

00:11:04.482 --> 00:11:08.081
Sometimes you just want to relax
and watch a show like "Nailed It!"

00:11:08.736 --> 00:11:11.256
And it's fun, and it's not stressful.

00:11:11.280 --> 00:11:14.442
Other times, people want
to watch very intensive film.

00:11:14.466 --> 00:11:17.345
"Mudbound" was Oscar-nominated,

00:11:17.369 --> 00:11:19.498
it's a great, very intensive film.

00:11:19.522 --> 00:11:24.265
And you know, we've had over
20 million hours of viewing on "Mudbound,"

00:11:24.289 --> 00:11:27.545
which is dramatically bigger
than it would have been in the theaters

00:11:27.569 --> 00:11:28.815
or any other distribution.

00:11:28.839 --> 00:11:33.212
And so, we have some candy, too,
but we have lots of broccoli.

00:11:33.236 --> 00:11:37.858
And you know, if you have the good mix,
you get to a healthy diet.

00:11:37.882 --> 00:11:39.506
CA: But -- yes, indeed.

00:11:39.530 --> 00:11:44.619
But isn't it the case that algorithms
tend to point you away from the broccoli

00:11:44.643 --> 00:11:45.794
and towards the candy,

00:11:45.818 --> 00:11:46.969
if you're not careful?

00:11:46.993 --> 00:11:49.847
We just had a talk about how,
on YouTube, somehow algorithms

00:11:49.871 --> 00:11:53.379
tend to, just by actually being smarter,

00:11:53.403 --> 00:11:57.641
tend to drive people towards
more radical or specific content.

00:11:57.665 --> 00:12:00.815
It'd be easy to imagine
that Netflix algorithms,

00:12:00.839 --> 00:12:04.783
just going on revealed values,
would gradually --

00:12:04.807 --> 00:12:06.403
RH: Right, get too base --

00:12:06.427 --> 00:12:09.752
CA: We'd all be watching
violent pornography or something.

00:12:09.776 --> 00:12:11.369
Or some people would, you know.

00:12:11.393 --> 00:12:12.545
But, how --

00:12:12.569 --> 00:12:14.879
(Laughter)

00:12:14.903 --> 00:12:16.053
Not me!

00:12:16.728 --> 00:12:19.982
I'm the child of a missionary,
I don't even think about these things.

00:12:20.006 --> 00:12:21.164
But --

00:12:21.188 --> 00:12:22.426
(Laughter)

00:12:22.450 --> 00:12:24.189
But I mean, it's possible, right?

00:12:25.037 --> 00:12:28.356
RH: In practice, you're right
that you can't just rely on algorithms.

00:12:28.380 --> 00:12:30.506
It's a mix of judgment and what we carry,

00:12:30.530 --> 00:12:31.887
and we're a curated service

00:12:31.911 --> 00:12:34.204
versus a platform
like Facebook and YouTube,

00:12:34.228 --> 00:12:37.417
so we have an easier set of issues,

00:12:37.441 --> 00:12:41.676
which is: What are these great
films and series that we acquire?

00:12:42.379 --> 00:12:44.861
But then within that,
the algorithm is a tool.

00:12:45.958 --> 00:12:50.690
CA: But how -- John Doerr just talked
about measuring what matters.

00:12:51.148 --> 00:12:53.730
As a business, what matters, I presume,

00:12:53.754 --> 00:12:56.375
is fundamentally just growing subscribers.

00:12:56.399 --> 00:13:00.498
I mean, that's your unique advantage.

00:13:00.522 --> 00:13:07.498
Are subscribers grown only by
the more time they spend watching Netflix,

00:13:07.522 --> 00:13:09.482
that is what will make them re-subscribe?

00:13:09.506 --> 00:13:14.235
Or is it even more about having shows

00:13:14.259 --> 00:13:16.237
that might not have been so much time

00:13:16.261 --> 00:13:18.949
as watching the whole season
of "Nailed It!" or whatever?

00:13:18.973 --> 00:13:21.144
But just get into them more;
they just think,

00:13:21.168 --> 00:13:23.791
"That was nourishing,
that was extraordinary,

00:13:23.815 --> 00:13:26.029
I'm so glad I watched
that with my family."

00:13:26.053 --> 00:13:28.887
Isn't there a version
of the business model

00:13:28.911 --> 00:13:31.474
that would be less content
but more awesome content,

00:13:31.498 --> 00:13:34.228
possibly even more uplifting content?

00:13:34.625 --> 00:13:36.737
RH: And people choose
that uplifting content.

00:13:36.761 --> 00:13:39.783
I think you're right, which is,
when people talk about Netflix,

00:13:39.807 --> 00:13:41.815
they talk about the shows that move them:

00:13:41.839 --> 00:13:44.648
"13 Reasons Why" or "The Crown."

00:13:44.672 --> 00:13:48.156
And that is way disproportionate
and positive impact,

00:13:48.180 --> 00:13:50.664
even for the subscriber growth
that you talked about

00:13:50.688 --> 00:13:53.005
is those couple big, memorable shows.

00:13:53.029 --> 00:13:55.092
But what we want to do is offer a variety.

00:13:55.116 --> 00:13:58.645
You don't want to watch the same thing
every night, as much as you like it;

00:13:58.669 --> 00:14:00.323
you want to try different things.

00:14:00.347 --> 00:14:02.481
And what we haven't seen is this, say,

00:14:02.505 --> 00:14:06.085
race to the bottom of your
violent pornography kind of examples.

00:14:06.474 --> 00:14:09.443
Instead, we've seen great viewing
across a whole range --

00:14:09.467 --> 00:14:13.313
"Black Mirror" --
we're filming season five now.

00:14:13.649 --> 00:14:17.403
And that was a struggling show
when it was only in the BBC.

00:14:17.427 --> 00:14:19.830
And with the distribution of on-demand,

00:14:19.854 --> 00:14:23.005
you can make these much bigger shows.

00:14:23.442 --> 00:14:25.585
CA: You're telling me
humans can get addicted

00:14:25.609 --> 00:14:27.667
by their angels as well as their demons.

00:14:28.481 --> 00:14:32.053
RH: Yeah, and again, we try
not to think about it in addiction terms,

00:14:32.077 --> 00:14:33.648
we think about it as, you know:

00:14:33.672 --> 00:14:37.696
What are you going to do
with your time and when you want to relax?

00:14:37.720 --> 00:14:41.601
You can watch linear TV, you can do
video games, you can do YouTube,

00:14:41.625 --> 00:14:42.982
or you can watch Netflix.

00:14:43.006 --> 00:14:47.164
And if we're as great as we can be,
and we have a variety of moods,

00:14:47.188 --> 00:14:49.410
then more often, people will choose us.

00:14:49.434 --> 00:14:52.972
CA: But you have people
in the organization

00:14:52.996 --> 00:14:58.337
who are looking regularly
at the actual impacts

00:14:58.361 --> 00:15:00.752
of these brilliant algorithms
that you've created.

00:15:00.776 --> 00:15:02.287
Just for reality check, just,

00:15:02.311 --> 00:15:05.198
"Are we sure that this
is the direction we want to go?"

00:15:05.951 --> 00:15:07.508
RH: You know, I think we learn.

00:15:07.532 --> 00:15:11.332
And you have to be humble and sort of say,
"Look, there's no perfect tool."

00:15:11.356 --> 00:15:15.141
The algorithm’s one part,
the way we commission the content,

00:15:15.165 --> 00:15:17.365
our relationships with societies.

00:15:17.934 --> 00:15:20.417
So there's a lot of ways
that we have to look at it.

00:15:20.441 --> 00:15:23.965
So if you get too stuck in
"Let's just increase viewing"

00:15:23.989 --> 00:15:25.479
or "Just increase subscribers,"

00:15:25.503 --> 00:15:29.990
you're unlikely to be able to grow
and be the great company you want to be.

00:15:30.014 --> 00:15:32.878
So think of it as this
multiple measures of success.

00:15:33.196 --> 00:15:36.307
CA: So, speaking of algorithms
that have raised questions:

00:15:36.331 --> 00:15:38.236
You were on the board of Facebook,

00:15:38.260 --> 00:15:42.335
and I think Mark Zuckerberg --
you've done some mentoring for him.

00:15:42.950 --> 00:15:48.286
What should we know about Mark Zuckerberg
that people don't know?

00:15:49.268 --> 00:15:51.615
RH: Well, many of you know him
or have seen him.

00:15:51.639 --> 00:15:54.053
I mean, he's a fantastic human being.

00:15:54.077 --> 00:15:55.553
Really first-class.

00:15:56.323 --> 00:16:01.664
And social -- these platforms,
whether that's YouTube or Facebook,

00:16:01.688 --> 00:16:04.617
are clearly trying to grow up quickly.

00:16:04.641 --> 00:16:06.791
And we see that with all new technologies.

00:16:06.815 --> 00:16:09.768
I mean, yesterday we were talking
about printed DNA,

00:16:09.792 --> 00:16:13.549
and it's like: could be fantastic
or could be horrific.

00:16:14.315 --> 00:16:16.331
And you know, all new technologies --

00:16:16.355 --> 00:16:19.482
when television was first popular
in the 1960s in the US,

00:16:19.506 --> 00:16:21.601
it was called a "vast wasteland,"

00:16:21.625 --> 00:16:24.887
and that television was going to rot
the minds of everybody.

00:16:24.911 --> 00:16:27.260
It turns out everybody's minds were fine.

00:16:27.284 --> 00:16:29.363
And there were some adjustments,

00:16:29.387 --> 00:16:31.889
but think of it as --
or, I think of it as --

00:16:31.913 --> 00:16:34.360
all new technologies have pros and cons.

00:16:34.670 --> 00:16:37.122
And in social,
we're just figuring that out.

00:16:37.146 --> 00:16:40.045
CA: How much of a priority
is it for the board of Facebook

00:16:40.069 --> 00:16:42.339
to really address some of the issues?

00:16:42.363 --> 00:16:43.938
Or is the belief that, actually,

00:16:43.962 --> 00:16:47.212
the company has been completely
unfairly criticized?

00:16:47.236 --> 00:16:49.030
RH: Oh, it's not completely unfairly.

00:16:49.054 --> 00:16:52.450
And Mark's leading the charge
on fixing Facebook.

00:16:52.474 --> 00:16:54.874
And he's very passionate about that.

00:16:56.839 --> 00:16:59.450
CA: Reed, I want to look
at another passion of yours.

00:16:59.474 --> 00:17:04.132
I mean, you've done incredibly well
with Netflix, you're a billionaire,

00:17:04.156 --> 00:17:09.267
and you spend a lot of time
and indeed, money, on education.

00:17:09.291 --> 00:17:10.442
RH: Yep.

00:17:10.466 --> 00:17:13.307
CA: Why is this a passion,
and what are you doing about it?

00:17:13.331 --> 00:17:16.617
RH: Sure. Right out of college,
I was a high school math teacher.

00:17:16.641 --> 00:17:20.561
So when I later went into business
and became a philanthropist,

00:17:20.585 --> 00:17:23.185
I think I gravitated towards education

00:17:23.871 --> 00:17:26.077
and trying to make a difference there.

00:17:26.101 --> 00:17:28.389
And the main thing I noticed is, you know,

00:17:28.413 --> 00:17:31.196
educators want to work
with other great educators

00:17:31.220 --> 00:17:34.434
and to create many
unique environments for kids.

00:17:34.458 --> 00:17:37.198
And we need a lot more
variety in the system

00:17:37.222 --> 00:17:38.373
than we have,

00:17:38.397 --> 00:17:41.634
and a lot more
educator-centric organizations.

00:17:41.658 --> 00:17:44.228
And so the tricky thing is,
right now in the US,

00:17:44.252 --> 00:17:47.728
most schools are run
by a local school board.

00:17:48.141 --> 00:17:51.164
And it has to meet all needs
in the community,

00:17:51.188 --> 00:17:53.863
and, in fact, what we need
is a lot more variety.

00:17:53.887 --> 00:17:56.837
So in the US there's a form
of public school

00:17:56.861 --> 00:17:59.860
called charter public schools,
that are run by nonprofits.

00:17:59.884 --> 00:18:01.704
And that's the big emphasis for me,

00:18:01.728 --> 00:18:04.367
is if you can have schools
run by nonprofits,

00:18:04.391 --> 00:18:08.268
they are more mission-focused,
they support the educators well.

00:18:08.292 --> 00:18:10.515
I'm on the board of KIPP charter schools,

00:18:10.539 --> 00:18:12.498
which is one of the larger networks.

00:18:12.522 --> 00:18:17.625
And, you know, it's 30,000 kids a year
getting very stimulating education.

00:18:17.649 --> 00:18:21.533
CA: Paint me a picture of what
a school should look like.

00:18:22.029 --> 00:18:23.271
RH: It depends on the kid.

00:18:23.295 --> 00:18:26.400
Think about it as: with multiple
kids, there's all different needs

00:18:26.424 --> 00:18:27.575
that need to be met,

00:18:27.599 --> 00:18:28.987
so there's not any one model.

00:18:29.011 --> 00:18:30.646
And you want to be able to choose,

00:18:30.670 --> 00:18:33.067
depending on your kid
and what you think they need.

00:18:33.091 --> 00:18:36.799
But they should be very educator-centric
and curious and stimulating

00:18:36.823 --> 00:18:38.125
and all of those things.

00:18:38.149 --> 00:18:40.865
And this whole idea
of 30 kids in fifth grade,

00:18:40.889 --> 00:18:43.331
all learning the same thing
at the same time,

00:18:43.355 --> 00:18:46.000
you know, is clearly
an industrial throwback.

00:18:46.489 --> 00:18:50.149
But changing that, given
the current government structure,

00:18:50.173 --> 00:18:51.339
is super hard.

00:18:51.363 --> 00:18:56.600
But what these innovative, nonprofit
schools are doing is pushing the bounds,

00:18:56.624 --> 00:18:59.529
letting kids try new things.

00:18:59.553 --> 00:19:03.109
And so think of it as
the governance reform,

00:19:03.133 --> 00:19:04.466
that is, the nonprofit,

00:19:04.490 --> 00:19:07.393
to allow the educational changes.

00:19:07.718 --> 00:19:12.395
CA: And sometimes the criticism is put
that charter schools,

00:19:12.419 --> 00:19:14.008
intentionally or unintentionally,

00:19:14.032 --> 00:19:16.601
suck resources away
from the public school system.

00:19:16.625 --> 00:19:18.681
Should we be concerned about that?

00:19:18.705 --> 00:19:20.427
RH: Well, they are public schools.

00:19:20.451 --> 00:19:23.245
I mean, there's these multiple types
of public schools.

00:19:23.760 --> 00:19:26.165
And if you look at charters as a whole,

00:19:26.189 --> 00:19:27.989
they serve low-income kids.

00:19:28.442 --> 00:19:30.617
Because if high-income kids
get in trouble,

00:19:30.641 --> 00:19:32.808
the parents will send them
to a private school

00:19:32.832 --> 00:19:34.235
or they move neighborhoods.

00:19:34.259 --> 00:19:37.108
And low-income families generally
don't have those choices.

00:19:37.517 --> 00:19:42.117
Like KIPP -- it's 80 percent
low-income kids, free and reduced lunch.

00:19:42.141 --> 00:19:44.874
And the college admissions
for KIPP is fantastic.

00:19:45.530 --> 00:19:48.352
CA: Reed, you signed
the Giving Pledge a few years ago,

00:19:48.376 --> 00:19:51.332
you're committed to giving away
more than half of your fortune

00:19:51.356 --> 00:19:52.736
during your lifetime.

00:19:52.760 --> 00:19:55.838
Can I cheekily ask how much
you've invested in education

00:19:55.862 --> 00:19:57.092
in the last few years?

00:19:57.116 --> 00:20:00.677
RH: It's a couple hundred million,
I don't know exactly how many hundreds,

00:20:00.701 --> 00:20:02.897
but we're continuing to invest and --

00:20:02.921 --> 00:20:04.072
(Applause)

00:20:04.096 --> 00:20:05.246
thank you all --

00:20:05.270 --> 00:20:06.680
(Applause)

00:20:06.704 --> 00:20:11.530
You know, honestly, for a little while
I tried to do politics full-time,

00:20:11.554 --> 00:20:12.903
working for John Doerr.

00:20:13.462 --> 00:20:17.422
And while I loved working for John,
I just didn't thrive on politics.

00:20:17.446 --> 00:20:19.815
I love business, I love competing.

00:20:19.839 --> 00:20:22.639
I love going up against Disney and HBO.

00:20:22.663 --> 00:20:23.712
(Laughter)

00:20:23.736 --> 00:20:24.996
That's what gets me going.

00:20:25.020 --> 00:20:28.705
And now I do that to really
increase Netflix's value,

00:20:28.729 --> 00:20:31.643
which allows me to write
more checks to schools.

00:20:32.364 --> 00:20:34.964
And so for now, it's the perfect life.

00:20:35.651 --> 00:20:38.944
CA: Reed, you're a remarkable person,
you've changed all of our lives

00:20:38.968 --> 00:20:40.516
and the lives of many kids.

00:20:40.540 --> 00:20:42.944
Thank you so much for coming to TED.

00:20:42.968 --> 00:20:47.824
(Applause)

