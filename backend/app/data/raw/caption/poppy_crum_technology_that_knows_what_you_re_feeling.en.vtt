WEBVTT
Kind: captions
Language: en

00:00:12.881 --> 00:00:17.337
What happens when technology
knows more about us than we do?

00:00:17.992 --> 00:00:21.664
A computer now can detect
our slightest facial microexpressions

00:00:21.688 --> 00:00:25.299
and be able to tell the difference
between a real smile and a fake one.

00:00:25.323 --> 00:00:27.057
That's only the beginning.

00:00:27.466 --> 00:00:30.331
Technology has become
incredibly intelligent

00:00:30.355 --> 00:00:33.755
and already knows a lot
about our internal states.

00:00:34.085 --> 00:00:36.371
And whether we like it or not,

00:00:36.395 --> 00:00:39.894
we already are sharing
parts of our inner lives

00:00:39.918 --> 00:00:41.651
that's out of our control.

00:00:43.413 --> 00:00:44.834
That seems like a problem,

00:00:44.858 --> 00:00:48.104
because a lot of us like to keep
what's going on inside

00:00:48.128 --> 00:00:49.775
from what people actually see.

00:00:50.323 --> 00:00:54.743
We want to have agency
over what we share and what we don't.

00:00:55.473 --> 00:00:57.794
We all like to have a poker face.

00:00:59.584 --> 00:01:02.930
But I'm here to tell you
that I think that's a thing of the past.

00:01:03.347 --> 00:01:08.117
And while that might sound scary,
it's not necessarily a bad thing.

00:01:09.030 --> 00:01:11.800
I've spent a lot of time
studying the circuits in the brain

00:01:11.824 --> 00:01:15.517
that create the unique perceptual
realities that we each have.

00:01:16.110 --> 00:01:17.515
And now I bring that together

00:01:17.539 --> 00:01:19.601
with the capabilities
of current technology

00:01:19.625 --> 00:01:22.162
to create new technology
that does make us better,

00:01:22.186 --> 00:01:23.786
feel more, connect more.

00:01:24.482 --> 00:01:26.268
And I believe to do that,

00:01:26.292 --> 00:01:29.041
we have to be OK
losing some of our agency.

00:01:30.149 --> 00:01:32.672
With some animals, it's really amazing,

00:01:32.696 --> 00:01:36.170
and we get to see into
their internal experiences.

00:01:36.649 --> 00:01:40.371
We get this upfront look
at the mechanistic interaction

00:01:40.395 --> 00:01:43.212
between how they respond
to the world around them

00:01:43.236 --> 00:01:45.244
and the state of their biological systems.

00:01:45.268 --> 00:01:49.077
This is where evolutionary pressures
like eating, mating

00:01:49.101 --> 00:01:50.863
and making sure we don't get eaten

00:01:50.887 --> 00:01:55.044
drive deterministic behavioral responses
to information in the world.

00:01:55.806 --> 00:01:58.600
And we get to see into this window,

00:01:58.624 --> 00:02:02.260
into their internal states
and their biological experiences.

00:02:02.284 --> 00:02:03.926
It's really pretty cool.

00:02:03.950 --> 00:02:08.053
Now, stay with me for a moment --
I'm a violinist, not a singer.

00:02:08.077 --> 00:02:11.667
But the spider's already
given me a critical review.

00:02:16.907 --> 00:02:18.967
(Video) (Singing in a low pitch)

00:02:19.868 --> 00:02:22.756
(Singing in a middle pitch)

00:02:23.800 --> 00:02:26.305
(Singing in a high pitch)

00:02:27.069 --> 00:02:28.490
(Singing in a low pitch)

00:02:29.236 --> 00:02:30.836
(Singing in a middle pitch)

00:02:31.403 --> 00:02:33.180
(Singing in a high pitch)

00:02:33.204 --> 00:02:34.354
(Laughter)

00:02:36.387 --> 00:02:39.585
Poppy Crum: It turns out, some spiders
tune their webs like violins

00:02:39.609 --> 00:02:41.767
to resonate with certain sounds.

00:02:41.791 --> 00:02:44.562
And likely, the harmonics
of my voice as it went higher

00:02:44.586 --> 00:02:46.316
coupled with how loud I was singing

00:02:46.340 --> 00:02:50.807
recreated either the predatory call
of an echolocating bat or a bird,

00:02:50.831 --> 00:02:52.712
and the spider did what it should.

00:02:53.300 --> 00:02:56.117
It predictively told me to bug off.

00:02:56.824 --> 00:02:57.974
I love this.

00:02:58.546 --> 00:03:01.855
The spider's responding
to its external world

00:03:01.879 --> 00:03:06.229
in a way that we get to see and know
what's happening to its internal world.

00:03:07.069 --> 00:03:09.275
Biology is controlling
the spider's response;

00:03:09.299 --> 00:03:12.075
it's wearing its internal
state on its sleeve.

00:03:13.768 --> 00:03:15.423
But us, humans --

00:03:16.184 --> 00:03:17.334
we're different.

00:03:17.899 --> 00:03:23.634
We like to think we have cognitive control
over what people see, know and understand

00:03:23.658 --> 00:03:25.067
about our internal states --

00:03:25.091 --> 00:03:29.394
our emotions, our insecurities,
our bluffs, our trials and tribulations --

00:03:29.418 --> 00:03:30.685
and how we respond.

00:03:31.927 --> 00:03:34.209
We get to have our poker face.

00:03:35.799 --> 00:03:36.999
Or maybe we don't.

00:03:37.728 --> 00:03:38.910
Try this with me.

00:03:38.934 --> 00:03:41.624
Your eye responds
to how hard your brain is working.

00:03:42.363 --> 00:03:45.593
The response you're about to see
is driven entirely by mental effort

00:03:45.617 --> 00:03:48.252
and has nothing to do
with changes in lighting.

00:03:48.276 --> 00:03:49.926
We know this from neuroscience.

00:03:49.950 --> 00:03:54.510
I promise, your eyes are doing
the same thing as the subject in our lab,

00:03:54.534 --> 00:03:56.268
whether you want them to or not.

00:03:56.292 --> 00:03:58.465
At first, you'll hear some voices.

00:03:58.489 --> 00:04:01.767
Try and understand them
and keep watching the eye in front of you.

00:04:01.791 --> 00:04:03.289
It's going to be hard at first,

00:04:03.313 --> 00:04:05.704
one should drop out,
and it should get really easy.

00:04:05.728 --> 00:04:09.053
You're going to see the change in effort
in the diameter of the pupil.

00:04:10.140 --> 00:04:12.707
(Video) (Two overlapping voices talking)

00:04:12.731 --> 00:04:15.694
(Single voice) Intelligent technology
depends on personal data.

00:04:15.718 --> 00:04:18.164
(Two overlapping voices talking)

00:04:18.188 --> 00:04:21.164
(Single voice) Intelligent technology
depends on personal data.

00:04:21.680 --> 00:04:23.006
PC: Your pupil doesn't lie.

00:04:23.030 --> 00:04:25.430
Your eye gives away your poker face.

00:04:25.990 --> 00:04:27.903
When your brain's having to work harder,

00:04:27.927 --> 00:04:30.712
your autonomic nervous system
drives your pupil to dilate.

00:04:30.736 --> 00:04:32.291
When it's not, it contracts.

00:04:32.680 --> 00:04:34.371
When I take away one of the voices,

00:04:34.395 --> 00:04:36.657
the cognitive effort
to understand the talkers

00:04:36.681 --> 00:04:37.839
gets a lot easier.

00:04:37.863 --> 00:04:40.863
I could have put the two voices
in different spatial locations,

00:04:40.887 --> 00:04:42.553
I could have made one louder.

00:04:42.577 --> 00:04:44.315
You would have seen the same thing.

00:04:45.006 --> 00:04:49.792
We might think we have more agency
over the reveal of our internal state

00:04:49.816 --> 00:04:51.395
than that spider,

00:04:51.419 --> 00:04:52.685
but maybe we don't.

00:04:53.021 --> 00:04:55.990
Today's technology is starting
to make it really easy

00:04:56.014 --> 00:04:58.704
to see the signals and tells
that give us away.

00:04:59.109 --> 00:05:02.403
The amalgamation of sensors
paired with machine learning

00:05:02.427 --> 00:05:04.840
on us, around us and in our environments,

00:05:04.864 --> 00:05:09.517
is a lot more than cameras and microphones
tracking our external actions.

00:05:12.529 --> 00:05:15.347
Our bodies radiate our stories

00:05:15.371 --> 00:05:18.037
from changes in the temperature
of our physiology.

00:05:18.546 --> 00:05:20.807
We can look at these
as infrared thermal images

00:05:20.831 --> 00:05:21.991
showing up behind me,

00:05:22.015 --> 00:05:24.085
where reds are hotter
and blues are cooler.

00:05:24.458 --> 00:05:27.641
The dynamic signature
of our thermal response

00:05:27.665 --> 00:05:30.696
gives away our changes in stress,

00:05:30.720 --> 00:05:32.728
how hard our brain is working,

00:05:32.752 --> 00:05:34.688
whether we're paying attention

00:05:34.712 --> 00:05:37.339
and engaged in the conversation
we might be having

00:05:37.363 --> 00:05:41.458
and even whether we're experiencing
a picture of fire as if it were real.

00:05:41.482 --> 00:05:44.125
We can actually see
people give off heat on their cheeks

00:05:44.149 --> 00:05:46.349
in response to an image of flame.

00:05:48.013 --> 00:05:50.942
But aside from giving away
our poker bluffs,

00:05:50.966 --> 00:05:55.712
what if dimensions of data
from someone's thermal response

00:05:55.736 --> 00:05:58.395
gave away a glow
of interpersonal interest?

00:05:58.966 --> 00:06:02.498
Tracking the honesty of feelings
in someone's thermal image

00:06:02.522 --> 00:06:06.148
might be a new part of how
we fall in love and see attraction.

00:06:06.172 --> 00:06:09.865
Our technology can listen,
develop insights and make predictions

00:06:09.889 --> 00:06:11.984
about our mental and physical health

00:06:12.008 --> 00:06:16.008
just by analyzing the timing dynamics
of our speech and language

00:06:16.032 --> 00:06:17.475
picked up by microphones.

00:06:18.038 --> 00:06:21.918
Groups have shown that changes
in the statistics of our language

00:06:21.942 --> 00:06:23.362
paired with machine learning

00:06:23.386 --> 00:06:26.547
can predict the likelihood
someone will develop psychosis.

00:06:27.442 --> 00:06:29.193
I'm going to take it a step further

00:06:29.217 --> 00:06:31.804
and look at linguistic changes
and changes in our voice

00:06:31.828 --> 00:06:34.067
that show up with a lot
of different conditions.

00:06:34.091 --> 00:06:38.458
Dementia, diabetes can alter
the spectral coloration of our voice.

00:06:39.205 --> 00:06:42.324
Changes in our language
associated with Alzheimer's

00:06:42.348 --> 00:06:46.713
can sometimes show up more
than 10 years before clinical diagnosis.

00:06:47.236 --> 00:06:51.196
What we say and how we say it
tells a much richer story

00:06:51.220 --> 00:06:52.474
than we used to think.

00:06:53.022 --> 00:06:57.069
And devices we already have in our homes
could, if we let them,

00:06:57.093 --> 00:06:59.227
give us invaluable insight back.

00:06:59.998 --> 00:07:02.976
The chemical composition of our breath

00:07:03.959 --> 00:07:05.313
gives away our feelings.

00:07:06.363 --> 00:07:10.841
There's a dynamic mixture of acetone,
isoprene and carbon dioxide

00:07:10.865 --> 00:07:14.249
that changes when our heart speeds up,
when our muscles tense,

00:07:14.809 --> 00:07:17.706
and all without any obvious change
in our behaviors.

00:07:18.268 --> 00:07:21.006
Alright, I want you to watch
this clip with me.

00:07:21.030 --> 00:07:24.149
Some things might be going on
on the side screens,

00:07:24.173 --> 00:07:27.950
but try and focus on
the image in the front

00:07:27.974 --> 00:07:29.437
and the man at the window.

00:07:31.633 --> 00:07:34.291
(Eerie music)

00:07:39.767 --> 00:07:41.204
(Woman screams)

00:07:50.692 --> 00:07:53.087
PC: Sorry about that.
I needed to get a reaction.

00:07:53.111 --> 00:07:54.896
(Laughter)

00:07:55.412 --> 00:08:00.384
I'm actually tracking the carbon dioxide
you exhale in the room right now.

00:08:01.903 --> 00:08:05.196
We've installed tubes
throughout the theater,

00:08:05.220 --> 00:08:07.815
lower to the ground,
because CO2 is heavier than air.

00:08:07.839 --> 00:08:10.506
But they're connected
to a device in the back

00:08:10.530 --> 00:08:13.817
that lets us measure, in real time,
with high precision,

00:08:13.841 --> 00:08:16.763
the continuous differential
concentration of CO2.

00:08:17.246 --> 00:08:22.754
The clouds on the sides are actually
the real-time data visualization

00:08:22.778 --> 00:08:24.776
of the density of our CO2.

00:08:25.374 --> 00:08:29.073
You might still see
a patch of red on the screen,

00:08:29.097 --> 00:08:32.802
because we're showing increases
with larger colored clouds,

00:08:32.826 --> 00:08:35.022
larger colored areas of red.

00:08:35.046 --> 00:08:37.605
And that's the point
where a lot of us jumped.

00:08:38.173 --> 00:08:43.088
It's our collective suspense
driving a change in carbon dioxide.

00:08:43.649 --> 00:08:46.371
Alright, now, watch this
with me one more time.

00:08:46.395 --> 00:08:48.633
(Cheerful music)

00:08:54.553 --> 00:08:56.690
(Woman laughs)

00:09:05.344 --> 00:09:06.693
PC: You knew it was coming.

00:09:06.717 --> 00:09:10.080
But it's a lot different
when we changed the creator's intent.

00:09:10.776 --> 00:09:13.545
Changing the music and the sound effects

00:09:13.569 --> 00:09:17.172
completely alter the emotional
impact of that scene.

00:09:17.196 --> 00:09:19.330
And we can see it in our breath.

00:09:20.196 --> 00:09:22.458
Suspense, fear, joy

00:09:22.482 --> 00:09:26.989
all show up as reproducible,
visually identifiable moments.

00:09:27.473 --> 00:09:31.624
We broadcast a chemical signature
of our emotions.

00:09:35.249 --> 00:09:37.382
It is the end of the poker face.

00:09:38.582 --> 00:09:42.148
Our spaces, our technology
will know what we're feeling.

00:09:42.736 --> 00:09:45.521
We will know more about each other
than we ever have.

00:09:45.911 --> 00:09:50.218
We get a chance to reach in and connect
to the experience and sentiments

00:09:50.242 --> 00:09:51.984
that are fundamental to us as humans

00:09:52.008 --> 00:09:54.418
in our senses, emotionally and socially.

00:09:55.482 --> 00:09:58.022
I believe it is the era of the empath.

00:09:58.046 --> 00:10:03.268
And we are enabling the capabilities
that true technological partners can bring

00:10:03.292 --> 00:10:06.339
to how we connect with each other
and with our technology.

00:10:06.363 --> 00:10:09.752
If we recognize the power
of becoming technological empaths,

00:10:09.776 --> 00:10:11.712
we get this opportunity

00:10:11.736 --> 00:10:16.160
where technology can help us bridge
the emotional and cognitive divide.

00:10:16.680 --> 00:10:19.403
And in that way, we get to change
how we tell our stories.

00:10:19.427 --> 00:10:23.007
We can enable a better future
for technologies like augmented reality

00:10:23.031 --> 00:10:27.224
to extend our own agency
and connect us at a much deeper level.

00:10:27.625 --> 00:10:30.172
Imagine a high school counselor
being able to realize

00:10:30.196 --> 00:10:34.022
that an outwardly cheery student
really was having a deeply hard time,

00:10:34.046 --> 00:10:37.226
where reaching out can make
a crucial, positive difference.

00:10:37.766 --> 00:10:40.996
Or authorities, being able
to know the difference

00:10:41.020 --> 00:10:43.345
between someone having
a mental health crisis

00:10:43.369 --> 00:10:45.195
and a different type of aggression,

00:10:45.219 --> 00:10:47.019
and responding accordingly.

00:10:47.609 --> 00:10:50.882
Or an artist, knowing
the direct impact of their work.

00:10:52.173 --> 00:10:54.816
Leo Tolstoy defined his perspective of art

00:10:54.840 --> 00:10:56.625
by whether what the creator intended

00:10:56.649 --> 00:10:59.235
was experienced by the person
on the other end.

00:10:59.259 --> 00:11:01.825
Today's artists can know
what we're feeling.

00:11:02.204 --> 00:11:05.209
But regardless of whether
it's art or human connection,

00:11:06.608 --> 00:11:09.410
today's technologies
will know and can know

00:11:09.434 --> 00:11:11.482
what we're experiencing on the other side,

00:11:11.506 --> 00:11:14.124
and this means we can be
closer and more authentic.

00:11:14.498 --> 00:11:18.791
But I realize a lot of us
have a really hard time

00:11:18.815 --> 00:11:21.082
with the idea of sharing our data,

00:11:21.673 --> 00:11:24.784
and especially the idea
that people know things about us

00:11:24.808 --> 00:11:27.129
that we didn't actively choose to share.

00:11:28.728 --> 00:11:30.944
Anytime we talk to someone,

00:11:31.946 --> 00:11:33.501
look at someone

00:11:33.525 --> 00:11:34.993
or choose not to look,

00:11:35.017 --> 00:11:37.664
data is exchanged, given away,

00:11:38.533 --> 00:11:40.738
that people use to learn,

00:11:40.762 --> 00:11:44.029
make decisions about
their lives and about ours.

00:11:45.469 --> 00:11:49.437
I'm not looking to create a world
where our inner lives are ripped open

00:11:49.461 --> 00:11:51.809
and our personal data
and our privacy given away

00:11:51.833 --> 00:11:54.546
to people and entities
where we don't want to see it go.

00:11:55.117 --> 00:11:57.879
But I am looking to create a world

00:11:57.903 --> 00:12:01.311
where we can care about
each other more effectively,

00:12:01.335 --> 00:12:04.395
we can know more about when
someone is feeling something

00:12:04.419 --> 00:12:06.291
that we ought to pay attention to.

00:12:06.800 --> 00:12:10.135
And we can have richer experiences
from our technology.

00:12:10.887 --> 00:12:13.244
Any technology
can be used for good or bad.

00:12:13.268 --> 00:12:15.680
Transparency to engagement
and effective regulation

00:12:15.704 --> 00:12:18.824
are absolutely critical
to building the trust for any of this.

00:12:20.106 --> 00:12:24.940
But the benefits that "empathetic
technology" can bring to our lives

00:12:24.964 --> 00:12:28.855
are worth solving the problems
that make us uncomfortable.

00:12:29.315 --> 00:12:33.340
And if we don't, there are
too many opportunities and feelings

00:12:33.364 --> 00:12:35.059
we're going to be missing out on.

00:12:35.083 --> 00:12:36.258
Thank you.

00:12:36.282 --> 00:12:38.761
(Applause)

