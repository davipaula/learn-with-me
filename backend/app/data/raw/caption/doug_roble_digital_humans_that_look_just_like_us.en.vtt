WEBVTT
Kind: captions
Language: en

00:00:13.937 --> 00:00:15.151
Hello.

00:00:15.175 --> 00:00:16.641
I'm not a real person.

00:00:17.119 --> 00:00:19.889
I'm actually a copy of a real person.

00:00:19.913 --> 00:00:22.466
Although, I feel like a real person.

00:00:22.490 --> 00:00:24.396
It's kind of hard to explain.

00:00:24.420 --> 00:00:28.210
Hold on -- I think I saw
a real person ... there's one.

00:00:28.697 --> 00:00:30.097
Let's bring him onstage.

00:00:33.307 --> 00:00:34.457
Hello.

00:00:35.485 --> 00:00:39.132
(Applause)

00:00:40.300 --> 00:00:43.394
What you see up there is a digital human.

00:00:43.990 --> 00:00:46.974
I'm wearing an inertial
motion capture suit

00:00:46.998 --> 00:00:49.577
that's figuring what my body is doing.

00:00:49.601 --> 00:00:53.426
And I've got a single camera here
that's watching my face

00:00:53.450 --> 00:00:58.291
and feeding some machine-learning software
that's taking my expressions,

00:00:58.315 --> 00:01:01.894
like, "Hm, hm, hm,"

00:01:02.379 --> 00:01:04.042
and transferring it to that guy.

00:01:05.300 --> 00:01:08.642
We call him "DigiDoug."

00:01:09.292 --> 00:01:14.018
He's actually a 3-D character
that I'm controlling live in real time.

00:01:16.292 --> 00:01:18.616
So, I work in visual effects.

00:01:19.101 --> 00:01:20.268
And in visual effects,

00:01:20.292 --> 00:01:26.203
one of the hardest things to do
is to create believable, digital humans

00:01:26.227 --> 00:01:28.409
that the audience accepts as real.

00:01:28.433 --> 00:01:32.957
People are just really good
at recognizing other people.

00:01:32.981 --> 00:01:34.131
Go figure!

00:01:35.577 --> 00:01:38.982
So, that's OK, we like a challenge.

00:01:39.006 --> 00:01:40.847
Over the last 15 years,

00:01:40.871 --> 00:01:45.854
we've been putting
humans and creatures into film

00:01:45.878 --> 00:01:47.617
that you accept as real.

00:01:48.712 --> 00:01:51.379
If they're happy, you should feel happy.

00:01:51.982 --> 00:01:57.419
And if they feel pain,
you should empathize with them.

00:01:58.467 --> 00:02:00.657
We're getting pretty good at it, too.

00:02:00.681 --> 00:02:03.427
But it's really, really difficult.

00:02:03.847 --> 00:02:07.061
Effects like these take thousands of hours

00:02:07.085 --> 00:02:09.752
and hundreds of really talented artists.

00:02:10.792 --> 00:02:12.392
But things have changed.

00:02:13.014 --> 00:02:14.934
Over the last five years,

00:02:14.958 --> 00:02:19.367
computers and graphics cards
have gotten seriously fast.

00:02:20.508 --> 00:02:24.479
And machine learning,
deep learning, has happened.

00:02:25.408 --> 00:02:26.641
So we asked ourselves:

00:02:27.320 --> 00:02:31.098
Do you suppose we could create
a photo-realistic human,

00:02:31.122 --> 00:02:32.746
like we're doing for film,

00:02:33.932 --> 00:02:39.579
but where you're seeing
the actual emotions and the details

00:02:39.603 --> 00:02:43.680
of the person who's controlling
the digital human

00:02:43.704 --> 00:02:44.878
in real time?

00:02:45.704 --> 00:02:47.268
In fact, that's our goal:

00:02:47.292 --> 00:02:51.053
If you were having
a conversation with DigiDoug

00:02:51.077 --> 00:02:52.314
one-on-one,

00:02:53.331 --> 00:02:58.997
is it real enough so that you could tell
whether or not I was lying to you?

00:02:59.934 --> 00:03:01.334
So that was our goal.

00:03:02.601 --> 00:03:06.617
About a year and a half ago,
we set off to achieve this goal.

00:03:06.641 --> 00:03:10.540
What I'm going to do now is take you
basically on a little bit of a journey

00:03:10.564 --> 00:03:14.490
to see exactly what we had to do
to get where we are.

00:03:15.832 --> 00:03:19.688
We had to capture
an enormous amount of data.

00:03:20.347 --> 00:03:23.061
In fact, by the end of this thing,

00:03:23.085 --> 00:03:27.648
we had probably one of the largest
facial data sets on the planet.

00:03:28.038 --> 00:03:29.720
Of my face.

00:03:29.744 --> 00:03:32.006
(Laughter)

00:03:32.030 --> 00:03:33.300
Why me?

00:03:33.324 --> 00:03:36.134
Well, I'll do just about
anything for science.

00:03:36.158 --> 00:03:38.106
I mean, look at me!

00:03:38.625 --> 00:03:39.775
I mean, come on.

00:03:43.320 --> 00:03:48.780
We had to first figure out
what my face actually looked like.

00:03:49.391 --> 00:03:52.418
Not just a photograph or a 3-D scan,

00:03:52.442 --> 00:03:56.363
but what it actually looked like
in any photograph,

00:03:56.387 --> 00:03:58.847
how light interacts with my skin.

00:03:59.768 --> 00:04:05.017
Luckily for us, about three blocks away
from our Los Angeles studio

00:04:05.041 --> 00:04:07.250
is this place called ICT.

00:04:07.708 --> 00:04:08.980
They're a research lab

00:04:09.004 --> 00:04:12.407
that's associated with the University
of Southern California.

00:04:12.871 --> 00:04:16.426
They have a device there,
it's called the "light stage."

00:04:16.450 --> 00:04:20.164
It has a zillion
individually controlled lights

00:04:20.188 --> 00:04:22.061
and a whole bunch of cameras.

00:04:22.085 --> 00:04:28.176
And with that, we can reconstruct my face
under a myriad of lighting conditions.

00:04:29.589 --> 00:04:31.171
We even captured the blood flow

00:04:31.195 --> 00:04:34.287
and how my face changes
when I make expressions.

00:04:35.454 --> 00:04:40.714
This let us build a model of my face
that, quite frankly, is just amazing.

00:04:41.399 --> 00:04:45.732
It's got an unfortunate
level of detail, unfortunately.

00:04:45.756 --> 00:04:47.034
(Laughter)

00:04:47.058 --> 00:04:50.754
You can see every pore, every wrinkle.

00:04:50.778 --> 00:04:52.378
But we had to have that.

00:04:52.960 --> 00:04:55.341
Reality is all about detail.

00:04:55.365 --> 00:04:57.232
And without it, you miss it.

00:04:58.793 --> 00:05:00.340
We are far from done, though.

00:05:01.363 --> 00:05:04.660
This let us build a model of my face
that looked like me.

00:05:05.196 --> 00:05:07.942
But it didn't really move like me.

00:05:08.871 --> 00:05:11.584
And that's where
machine learning comes in.

00:05:11.608 --> 00:05:14.812
And machine learning needs a ton of data.

00:05:15.497 --> 00:05:20.426
So I sat down in front of some
high-resolution motion-capturing device.

00:05:20.450 --> 00:05:24.521
And also, we did this traditional
motion capture with markers.

00:05:25.696 --> 00:05:28.672
We created a whole bunch
of images of my face

00:05:28.696 --> 00:05:32.783
and moving point clouds
that represented that shapes of my face.

00:05:33.996 --> 00:05:36.807
Man, I made a lot of expressions,

00:05:36.831 --> 00:05:40.291
I said different lines
in different emotional states ...

00:05:40.315 --> 00:05:42.982
We had to do a lot of capture with this.

00:05:43.752 --> 00:05:46.643
Once we had this enormous amount of data,

00:05:46.667 --> 00:05:50.442
we built and trained deep neural networks.

00:05:51.117 --> 00:05:52.863
And when we were finished with that,

00:05:52.887 --> 00:05:55.331
in 16 milliseconds,

00:05:55.355 --> 00:05:58.467
the neural network can look at my image

00:05:58.491 --> 00:06:01.419
and figure out everything about my face.

00:06:02.458 --> 00:06:07.934
It can compute my expression,
my wrinkles, my blood flow --

00:06:07.958 --> 00:06:10.275
even how my eyelashes move.

00:06:10.925 --> 00:06:13.760
This is then rendered
and displayed up there

00:06:13.784 --> 00:06:17.006
with all the detail
that we captured previously.

00:06:18.077 --> 00:06:19.411
We're far from done.

00:06:20.188 --> 00:06:22.395
This is very much a work in progress.

00:06:22.419 --> 00:06:25.740
This is actually the first time
we've shown it outside of our company.

00:06:25.764 --> 00:06:29.958
And, you know, it doesn't look
as convincing as we want;

00:06:29.982 --> 00:06:32.165
I've got wires coming out
of the back of me,

00:06:32.189 --> 00:06:34.227
and there's a sixth-of-a-second delay

00:06:34.251 --> 00:06:38.618
between when we capture the video
and we display it up there.

00:06:38.642 --> 00:06:41.458
Sixth of a second -- that's crazy good!

00:06:41.911 --> 00:06:45.311
But it's still why you're hearing
a bit of an echo and stuff.

00:06:46.104 --> 00:06:49.993
And you know, this machine learning
stuff is brand-new to us,

00:06:50.017 --> 00:06:54.241
sometimes it's hard to convince
to do the right thing, you know?

00:06:54.265 --> 00:06:56.323
It goes a little sideways.

00:06:56.347 --> 00:06:58.769
(Laughter)

00:06:59.538 --> 00:07:02.767
But why did we do this?

00:07:03.077 --> 00:07:05.339
Well, there's two reasons, really.

00:07:05.363 --> 00:07:08.339
First of all, it is just crazy cool.

00:07:08.363 --> 00:07:09.371
(Laughter)

00:07:09.395 --> 00:07:10.648
How cool is it?

00:07:10.990 --> 00:07:12.982
Well, with the push of a button,

00:07:13.006 --> 00:07:17.013
I can deliver this talk
as a completely different character.

00:07:17.823 --> 00:07:20.424
This is Elbor.

00:07:22.037 --> 00:07:24.349
We put him together
to test how this would work

00:07:24.373 --> 00:07:26.508
with a different appearance.

00:07:27.450 --> 00:07:32.268
And the cool thing about this technology
is that, while I've changed my character,

00:07:32.292 --> 00:07:35.565
the performance is still all me.

00:07:35.589 --> 00:07:38.263
I tend to talk out of the right
side of my mouth;

00:07:38.287 --> 00:07:39.866
so does Elbor.

00:07:39.890 --> 00:07:41.040
(Laughter)

00:07:42.021 --> 00:07:44.811
Now, the second reason we did this,
and you can imagine,

00:07:44.835 --> 00:07:47.171
is this is going to be great for film.

00:07:47.195 --> 00:07:49.896
This is a brand-new, exciting tool

00:07:49.920 --> 00:07:54.242
for artists and directors
and storytellers.

00:07:55.131 --> 00:07:56.615
It's pretty obvious, right?

00:07:56.639 --> 00:07:59.101
I mean, this is going to be
really neat to have.

00:07:59.125 --> 00:08:01.180
But also, now that we've built it,

00:08:01.204 --> 00:08:04.195
it's clear that this
is going to go way beyond film.

00:08:05.510 --> 00:08:06.660
But wait.

00:08:07.653 --> 00:08:11.629
Didn't I just change my identity
with the push of a button?

00:08:11.653 --> 00:08:14.686
Isn't this like "deepfake"
and face-swapping

00:08:14.710 --> 00:08:16.271
that you guys may have heard of?

00:08:17.208 --> 00:08:18.358
Well, yeah.

00:08:19.074 --> 00:08:22.026
In fact, we are using
some of the same technology

00:08:22.050 --> 00:08:23.650
that deepfake is using.

00:08:23.954 --> 00:08:28.553
Deepfake is 2-D and image based,
while ours is full 3-D

00:08:28.577 --> 00:08:30.783
and way more powerful.

00:08:31.204 --> 00:08:32.870
But they're very related.

00:08:33.680 --> 00:08:35.569
And now I can hear you thinking,

00:08:35.593 --> 00:08:36.871
"Darn it!

00:08:36.895 --> 00:08:40.696
I though I could at least
trust and believe in video.

00:08:40.720 --> 00:08:43.547
If it was live video,
didn't it have to be true?"

00:08:44.609 --> 00:08:48.131
Well, we know that's not
really the case, right?

00:08:48.727 --> 00:08:52.537
Even without this, there are simple tricks
that you can do with video

00:08:52.561 --> 00:08:55.337
like how you frame a shot

00:08:55.361 --> 00:08:59.723
that can make it really misrepresent
what's actually going on.

00:09:00.263 --> 00:09:03.569
And I've been working
in visual effects for a long time,

00:09:03.593 --> 00:09:05.525
and I've known for a long time

00:09:05.549 --> 00:09:10.775
that with enough effort,
we can fool anyone about anything.

00:09:11.546 --> 00:09:13.934
What this stuff and deepfake is doing

00:09:13.958 --> 00:09:18.569
is making it easier and more accessible
to manipulate video,

00:09:18.593 --> 00:09:23.964
just like Photoshop did
for manipulating images, some time ago.

00:09:25.441 --> 00:09:26.739
I prefer to think about

00:09:26.763 --> 00:09:31.799
how this technology could bring
humanity to other technology

00:09:31.823 --> 00:09:34.117
and bring us all closer together.

00:09:34.141 --> 00:09:36.500
Now that you've seen this,

00:09:36.524 --> 00:09:38.426
think about the possibilities.

00:09:39.810 --> 00:09:44.333
Right off the bat, you're going to see it
in live events and concerts, like this.

00:09:45.612 --> 00:09:50.347
Digital celebrities, especially
with new projection technology,

00:09:50.371 --> 00:09:54.331
are going to be just like the movies,
but alive and in real time.

00:09:55.609 --> 00:09:58.342
And new forms of communication are coming.

00:09:59.088 --> 00:10:03.253
You can already interact
with DigiDoug in VR.

00:10:03.699 --> 00:10:05.969
And it is eye-opening.

00:10:05.993 --> 00:10:09.855
It's just like you and I
are in the same room,

00:10:09.879 --> 00:10:12.252
even though we may be miles apart.

00:10:12.276 --> 00:10:15.117
Heck, the next time you make a video call,

00:10:15.141 --> 00:10:18.877
you will be able to choose
the version of you

00:10:18.901 --> 00:10:20.467
you want people to see.

00:10:20.974 --> 00:10:23.507
It's like really, really good makeup.

00:10:24.853 --> 00:10:28.432
I was scanned about a year and a half ago.

00:10:29.068 --> 00:10:30.789
I've aged.

00:10:30.813 --> 00:10:32.463
DigiDoug hasn't.

00:10:32.798 --> 00:10:36.290
On video calls, I never have to grow old.

00:10:38.322 --> 00:10:41.410
And as you can imagine,
this is going to be used

00:10:41.434 --> 00:10:44.647
to give virtual assistants
a body and a face.

00:10:44.671 --> 00:10:45.863
A humanity.

00:10:45.887 --> 00:10:48.649
I already love it that when I talk
to virtual assistants,

00:10:48.673 --> 00:10:51.606
they answer back in a soothing,
humanlike voice.

00:10:51.919 --> 00:10:53.695
Now they'll have a face.

00:10:53.719 --> 00:10:58.601
And you'll get all the nonverbal cues
that make communication so much easier.

00:11:00.171 --> 00:11:01.591
It's going to be really nice.

00:11:01.615 --> 00:11:05.252
You'll be able to tell when
a virtual assistant is busy or confused

00:11:05.276 --> 00:11:07.956
or concerned about something.

00:11:09.694 --> 00:11:12.203
Now, I couldn't leave the stage

00:11:12.227 --> 00:11:14.925
without you actually being able
to see my real face,

00:11:14.949 --> 00:11:16.633
so you can do some comparison.

00:11:18.573 --> 00:11:20.449
So let me take off my helmet here.

00:11:20.473 --> 00:11:25.243
Yeah, don't worry,
it looks way worse than it feels.

00:11:25.267 --> 00:11:27.695
(Laughter)

00:11:29.188 --> 00:11:30.886
So this is where we are.

00:11:30.910 --> 00:11:32.514
Let me put this back on here.

00:11:32.538 --> 00:11:34.488
(Laughter)

00:11:35.115 --> 00:11:36.301
Doink!

00:11:37.292 --> 00:11:38.892
So this is where we are.

00:11:39.997 --> 00:11:43.698
We're on the cusp of being able
to interact with digital humans

00:11:43.722 --> 00:11:45.903
that are strikingly real,

00:11:45.927 --> 00:11:49.196
whether they're being controlled
by a person or a machine.

00:11:49.220 --> 00:11:53.595
And like all new technology these days,

00:11:54.531 --> 00:11:59.277
it's going to come with some
serious and real concerns

00:11:59.301 --> 00:12:01.035
that we have to deal with.

00:12:02.017 --> 00:12:04.135
But I am just so really excited

00:12:04.159 --> 00:12:09.212
about the ability to bring something
that I've seen only in science fiction

00:12:09.236 --> 00:12:11.506
for my entire life

00:12:11.530 --> 00:12:12.858
into reality.

00:12:13.752 --> 00:12:17.974
Communicating with computers
will be like talking to a friend.

00:12:18.323 --> 00:12:20.823
And talking to faraway friends

00:12:20.847 --> 00:12:24.120
will be like sitting with them
together in the same room.

00:12:24.974 --> 00:12:26.282
Thank you very much.

00:12:26.306 --> 00:12:33.019
(Applause)

