WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Joseph Geni
Reviewer: Krystian Aparta

00:00:13.515 --> 00:00:17.221
So a friend of mine was riding
in a taxi to the airport the other day,

00:00:17.245 --> 00:00:19.955
and on the way, she was chatting
with the taxi driver,

00:00:19.979 --> 00:00:22.408
and he said to her, with total sincerity,

00:00:22.432 --> 00:00:25.718
"I can tell you are a really good person."

00:00:25.742 --> 00:00:27.559
And when she told me this story later,

00:00:27.583 --> 00:00:30.758
she said she couldn't believe
how good it made her feel,

00:00:30.782 --> 00:00:32.841
that it meant a lot to her.

00:00:32.865 --> 00:00:35.891
Now that may seem
like a strong reaction from my friend

00:00:35.915 --> 00:00:38.119
to the words of a total stranger,

00:00:38.143 --> 00:00:39.761
but she's not alone.

00:00:39.785 --> 00:00:41.150
I'm a social scientist.

00:00:41.174 --> 00:00:43.827
I study the psychology of good people,

00:00:43.851 --> 00:00:48.141
and research in my field says
many of us care deeply

00:00:48.165 --> 00:00:53.166
about feeling like a good person
and being seen as a good person.

00:00:53.467 --> 00:00:58.300
Now, your definition of "good person"
and your definition of "good person"

00:00:58.324 --> 00:01:01.064
and maybe the taxi driver's
definition of "good person" --

00:01:01.088 --> 00:01:03.071
we may not all have the same definition,

00:01:03.095 --> 00:01:05.920
but within whatever our definition is,

00:01:05.944 --> 00:01:08.745
that moral identity
is important to many of us.

00:01:09.154 --> 00:01:14.375
Now, if somebody challenges it,
like they question us for a joke we tell,

00:01:14.399 --> 00:01:17.082
or maybe we say
our workforce is homogenous,

00:01:17.106 --> 00:01:20.085
or a slippery business expense,

00:01:20.109 --> 00:01:23.307
we go into red-zone defensiveness
a lot of the time.

00:01:23.331 --> 00:01:26.422
I mean, sometimes we call out

00:01:26.446 --> 00:01:30.115
all the ways in which we help
people from marginalized groups,

00:01:30.139 --> 00:01:31.907
or we donate to charity,

00:01:31.931 --> 00:01:35.970
or the hours we volunteer to nonprofits.

00:01:35.994 --> 00:01:39.685
We work to protect
that good person identity.

00:01:39.709 --> 00:01:41.645
It's important to many of us.

00:01:42.517 --> 00:01:44.375
But what if I told you this?

00:01:44.399 --> 00:01:49.113
What if I told you that our attachment
to being good people

00:01:49.137 --> 00:01:51.653
is getting in the way
of us being better people?

00:01:52.225 --> 00:01:58.551
What if I told you that our definition
of "good person" is so narrow,

00:01:58.575 --> 00:02:01.106
it's scientifically impossible to meet?

00:02:01.806 --> 00:02:05.083
And what if I told you
the path to being better people

00:02:05.107 --> 00:02:08.043
just begins with letting go
of being a good person?

00:02:08.876 --> 00:02:11.516
Now, let me tell you a little bit
about the research

00:02:11.540 --> 00:02:13.012
about how the human mind works

00:02:13.036 --> 00:02:14.186
to explain.

00:02:14.540 --> 00:02:18.648
The brain relies on shortcuts
to do a lot of its work.

00:02:18.672 --> 00:02:20.297
That means a lot of the time,

00:02:20.321 --> 00:02:23.649
your mental processes are taking place
outside of your awareness,

00:02:23.673 --> 00:02:28.411
like in low-battery, low-power mode
in the back of your mind.

00:02:29.088 --> 00:02:32.549
That's, in fact, the premise
of bounded rationality.

00:02:32.573 --> 00:02:36.014
Bounded rationality is
the Nobel Prize-winning idea

00:02:36.038 --> 00:02:38.880
that the human mind
has limited storage resources,

00:02:38.904 --> 00:02:41.000
limited processing power,

00:02:41.024 --> 00:02:45.056
and as a result, it relies on shortcuts
to do a lot of its work.

00:02:45.571 --> 00:02:47.095
So for example,

00:02:47.833 --> 00:02:50.467
some scientists estimate
that in any given moment ...

00:02:51.270 --> 00:02:53.350
Better, better click, right? There we go.

00:02:53.374 --> 00:02:54.381
(Laughter)

00:02:54.405 --> 00:02:55.649
At any given moment,

00:02:55.673 --> 00:02:59.477
11 million pieces of information
are coming into your mind.

00:03:00.054 --> 00:03:01.670
Eleven million.

00:03:01.694 --> 00:03:04.567
And only 40 of them
are being processed consciously.

00:03:05.051 --> 00:03:07.273
So 11 million, 40.

00:03:08.140 --> 00:03:10.024
I mean, has this ever happened to you?

00:03:10.048 --> 00:03:12.402
Have you ever had
a really busy day at work,

00:03:12.426 --> 00:03:14.155
and you drive home,

00:03:14.179 --> 00:03:16.397
and when you get in the door,

00:03:16.421 --> 00:03:19.669
you realize you don't
even remember the drive home,

00:03:19.693 --> 00:03:22.196
like whether you had
green lights or red lights.

00:03:22.220 --> 00:03:24.630
You don't even remember.
You were on autopilot.

00:03:24.974 --> 00:03:28.261
Or have you ever opened the fridge,

00:03:28.285 --> 00:03:30.357
looked for the butter,

00:03:30.381 --> 00:03:33.325
swore there is no butter,

00:03:33.349 --> 00:03:36.966
and then realized the butter
was right in front of you the whole time?

00:03:36.990 --> 00:03:40.511
These are the kinds of "whoops" moments
that make us giggle,

00:03:40.535 --> 00:03:42.546
and this is what happens in a brain

00:03:42.570 --> 00:03:46.144
that can handle 11 million
pieces of information coming in

00:03:46.168 --> 00:03:48.745
with only 40 being processed consciously.

00:03:48.769 --> 00:03:52.149
That's the bounded part
of bounded rationality.

00:03:55.352 --> 00:03:57.829
This work on bounded rationality

00:03:57.853 --> 00:04:02.019
is what's inspired work I've done
with my collaborators

00:04:02.043 --> 00:04:04.678
Max Bazerman and Mahzarin Banaji,

00:04:04.702 --> 00:04:07.348
on what we call bounded ethicality.

00:04:07.702 --> 00:04:10.774
So it's the same premise
as bounded rationality,

00:04:10.798 --> 00:04:16.399
that we have a human mind
that is bounded in some sort of way

00:04:16.423 --> 00:04:18.505
and relying on shortcuts,

00:04:18.529 --> 00:04:22.354
and that those shortcuts
can sometimes lead us astray.

00:04:22.886 --> 00:04:24.411
With bounded rationality,

00:04:24.435 --> 00:04:28.121
perhaps it affects the cereal
we buy in the grocery store,

00:04:28.145 --> 00:04:31.228
or the product we launch in the boardroom.

00:04:31.836 --> 00:04:34.519
With bounded ethicality, the human mind,

00:04:34.543 --> 00:04:36.622
the same human mind,

00:04:36.646 --> 00:04:38.138
is making decisions,

00:04:38.162 --> 00:04:40.948
and here, it's about who to hire next,

00:04:40.972 --> 00:04:42.622
or what joke to tell

00:04:42.646 --> 00:04:44.868
or that slippery business decision.

00:04:46.157 --> 00:04:50.760
So let me give you an example
of bounded ethicality at work.

00:04:50.784 --> 00:04:53.570
Unconscious bias is one place

00:04:53.594 --> 00:04:57.103
where we see the effects
of bounded ethicality.

00:04:57.127 --> 00:05:01.513
So unconscious bias refers
to associations we have in our mind,

00:05:01.537 --> 00:05:05.827
the shortcuts your brain is using
to organize information,

00:05:05.851 --> 00:05:08.115
very likely outside of your awareness,

00:05:08.139 --> 00:05:11.591
not necessarily lining up
with your conscious beliefs.

00:05:12.503 --> 00:05:15.027
Researchers Nosek, Banaji and Greenwald

00:05:15.051 --> 00:05:17.782
have looked at data
from millions of people,

00:05:17.806 --> 00:05:20.563
and what they've found is, for example,

00:05:20.587 --> 00:05:24.080
most white Americans
can more quickly and easily

00:05:24.104 --> 00:05:28.373
associate white people and good things

00:05:28.397 --> 00:05:30.690
than black people and good things,

00:05:31.650 --> 00:05:37.264
and most men and women
can more quickly and easily associate

00:05:37.288 --> 00:05:41.590
men and science than women and science.

00:05:42.137 --> 00:05:46.424
And these associations
don't necessarily line up

00:05:46.448 --> 00:05:48.323
with what people consciously think.

00:05:48.347 --> 00:05:51.680
They may have
very egalitarian views, in fact.

00:05:52.206 --> 00:05:56.619
So sometimes, that 11 million
and that 40 just don't line up.

00:05:57.402 --> 00:05:59.369
And here's another example:

00:05:59.393 --> 00:06:00.885
conflicts of interest.

00:06:01.372 --> 00:06:05.182
So we tend to underestimate
how much a small gift --

00:06:05.206 --> 00:06:08.849
imagine a ballpoint pen or dinner --

00:06:08.873 --> 00:06:13.031
how much that small gift
can affect our decision making.

00:06:13.852 --> 00:06:18.178
We don't realize that our mind
is unconsciously lining up evidence

00:06:18.202 --> 00:06:21.733
to support the point of view
of the gift-giver,

00:06:21.757 --> 00:06:26.578
no matter how hard we're consciously
trying to be objective and professional.

00:06:27.689 --> 00:06:29.408
We also see bounded ethicality --

00:06:29.432 --> 00:06:32.809
despite our attachment
to being good people,

00:06:32.833 --> 00:06:34.914
we still make mistakes,

00:06:34.938 --> 00:06:38.949
and we make mistakes
that sometimes hurt other people,

00:06:38.973 --> 00:06:41.443
that sometimes promote injustice,

00:06:41.467 --> 00:06:43.492
despite our best attempts,

00:06:43.516 --> 00:06:47.633
and we explain away our mistakes
rather than learning from them.

00:06:48.810 --> 00:06:51.263
Like, for example,

00:06:51.287 --> 00:06:55.088
when I got an email
from a female student in my class

00:06:55.112 --> 00:06:57.660
saying that a reading I had assigned,

00:06:57.684 --> 00:07:00.438
a reading I had been assigning for years,

00:07:00.462 --> 00:07:01.893
was sexist.

00:07:02.738 --> 00:07:08.326
Or when I confused
two students in my class

00:07:08.350 --> 00:07:09.707
of the same race --

00:07:09.731 --> 00:07:12.001
look nothing alike --

00:07:12.025 --> 00:07:14.184
when I confused them for each other

00:07:14.208 --> 00:07:16.873
more than once, in front of everybody.

00:07:17.885 --> 00:07:22.208
These kinds of mistakes send us, send me,

00:07:22.232 --> 00:07:25.067
into red-zone defensiveness.

00:07:25.091 --> 00:07:29.321
They leave us fighting
for that good person identity.

00:07:30.189 --> 00:07:34.529
But the latest work that I've been doing
on bounded ethicality with Mary Kern

00:07:34.553 --> 00:07:38.125
says that we're not
only prone to mistakes --

00:07:38.149 --> 00:07:43.388
that tendency towards mistakes depends
on how close we are to that red zone.

00:07:43.412 --> 00:07:47.611
So most of the time, nobody's challenging
our good person identity,

00:07:47.635 --> 00:07:49.794
and so we're not thinking too much

00:07:49.818 --> 00:07:52.151
about the ethical implications
of our decisions,

00:07:52.175 --> 00:07:56.054
and our model shows
that we're then spiraling

00:07:56.078 --> 00:08:00.817
towards less and less
ethical behavior most of the time.

00:08:00.841 --> 00:08:03.689
On the other hand, somebody
might challenge our identity,

00:08:03.713 --> 00:08:07.212
or, upon reflection,
we may be challenging it ourselves.

00:08:07.236 --> 00:08:11.360
So the ethical implications
of our decisions become really salient,

00:08:11.384 --> 00:08:17.121
and in those cases, we spiral towards
more and more good person behavior,

00:08:17.145 --> 00:08:18.986
or, to be more precise,

00:08:19.010 --> 00:08:23.548
towards more and more behavior
that makes us feel like a good person,

00:08:23.572 --> 00:08:26.016
which isn't always the same, of course.

00:08:27.413 --> 00:08:31.056
The idea with bounded ethicality

00:08:31.080 --> 00:08:35.282
is that we are perhaps overestimating

00:08:35.306 --> 00:08:40.474
the importance our inner compass
is playing in our ethical decisions.

00:08:40.498 --> 00:08:44.983
We perhaps are overestimating
how much our self-interest

00:08:45.007 --> 00:08:48.379
is driving our decisions,

00:08:48.403 --> 00:08:54.118
and perhaps we don't realize
how much our self-view as a good person

00:08:54.142 --> 00:08:56.666
is affecting our behavior,

00:08:56.690 --> 00:09:02.175
that in fact, we're working so hard
to protect that good person identity,

00:09:02.199 --> 00:09:04.493
to keep out of that red zone,

00:09:04.517 --> 00:09:09.871
that we're not actually giving ourselves
space to learn from our mistakes

00:09:09.895 --> 00:09:12.212
and actually be better people.

00:09:13.998 --> 00:09:17.039
It's perhaps because
we expect it to be easy.

00:09:17.063 --> 00:09:21.153
We have this definition
of good person that's either-or.

00:09:21.177 --> 00:09:24.216
Either you are a good person
or you're not.

00:09:24.240 --> 00:09:26.860
Either you have integrity or you don't.

00:09:26.884 --> 00:09:31.516
Either you are a racist or a sexist
or a homophobe or you're not.

00:09:31.540 --> 00:09:35.523
And in this either-or definition,
there's no room to grow.

00:09:36.444 --> 00:09:37.595
And by the way,

00:09:37.619 --> 00:09:40.603
this is not what we do
in most parts of our lives.

00:09:40.627 --> 00:09:43.102
Life, if you needed to learn accounting,

00:09:43.126 --> 00:09:44.819
you would take an accounting class,

00:09:44.843 --> 00:09:47.137
or if you become a parent,

00:09:47.161 --> 00:09:50.668
we pick up a book and we read about it.

00:09:50.692 --> 00:09:53.319
We talk to experts,

00:09:53.343 --> 00:09:54.797
we learn from our mistakes,

00:09:54.821 --> 00:09:56.320
we update our knowledge,

00:09:56.344 --> 00:09:58.310
we just keep getting better.

00:09:58.835 --> 00:10:00.791
But when it comes to being a good person,

00:10:00.815 --> 00:10:03.307
we think it's something
we're just supposed to know,

00:10:03.331 --> 00:10:04.594
we're just supposed to do,

00:10:04.618 --> 00:10:07.926
without the benefit of effort or growth.

00:10:07.950 --> 00:10:09.790
So what I've been thinking about

00:10:09.814 --> 00:10:13.966
is what if we were to just forget
about being good people,

00:10:13.990 --> 00:10:15.755
just let it go,

00:10:15.779 --> 00:10:18.875
and instead, set a higher standard,

00:10:18.899 --> 00:10:21.961
a higher standard
of being a good-ish person?

00:10:24.891 --> 00:10:29.114
A good-ish person
absolutely still makes mistakes.

00:10:29.138 --> 00:10:32.180
As a good-ish person,
I'm making them all the time.

00:10:32.881 --> 00:10:37.255
But as a good-ish person,
I'm trying to learn from them, own them.

00:10:37.279 --> 00:10:40.838
I expect them and I go after them.

00:10:40.862 --> 00:10:43.466
I understand there are costs
to these mistakes.

00:10:43.490 --> 00:10:47.558
When it comes to issues like ethics
and bias and diversity and inclusion,

00:10:47.582 --> 00:10:50.724
there are real costs to real people,

00:10:50.748 --> 00:10:52.063
and I accept that.

00:10:54.602 --> 00:10:56.483
As a good-ish person, in fact,

00:10:56.507 --> 00:10:59.190
I become better
at noticing my own mistakes.

00:10:59.214 --> 00:11:01.514
I don't wait for people to point them out.

00:11:01.538 --> 00:11:03.680
I practice finding them,

00:11:03.704 --> 00:11:04.980
and as a result ...

00:11:05.911 --> 00:11:09.528
Sure, sometimes it can be embarrassing,

00:11:09.552 --> 00:11:11.414
it can be uncomfortable.

00:11:11.438 --> 00:11:14.784
We put ourselves
in a vulnerable place, sometimes.

00:11:15.968 --> 00:11:18.119
But through all that vulnerability,

00:11:18.143 --> 00:11:22.483
just like in everything else
we've tried to ever get better at,

00:11:22.507 --> 00:11:23.809
we see progress.

00:11:23.833 --> 00:11:24.984
We see growth.

00:11:25.008 --> 00:11:27.937
We allow ourselves to get better.

00:11:29.016 --> 00:11:32.437
Why wouldn't we give ourselves that?

00:11:32.944 --> 00:11:37.471
In every other part of our lives,
we give ourselves room to grow --

00:11:37.495 --> 00:11:40.026
except in this one, where it matters most.

00:11:41.256 --> 00:11:42.407
Thank you.

00:11:42.431 --> 00:11:47.031
(Applause)

